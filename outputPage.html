<html><head><title>Title</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous"></head><body><p class="lead">
<a name="1"></a><b>IN2002 Data Structures and Algorithms </b><br>
Lecture 2 &#xFFFD; Recursion and Abstract Data Types<br>
Aravin Naren<br>Semester 1, 2018/19<br>
1<br>
<hr>
<a name="2"></a><b>Learning Objectives</b><br>
&#xFFFD; Understand recursive algorithms<br>
&#xFFFD; What it means for an algorithm to be recursive<br>&#xFFFD; How to analyse a recursive algorithm in terms of time and space <br>
complexities<br>
&#xFFFD; Abstract data types <br>
&#xFFFD; What they are<br>&#xFFFD; How they are implemented<br>
2<br>
<hr>
<a name="3"></a><b>Recursion</b><br>
3<br>
<hr>
<a name="4"></a><b>Divide and Conquer</b><br>
Many algorithms have the form:<br>
&#xFFFD;If the input is not simple, <b>divide </b>the input into simpler <br>
components, apply the algorithm recursively to each part, and <br><b>combine </b>the results obtained<br>
&#xFFFD;Otherwise, <b>solve </b>it with a special algorithm<br>
4<br>
<hr>
<a name="5"></a><b>Analysing divide and conquer algorithms</b><br>
You have to consider, for an input size of <i>n</i>:<br>
&#xFFFD;If the input is simple<br>
&#xFFFD; the time the special algorithm takes<br>
&#xFFFD;Otherwise, <br>
&#xFFFD; the time of dividing the input, plus<br>&#xFFFD; the time of processing the components, plus<br>&#xFFFD; the time of combining the results<br>&#xFFFD; ... and then solve the recursive definition.<br>
5<br>
<hr>
<a name="6"></a><b>Recursion *</b><br>
A powerful way of programming using a function within itself<br>&#xFFFD; A problem is addressed by identifying:<br>
&#xFFFD; A step towards the next simpler case to which the same <br>
approach applies<br>
AND<br>
&#xFFFD; Result in the simplest case<br>
&#xFFFD; Recursion is, in a way, the reverse of proof by induction<br>
6<br>
* Introduced to you in Computation &amp; Reasoning<br>
<hr>
<a name="7"></a><b>Example: Factorial<br></b>Problem: calculate <i>n</i>! = <i>n</i>&#xFFFD;(<i>n</i>-1)&#xFFFD;(<i>n</i>-2)&#xFFFD;...&#xFFFD;1<br>&#xFFFD; Step (for <i>n</i>&gt;0): <i>n</i>! = <i>n</i>&#xFFFD;(<i>n</i>-1)!<br>&#xFFFD; Base (simplest) case: 0! = 1<br>This defines the value of n! for any natural number n.<br>
<i>Function factorial(n)<br>IF n = 0 THEN</i><br>
// 0<br>
<i>Return 1</i><br>
// 1<br>
<i>ELSE</i><br>
// 2<br>
<i>aux  factorial(n-1)</i><br>
// 3<br>
<i>Return n * aux</i><br>
// 4<br>
7<br>
<hr>
<a name="8"></a>n     aux<br>
<i>Function factorial(n) </i>0<br>
<i>IF n = 0 THEN                     // 0</i><br>
<b>What is going on?</b><br>
<i>Return 1                     // 1</i><br>
<i>ELSE                                  // 2</i><br>
<i>aux  factorial(n-1)  // 3</i><br>
Cal ing factorial (2)<br>
<i>Return n * aux          // 4</i><br>
n     aux<br>
n     aux<br>
<i>Function factorial(n)</i><br>
<i>Function factorial(n)</i><br>
1<br>
1<br>
<i>IF n = 0 THEN                     // 0</i><br>
<i>IF n = 0 THEN                     // 0</i><br>
<i>Return 1                     // 1</i><br>
<i>Return 1                     // 1</i><br>
<i>ELSE                                  // 2</i><br>
<i>ELSE                                  // 2</i><br>
<i>aux  factorial(n-1)  // 3</i><br>
<i>aux  factorial(n-1)  // 3</i><br>
<i>Return n * aux          // 4</i><br>
<i>Return n * aux          // 4</i><br>
n     aux<br>
n     aux<br>
n     aux<br>
<i>Function factorial(n)</i><br>
<i>Function factorial(n)</i><br>
<i>Function factorial(n)</i><br>
2<br>
2<br>
2<br>
<i>IF n = 0 THEN                     // 0</i><br>
<i>IF n = 0 THEN                     // 0</i><br>
<i>IF n = 0 THEN                     // 0</i><br>
<i>Return 1                     // 1</i><br>
<i>Return 1                     // 1</i><br>
<i>Return 1                     // 1</i><br>
<i>ELSE                                  // 2</i><br>
<i>ELSE                                  // 2</i><br>
<i>ELSE                                  // 2</i><br>
<i>aux  factorial(n-1)  // 3</i><br>
<i>aux  factorial(n-1)  // 3</i><br>
<i>aux  factorial(n-1)  // 3</i><br>
8<br>
<i>Return n * aux          // 4</i><br>
<i>Return n * aux          // 4</i><br>
<i>Return n * aux          // 4</i><br>
<hr>
<a name="9"></a>n     aux<br>
<i>Function factorial(n) </i>0<br>
<i>IF n = 0 THEN                     // 0</i><br>
<i>Return 1                     // 1</i><br>
<b>What is going on? (2)</b><br>
<i>ELSE                                  // 2</i><br>
<i>aux  factorial(n-1)  // 3<br>Return n * aux          // 4</i><br>
n     aux<br>
n     aux<br>
<i>Function factorial(n)</i><br>
<i>Function factorial(n)</i><br>
1<br>
1<br>
1<br>
1<br>
<i>IF n = 0 THEN                     // 0</i><br>
<i>IF n = 0 THEN                     // 0</i><br>
Returns 2<br>
<i>Return 1                     // 1</i><br>
<i>Return 1                     // 1</i><br>
<i>ELSE                                  // 2</i><br>
<i>ELSE                                  // 2</i><br>
<i>aux  factorial(n-1)  // 3</i><br>
<i>aux  factorial(n-1)  // 3</i><br>
<i>Return n * aux          // 4</i><br>
<i>Return n * aux          // 4</i><br>
n     aux<br>
n     aux<br>
<i>Function factorial(n)</i><br>
n     aux<br>
<i>Function factorial(n)</i><br>
2<br>
2<br>
1<br>
<i>Function factorial(n) </i>2<br>
1<br>
<i>IF n = 0 THEN                     // 0</i><br>
<i>IF n = 0 THEN                     // 0</i><br>
<i>IF n = 0 THEN                     // 0</i><br>
<i>Return 1                     // 1</i><br>
<i>Return 1                     // 1</i><br>
<i>Return 1                     // 1</i><br>
<i>ELSE                                  // 2</i><br>
<i>ELSE                                  // 2</i><br>
<i>ELSE                                  // 2</i><br>
<i>aux  factorial(n-1)  // 3</i><br>
<i>aux  factorial(n-1)  // 3</i><br>
<i>aux  factorial(n-1)  // 3</i><br>
9<br>
<i>Return n * aux          // 4</i><br>
<i>Return n * aux          // 4</i><br>
<i>Return n * aux          // 4</i><br>
<hr>
<a name="10"></a><b>Understanding the Picture</b><br>
&#xFFFD; Recursive calls to factorial get pushed onto the stack<br>
&#xFFFD; Multiple copies of function factorial, each with different <br>
arguments &amp; local variable values, and execution at <br>different lines of the code<br>
&#xFFFD; All the computer really needs to remember for each active <br>
function call is the values of arguments &amp; local variables <br>and the location of the next statement to be executed when <br>control goes back <br>
10<br>
<hr>
<a name="11"></a><b>The Stack</b><br>
n   aux  line<br>
0<br>
0<br>
n   aux  line<br>
n   aux  line<br>
n   aux  line<br>
1<br>
0<br>
1<br>
3<br>
1<br>
1<br>
3<br>
n   aux  line<br>
n   aux  line<br>
n   aux  line<br>
n   aux  line<br>
n   aux  line<br>
2<br>
0<br>
2<br>
3<br>
2<br>
3<br>
2<br>
3<br>
2<br>
1<br>
3<br>
11<br>
<hr>
<a name="12"></a><b>What are &quot;factorial&apos;s&quot; the time and space <br>complexities?  </b><br>
&#xFFFD; Time complexity<br>
&#xFFFD; Calls itself n times<br>&#xFFFD; All other statements constant<br>&#xFFFD; ... hence O(??)<br>
&#xFFFD; Space complexity <br>
&#xFFFD; Calls itself n times (stack)<br>&#xFFFD; ... hence O(??)<br>
12<br>
<hr>
<a name="13"></a><b>Example: power<br></b>Problem: calculate <i>xn<br></i>&#xFFFD; Step (for <i>n&gt;0</i>): <i>xn = x &#xFFFD; xn-1<br></i>&#xFFFD; Base case: <i>x0 = 1<br></i>This defines the value of <i>xn </i>for any natural number <i>n</i>.<br>
<i>Function power(x, n):<br>IF n = 0 THEN</i><br>
<i>Return 1</i><br>
<i>ELSE</i><br>
<i>Return x * power(x, n-1)</i><br>
13<br>
<hr>
<a name="14"></a><b>What are &quot;power&apos;s&quot; the time and space <br>complexities?  </b><br>
&#xFFFD; Time complexity<br>
&#xFFFD; Space complexity<br>
14<br>
<hr>
<a name="15"></a><b>Tail Recursion</b><br>
void tail(int i) {<br>
if (i &gt; 0) {<br>
Tail recursion is when the <br>
System.out.println(i);<br>
recursive call is the last thing <br>
tail(i-1);<br>
done.<br>
}<br>
}<br>
void tailloop(int i) {<br>
while (i &gt; 0) {<br>
A loop can easily replace it.<br>
System.out.println(i);<br>i=i-1;<br>
}<br>
15<br>
}<br>
<hr>
<a name="16"></a><b>Example of Tail Recursion: factorial</b><br>
<i>This factorial function is tail-recursive:</i><br>
int factorial(int n) {<br>
return fact(n, 1);<br>
}<br>
int fact (int n, int product) {<br>
if (n == 0){<br>
return product;<br>
}<br>return fact(n-1, n*product);<br>
}<br>
16<br>
<hr>
<a name="17"></a><b>... Tail Recursive factorial</b><br>
int fact (int n, int product) {<br>
if (n == 0)<br>
return product;<br>
return fact(n-1, n*product);<br>
}<br>
<i>And can easily be converted </i><br>
int fact(int n, int product) {<br>
<i>into iterative (i.e. a loop).</i><br>
while(n&gt;0) {<br>
product = n*product;<br>n = n-1;<br>
}<br>return product;<br>
}<br>
17<br>
<hr>
<a name="18"></a><b>Another Example of Recursion</b><br>
What does this function do?<br>
void printNum(int n) {<br>
if (n &gt;= 10){<br>
printNum(n/10);<br>
}<br>System.out.print(n%10);<br>
}<br>
18<br>
<hr>
<a name="19"></a><b>A Call Tree for printNum</b><br>
printNum(1234)<br>
printNum(123)<br>
printNum(12)<br>
printNum(1)<br>
System.out.print(`1&apos;)<br>
System.out.print(`2&apos;)<br>
System.out.print(`3&apos;)<br>
System.out.print(`4&apos;)<br>
19<br>
<hr>
<a name="20"></a><b>What are &quot;printNum&apos;s&quot; the time and space <br>complexities?</b><br>
&#xFFFD; Time complexity<br>
&#xFFFD; Calls itself log n times<br>&#xFFFD; All other statements constant<br>&#xFFFD; ... hence O(??)<br>
&#xFFFD; Space complexity <br>
&#xFFFD; Calls itself log n times (stack)<br>&#xFFFD; ... hence O(??)<br>
20<br>
<hr>
<a name="21"></a><b>Another example for recursion (exam 2014-15)</b><br>
<b>Recursion   </b>(15%)<br>You are given the code for <i>bla </i>below. <br>
void bla (int i)  {<br>
if (i &gt; 0) {<br>
System.out.print (i + &quot; &quot;);<br>bla(i &#xFFFD; 1);<br>
}<br>
}<br>
21<br>
<hr>
<a name="22"></a><b>Another example for recursion (exam 2014-15) &#xFFFD;<br>cont&apos;d</b><br>
a) Describe what <i>bla </i>does.  (5%)<br>
b) What is its time complexity? Justify your answer.  (5%)<br>
c) What is its space complexity? Justify your answer.  (5%)<br>
22<br>
<hr>
<a name="23"></a><b>Applications of Recursion</b><br>
Recursion is useful for:<br>
&#xFFFD; designing algorithms<br>&#xFFFD; traversing branching structures (like trees and graphs)<br>&#xFFFD; writing parsers<br>&#xFFFD; backtracking search algorithms<br>&#xFFFD; divide-and-conquer algorithms<br>
23<br>
<hr>
<a name="24"></a><b>Pros and Cons of Using Recursion</b><br>
&#xFFFD;Pros<br>
&#xFFFD;often elegant solutions<br>
&#xFFFD;compact code<br>
&#xFFFD;proving correctness often relatively easy<br>
&#xFFFD;Cons<br>
&#xFFFD;careful algorithm design necessary<br>
&#xFFFD;hard to debug (better prove correctness)<br>
&#xFFFD;function call stack needs extra memory and is often limited<br>
24<br>
<hr>
<a name="25"></a><b>Common Computations</b><br>
&#xFFFD; Why do we often discuss sorting algorithms?<br>
&#xFFFD; How about searching?<br>
&#xFFFD; Insertion?<br>
&#xFFFD; Deletion?<br>
25<br>
<hr>
<a name="26"></a><b>Sorting Algorithms</b><br>
&#xFFFD; What are examples of sorting algorithms?<br>
&#xFFFD; How fast are they?<br>
26<br>
<hr>
<a name="27"></a><b>Sorting Algorithms</b><br>
<b>Space </b><br>
<b>Average time  Worst case </b><br>
<b>complexity</b><br>
<b>complexity</b><br>
<b>time <br>complexity</b><br>
Selection sort O(1)<br>
O(n2)<br>
O(n2)<br>
Insertion sort<br>
O(1)<br>
O(n2)<br>
O(n2)<br>
Quicksort<br>
O(log n)<br>
O(n log n)<br>
O(n2)<br>
Mergesort<br>
O(n)<br>
O(n log n)<br>
O(n log n)<br>
27<br>
<hr>
<a name="28"></a><b>Other Common Computations</b><br>
&#xFFFD; How about searching?<br>
&#xFFFD; Insertion?<br>
&#xFFFD; Deletion?<br>
28<br>
<hr>
<a name="29"></a><b>Deletion Algorithm</b><br>
&#xFFFD; How do we delete an element of an array?<br>
&#xFFFD; What if the array is sorted?<br>
&#xFFFD; How often do we need to delete new elements?<br>
29<br>
<hr>
<a name="30"></a><b>Food for Thought</b><br>
&#xFFFD; Should we always use arrays to store and manipulate our data? <br>
&#xFFFD; Should we always sort their contents?<br>
30<br>
<hr>
<a name="31"></a><b>Abstract Data Types</b><br>
31<br>
<hr>
<a name="32"></a><b>Abstract Data Types  (ADTs)</b><br>
&#xFFFD;Abstract data types<br>
&#xFFFD;separate functionality from implementation<br>
&#xFFFD;hidden representation<br>&#xFFFD;manipulated via a limited set of operations<br>&#xFFFD;in Java, interfaces with defined method semantics<br>
&#xFFFD;Data structures<br>
&#xFFFD;concrete implementations, often subject to an invariant preserved by <br>the operations<br>&#xFFFD;in Java: classes implementing ADT interfaces<br>&#xFFFD;are analysed by measuring the time and space complexity of  the <br>structure and each  operation<br>
32<br>
<hr>
<a name="33"></a><b>ADT Stack</b><br>
Think of physical stacks:<br>
&#xFFFD; series of similar elements<br>&#xFFFD; you add elements on the top<br>&#xFFFD; you take the elements from the top<br>
... so the last element in is the first out (LIFO)<br>
33<br>
<hr>
<a name="34"></a><b>Stack Operations</b><br>
You can only remove the last element added.<br>
The operations are thus:<br>
&#xFFFD; Add an element to the stack<br>&#xFFFD; Remove the last element added<br>&#xFFFD; Check whether the stack is empty.<br>
34<br>
<hr>
<a name="35"></a><b>A stack in Java</b><br>
// a stack of integers<br>public interface Stack {<br>
// is the stack empty?<br>boolean isEmpty();<br>
// add (push) an element into the stack<br>void push(int elt);<br>
// remove and return the most recently pushed<br>// element still in the stack<br>int pop();<br>
35<br>
}<br>
<hr>
<a name="36"></a><b>A stack implementation using an array</b><br>
<i>public class ArrayStack implements Stack {</i><br>
<i>private int[] a;<br>private int count = 0;</i><br>
<i>public ArrayStack(int size) {a = new int[size];}</i><br>
<i>public boolean isEmpty() { return count == 0; }</i><br>
<i>public void push(int elt) { a[count++] = </i><br>
<i>elt; }</i><br>
<i>public int pop() { return a[--count]; }</i><br>
<i>}</i><br>
36<br>
<hr>
<a name="37"></a><b>Checking Brackets with a Stack</b><br>
opening bracket:  push on stack<br>closing bracket: pop from stack and match<br>
String <br>
Stack<br>
Op<br>
( [ ] ( [ ) ] )<br>
push<br>
[ ] ( [ ) ] ) <br>
( <br>
push<br>
] ( [ ) ] )<br>
( [ ) ] )<br>
[ ) ] )<br>
) ] )<br>
37<br>
<hr>
<a name="38"></a><b>Priority Queues</b><br>
&#xFFFD; You can only remove the element with the highest priority<br>&#xFFFD; Examples: printer queues, emergency rooms, council housing<br>
38<br>
<hr>
<a name="39"></a><b>Priority Queue Operations</b><br>
&#xFFFD; Add an element<br>&#xFFFD; Remove an element: the element removed is the one with <br>
the highest priority<br>
&#xFFFD; Check whether the queue is empty<br>
39<br>
<hr>
<a name="40"></a><b>Applications of Priority Queues</b><br>
&#xFFFD; As a component of various algorithms<br>&#xFFFD; Sorting: add all the items to the priority queue and then <br>
extract them one by one<br>
&#xFFFD; Scheduling (e.g. in operating systems, post, air traffic)<br>&#xFFFD; Event-driven simulation<br>
40<br>
<hr>
<a name="41"></a><b>Scheduling</b><br>
Several tasks should be performed with different priorities<br>For example...<br>
We want to produce a system for parcel deliveries. The priority could be <br>set by using the guaranteed date of delivery and the time at which the <br>parcel was posted.<br>
&#xFFFD; The priority queue would be handled by storing the parcels in the depot <br>
and releasing them for delivery according to their priority.<br>
&#xFFFD; In busy days, probably only those parcels whose delivery is due - i.e., <br>
those that have the highest priority - could be delivered.<br>
&#xFFFD; In less busy days, parcels would be delivered in advance of their <br>
41<br>
guaranteed date of delivery.<br>
<hr>
<a name="42"></a><b>Event-Driven Simulation</b><br>
<i>We wish to simulate a series of events, each considered to occur at a point in </i><br>
<i>simulated time.</i><br>
Nothing happens between events, so maintain a collection of pending events, and repeat:<br>
&#xFFFD; extract the first pending event<br>
&#xFFFD; advance the simulation clock to its time<br>
&#xFFFD; simulate the event<br>
Events may change the state, and may cause other events at later times, i.e. add further <br>
events to the collection<br>
Useful for load analysis and prediction<br>
e.g., for Internet nodes, road or air traffic, emergency procedures.<br>
42<br>
<hr>
<a name="43"></a><b>A priority queue ADT</b><br>
// A priority queue of integers<br>public interface PriorityQueue {<br>
// Is the priority queue empty?<br>boolean isEmpty();<br>
// Add an element to the priority queue<br>void add(int elt);<br>
// Remove and return the largest value<br>// currently in the priority queue<br>int extractMax();<br>
}<br>
43<br>
<hr>
<a name="44"></a><b>An implementation using a sorted array</b><br>
<i>A way of implementing priority queues is to keep the elements <br>in a sorted array, so:</i><br>
&#xFFFD; <i>to add an element, search and insertion are used<br></i>&#xFFFD; <i>to extract an element, the last element in the array is </i><br>
<i>extracted (as it will have the highest priority)</i><br>
44<br>
<hr>
<a name="45"></a><b>Concrete Implementation in Java</b><br>
public class ArrayPQ implements PriorityQueue {<br>
private int[] data;<br>private int count = 0;<br>
public ArrayPQ(int size){ data = new int[size]; }<br>
public boolean isEmpty(){ return count == 0; }<br>
public void add(int elt){<br>
insert(data, count++, elt);<br>
}<br>
public int extractMax(){ return data[--count]; }<br>
45<br>
}<br>
<hr>
<a name="46"></a><b>Analysing the use of the Data Structure</b><br>
&#xFFFD; The data structure takes O(n) space complexity<br>
&#xFFFD; By using the ordered array data structure:<br>
&#xFFFD; isEmpty takes time O(??)<br>&#xFFFD; add takes time O(??)<br>&#xFFFD; extractMax takes time O(??)<br>
&#xFFFD; The ordering constraint is very restrictive, maintaining it by <br>
insertions costs O(n) time.<br>
46<br>
<hr>
<a name="47"></a><b>An Alternative Implementation</b><br>
What would happen if the representation were an unordered array?<br>
In that case:<br>
&#xFFFD; isEmpty takes time O(??)<br>&#xFFFD; add takes time O(??)<br>&#xFFFD; extractMax takes time O(??)<br>
It is an equivalent situation, but slow at extracting.<br>
47<br>
<hr>
<a name="48"></a><b>Is there a better implementation?</b><br>
48<br>
<hr>
<a name="49"></a><b>Reading</b><br>
&#xFFFD; Weiss: Chapter 7, and chapter 15 section 1.1  <br>
&#xFFFD; Drozdek: Chapter 5, and chapter 4 sections 4.1and 4.3  <br>
Next week: Trees and heapsort<br>
49<br>
<hr>
<a name="50"></a>City, University of London<br>Northampton Square<br>London<br>EC1V 0HB<br>United Kingdom<br>
T: +44 (0)20 7040 8406<br>E: ug-compsci@city.ac.uk<br>www.city.ac.uk/department-computer-science<br>
50<br>
<hr>



<a name="1"></a><b>IN2002 Data Structures and Algorithms </b><br>
Lecture 3 &#xFFFD; Trees, Heaps and Queues<br>
Aravin Naren<br>Semester 1, 2018/19<br>
1<br>
<hr>
<a name="2"></a><b>Learning Objectives</b><br>
&#xFFFD; Understand and be able to use:<br>
&#xFFFD; the abstract data type queue<br>&#xFFFD; the data structures:<br>
&#xFFFD; Heaps<br>&#xFFFD; Extensible arrays<br>
&#xFFFD; Be able to understand, apply and develop algorithms to those <br>
above, most notably:<br>&#xFFFD; Adding elements<br>&#xFFFD; Extracting elements<br>&#xFFFD; HeapSort<br>
2<br>
<hr>
<a name="3"></a><b>Trees</b><br>
3<br>
<hr>
<a name="4"></a><b>What is this?</b><br>
17<br>
11<br>
15<br>
7<br>
5<br>
9<br>
10<br>
2<br>
4<br>
1<br>
3<br>
8<br>
6<br>
0<br>
4<br>
<hr>
<a name="5"></a><b>Quick introduction to trees</b><br>
&#xFFFD; Trees are data structures that have a <br>
root, nodes, branches and leaves<br>
&#xFFFD; Most nodes are at the end of a <br>
branch. The only exception is the root <br>(which is the top node!)<br>
&#xFFFD; Branches proceed from nodes<br>
&#xFFFD; Nodes without branches are cal ed <br>
&quot;leaves&quot;<br>
5<br>
<hr>
<a name="6"></a><b>More tree terminology</b><br>
&#xFFFD; The nodes n2,n3 at the end of a node <br>
n1&apos;s branches are its children, and n1 <br>is the parent of n2,n3.<br>
&#xFFFD; The root is thus a node with no <br>
parents.<br>
&#xFFFD; The leaves are nodes with no <br>
children.<br>
6<br>
<hr>
<a name="7"></a><b>Tree types</b><br>
A <b>binary </b>tree is a tree in which each node <br>has, at most, two children<br>
A <b>perfectly balanced </b>binary tree is a <br>tree whose least deep leaf is no more<br>than one level apart from the deepest one<br>
7<br>
<hr>
<a name="8"></a><b>Last week...</b><br>
Priority queues<br>
<b>Ordered </b><br>
<b>Unordered </b><br>
<b>Array</b><br>
<b>Array</b><br>
isEmpty<br>
O(?)<br>
O(?)<br>
add<br>
O(?)<br>
O(?)<br>
extractMax<br>
O(?)<br>
O(?)<br>
8<br>
<hr>
<a name="9"></a><b>Is there a better implementation?</b><br>
Using heaps (a kind of tree) we can distribute and<br>reduce the load, achieving O(log n) time for both add<br>and extractMax.<br>
9<br>
* Introduced to you in Computation &amp; Reasoning<br>
<hr>
<a name="10"></a><b>Heaps</b><br>
10<br>
<hr>
<a name="11"></a><b>Heaps</b><br>
A heap is a perfectly balanced binary tree such that:<br>&#xFFFD; No node is larger than its parent<br>&#xFFFD; All items on the lowest level are as far to the left as possible<br>
11<br>
<hr>
<a name="12"></a><b>Heap Operations</b><br>
&#xFFFD; Heap is empty if the root is empty<br>&#xFFFD; Heap insertion: add a node to the heap--displacing other nodes as necessary so <br>
that the heap remains a heap<br>
&#xFFFD; Heap extraction: remove the element with the highest value in the heap (the <br>
root), moving the other nodes as necessary so that the heap remains a heap<br>
12<br>
<hr>
<a name="13"></a><b>Heap Insertion</b><br>
&#xFFFD; Add the new node as a leaf<br>&#xFFFD; Sift the new node up to its correct position (at most log n swaps--<br>
because the tree has at most log n levels)<br>
13<br>
<hr>
<a name="14"></a><b>Heap Extraction</b><br>
&#xFFFD; Extract the root, and place the last leaf in the root position<br>&#xFFFD; Re-establish the heap conditions (at most log n swaps)<br>
14<br>
<hr>
<a name="15"></a><b>Heaps and Arrays</b><br>
&#xFFFD; Heaps can be represented as arrays:<br>
15<br>
<hr>
<a name="16"></a><b>Relating indices</b><br>
Notice that:<br>&#xFFFD; the parent of node n is node <br>
(n-1)/2 (int division)<br>
&#xFFFD; the left child of node n is <br>
node 2n + 1<br>
&#xFFFD; the right child of node n is <br>
node 2n + 2<br>
16<br>
<hr>
<a name="17"></a><b>An Implementation in Java</b><br>
public class HeapPQ implements PriorityQueue {<br>
private int[] data; // data[] is the heap<br>private int count = 0;<br>
public HeapPQ(int size){data = new int [size];}<br>
public boolean isEmpty(){return count == 0;}<br>
... HeapPQ continues<br>
17<br>
<hr>
<a name="18"></a><b>Relating Indices in Java</b><br>
You will remember that:<br>
&#xFFFD; the parent of node n is node (n-1)/2<br>&#xFFFD; the left child of node n is node 2n + 1<br>&#xFFFD; the right child of node n is node 2n + 2<br>
private int parent(int n) { return (n-1)/2; }<br>private int left(int n) { return n*2 + 1; }<br>private int right(int n) { return n*2 + 2; }<br>
... HeapPQ continues<br>
18<br>
<hr>
<a name="19"></a><b>Heap Insertion</b><br>
<i>Function add(elt) where data is the array containing<br>the heap and count is the heap size:<br>pos   count+1<br>WHILE pos &gt; 1 AND data[parent of pos] &lt; elt</i><br>
<i>data[pos]  data[parent of pos]<br>pos  parent of pos</i><br>
<i>data[pos]  elt<br>count  count + 1</i><br>
19<br>
<hr>
<a name="20"></a><b>Heap Extraction</b><br>
<i>Function extractMax() where &quot;data&quot; is the array containing the<br>heap and &quot;count&quot; is the heap size:<br>max  data[1]<br>data[1]  data[count]<br>count  count - 1<br>moveDown(data, 1, count)<br>Return max</i><br>
Function <i>moveDown(data, first, last) </i>moves the <br>element at position <i>first </i>down to its proper position<br>
20<br>
<hr>
<a name="21"></a><b>Moving a key down the heap</b><br>
<i>Function moveDown(data, first, last):<br>WHILE left child of first &lt;= last</i><br>
<i>larger  position of the child with the larger value</i><br>
<i>IF data[first] &gt;= data[larger] THEN</i><br>
<i>Break the while loop</i><br>
<i>swap first and larger in data</i><br>
<i>first  larger</i><br>
Remember that <i>first</i>, <i>larger </i>and <i>last </i>are positions in array <i>data</i>. <br>The value of <i>largest</i>, for example, is <i>data[largest].</i><br>
21<br>
<hr>
<a name="22"></a><b>Sorting using heaps</b><br>
Heap sort involves:<br>&#xFFFD; adding the elements to a heap, and then<br>&#xFFFD; extracting the elements from the heap<br>
This could be done with just one array:<br>&#xFFFD; in the first phase, the heap grows as the unsorted section shrinks<br>&#xFFFD; in the second phase, the heap shrinks as the sorted portion <br>
grows.<br>
22<br>
<hr>
<a name="23"></a><b>HeapSort in Java</b><br>
void heapsort(int[] data) {<br>
\\ first phase: heap goes from data[i+1] to<br>\\ data[data.length-1]. The rest of data[] is<br>\\ unsorted<br>for (int i = data.length/2 - 1; i&gt;= 0; i--)<br>
moveDown(data, i, data.length-1);<br>
\\ second phase: heap goes from data[0] to data[i]<br>\\ the rest contains the largest elements, sorted<br>for (int i = data.length - 1; i&gt;= 1; i--) {<br>
swap(data, 0, i);<br>moveDown(data, 0, i-1);<br>
}<br>
}<br>
23<br>
<hr>
<a name="24"></a><b>HeapSort Example</b><br>
&#xFFFD; Use heapSort to sort [1 20 3 10 8 7 40]<br>
24<br>
<hr>
<a name="25"></a><b>HeapSort Analysis</b><br>
&#xFFFD; Heap sort performs O(n) heap operations, each taking O(log n) time, in <br>
total <b>O(n log n) time </b>in the <b>worst case</b>.<br>
&#xFFFD; Heap sort and quicksort have both <b>average time complexity of          </b><br>
<b>O(n log n)</b>, but heap sort is normally slower than quicksort (different <br>constant factors). <br> Quicksort is preferred when no guaranteed response time needed.<br>
&#xFFFD; <b>Heap sort </b>requires only <b>O(1) extra memory space</b>, in contrast to <b>O(n) </b><br>
<b>for merge sort </b>or <b>O(log n) for quicksort </b>(on average, O(n) in the worst <br>case).<br>
&#xFFFD; A refinement: build the heap from the bottom up. This can be shown to <br>
take O(n) time, but the O(n log n) selection phase still dominates.<br>
25<br>
<hr>
<a name="26"></a><b>Dynamic Data Structures</b><br>
26<br>
<hr>
<a name="27"></a><b>Dynamic Data Structures</b><br>
&#xFFFD;Amounts of data to store often vary in size in ways we can <br>not determine beforehand<br>&#xFFFD;Reallocate-and-copy of arrays can solve this problem<br>&#xFFFD;In general, linked structures are more flexible:<br>
&#xFFFD;singly linked lists<br>
&#xFFFD;doubly linked lists and circular lists<br>
&#xFFFD;trees and graphs<br>
27<br>
<hr>
<a name="28"></a><b>Queues</b><br>
&#xFFFD;First In First Out (FIFO)<br>
&#xFFFD;As opposed to last in first out (stacks)<br>&#xFFFD;And also to priority queues (in which priorities may  not reflect the <br>actual order of addition)<br>
28<br>
<hr>
<a name="29"></a><b>Queue Operations</b><br>
You must always remove the element that has been in the <br>queue the longest.<br>
The operations are thus:<br>
&#xFFFD; Add an element to the queue<br>&#xFFFD; Remove the element added the longest time before<br>&#xFFFD; Check whether the queue is empty.<br>
29<br>
<hr>
<a name="30"></a><b>A Queue ADT</b><br>
public interface Queue {<br>
// Is the queue empty?<br>boolean isEmpty();<br>// Add an element to the queue<br>void enqueue(int elt);<br>// Remove and return the earliest element of<br>// the queue<br>int dequeue();<br>
}<br>
30<br>
<hr>
<a name="31"></a><b>A Stack ADT</b><br>
// a stack of integers<br>public interface Stack {<br>
// is the stack empty?<br>boolean isEmpty();<br>// add (push) an element into the stack<br>void push(int elt);<br>// remove and return the most recently pushed<br>// element still in the stack<br>int pop();<br>
}<br>
31<br>
<hr>
<a name="32"></a><b>Extending arrays by relocate-and-copy</b><br>
Because size is unpredictable:<br>&#xFFFD; initial array allocation may fall short<br>&#xFFFD; trying to be safe is wasteful<br>A solution: extensible arrays<br>&#xFFFD; start with a small array<br>&#xFFFD; if more space is needed, create a new, larger array and copy <br>
elements into it<br>
... adds O(n) to space and O(n) to time per extension<br>
32<br>
<hr>
<a name="33"></a><b>Stacks with relocate-and-copy</b><br>
public class ArrayStack implements Stack {<br>
private int count = 0;<br>private int[] data = new int[1];<br>
public boolean isEmpty() {<br>
return count == 0;<br>
}<br>
public int pop() {<br>
count--;<br>return data[count];<br>
33<br>
}<br>
... continues<br>
<hr>
<a name="34"></a><b>Stacks with relocate-and-copy (ctd.)</b><br>
... which was the same as last week. However:<br>
public void push(int elt) {<br>
if (count == data.length) { // not enough space<br>
int[] d1 = new int[data.length + 1]; // new<br>for (int i = 0; i &lt; count; i++) // array<br>
d1[i] = data[i]; <br>
// copy elements<br>
data = d1;<br>
// use new array<br>
}<br>data[count] = elt; <br>
// add new element<br>
count++;<br>
}<br>
34<br>
}<br>
<hr>
<a name="35"></a><b>Amortised Analysis</b><br>
<i><b>Amortised </b></i>complexity refers to the <b><i>average complexity over a <br>sequence of operations</i></b>, which normally depend on each other (usually <br>choosing the worst case regarding data input).<br>
This is different from what we normally call <b><i>average case </i></b>complexity, <br>which <b><i>averages over different input data </i></b>for a single, independent <br>operation.<br>
E.g., the average complexity (on an array of length n) of Quick Sort is     <br>O(n log n), the amortised complexity over a sequence of Quick Sort <br>applications is O(n2)<br>(implying the worst case per application).<br>
35<br>
<hr>
<a name="36"></a><b>Analysis of the implementation</b><br>
In a sequence of n pushes, the number of copies is<br>
1 + 2 + 3 + ... + (n - 1) = n(n - 1)/2 = O(n2)<br>
This means that <b>per <i>push </i>operation</b>, there is an <b>amortised cost of O(n).</b><br>
Going up by a larger step than 1 improves things, but<br>only by a constant factor.<br>
36<br>
<hr>
<a name="37"></a><b>... An improvement</b><br>
If we <b>double the size whenever we extend</b>, the<br>number of elements copied for n = 2k pushes is<br>
1 + 2 + 22 + ... + 2k-1 = 2k - 1 = O(n)  (proof on next slide)<br>
This <b>averages out at O(1) per operation</b>, i.e., the amortised cost over the <br>sequence of operations is constant.<br>
37<br>
<hr>
<a name="38"></a><b>Proof: Sum of Powers of 2</b><br>
This has been used in the last analysis and the telescopic sum.<br>
Statement: i=0...k-1 2i = 1 + 2 + 22 + ... + 2k-1 = 2k - 1<br>
Proof by in induction:<br>base case k=2:   20 + 21 = 1 + 2 = 3 = 4 &#xFFFD; 1 = 22 &#xFFFD; 1<br>step k to k+1:      20 + ... + 2k-1 + 2k = 2k &#xFFFD; 1 + 2k<br>
= 2&#xFFFD;2k &#xFFFD; 1<br>= 2k+1 &#xFFFD; 1<br>
Statement<br>applied here<br>
38<br>
<hr>
<a name="39"></a><b>Array-like operations in extensible arrays</b><br>
Some O(1) time operations in extensible arrays:<br>
public int size() {<br>
return count;<br>
}<br>public int elementAt(int pos) {<br>
return data[pos];<br>
}<br>public void setElementAt(int pos, int value) {<br>
data[pos] = value;<br>
}<br>
39<br>
<hr>
<a name="40"></a><b>Summary of extensible arrays</b><br>
&#xFFFD; Extensible arrays are an implementation of the Stack ADT that use O(n) <br>
space<br>
&#xFFFD; With the right extension policy, these operations take O(1) time<br>&#xFFFD; They also provide array-like operations at O(1) time<br>&#xFFFD; Implementing the Queue ADT with extensible arrays is not so convenient <br>
(why?)<br>
&#xFFFD; For greater convenience, we can use pointers<br>
40<br>
<hr>
<a name="41"></a><b>Extensible arrays in Java</b><br>
&#xFFFD;Java has data structures for extensible arrays: <br>
Vectors and ArrayLists<br>
&#xFFFD;Vectors and ArrayLists are like arrays that can be extended as <br>necessary<br>
&#xFFFD;you don&apos;t have to worry about their size<br>
&#xFFFD;you don&apos;t have to extend them explicitly<br>
&#xFFFD;Vectors have Objects as elements<br>
41<br>
<hr>
<a name="42"></a><b>ArrayLists in Java</b><br>
Import them:<br>import java.util.List; // ArrayList and Vector are Lists<br>import java.util.ArrayList;<br>Create an ArrayList:<br>List l1 = new ArrayList();<br>Programming against an Interface is more flexible.<br>
Adding at index i moves following elements to the right:<br>al.add(i,p)<br>(Array)List and Vector use Generics since Java 5.0 (JDK 1.5):<br>
42<br>
List&lt;String&gt; stringList = new ArrayList&lt;String&gt;();<br>
<hr>
<a name="43"></a><b>Vectors in Java</b><br>
To use them you have to import them:<br>import java.util.Vector;<br>
To create a vector v1:<br>Vector v1 = new Vector();<br>
The size of vector v1 is:<br>v1.size()<br>
To test whether v1 is empty:<br>v1.isEmpty()<br>
43<br>
<hr>
<a name="44"></a><b>Other vector &amp; arrayList methods in Java</b><br>
To add an element--object <i>p</i>--at the end of vector v1 (arrayList a1):<br>v1.addElement(p); al.add(p);<br>
To access the element at position <i>n </i>in vector v1 (arrayList a1):<br>e_n = v1.elementAt(n); e_n = al.get(n);<br>
To assign element <i>p </i>to position <i>n </i>in vector v1:<br>v1.set(n, p); \\ note that this returns the<br>\\ object previously in that position<br>
44<br>
<hr>
<a name="45"></a><b>Reading</b><br>
&#xFFFD; Weiss: Chapters 15, 17 and 20<br>
&#xFFFD; Drozdek: Sections 4.2, 6.1 and 9.3.2<br>
Next week: Linked lists<br>
45<br>
<hr>
<a name="46"></a>City, University of London<br>Northampton Square<br>London<br>EC1V 0HB<br>United Kingdom<br>
T: +44 (0)20 7040 8406<br>E: ug-compsci@city.ac.uk<br>www.city.ac.uk/department-computer-science<br>
46<br>
<hr>



<a name="1"></a><b>IN2002 Data Structures and Algorithms </b><br>
Lecture 4 &#xFFFD; Pointers and Singly Linked Lists<br>
Aravin Naren<br>Semester 1, 2018/19<br>
1<br>
<hr>
<a name="2"></a><b>Learning Objectives</b><br>
&#xFFFD;Understand and be able to use the data structure <br>singly linked lists<br>&#xFFFD; Be able to understand, apply and develop <br>algorithms to handle singly linked lists. Including:<br>
&#xFFFD;Adding elements<br>
&#xFFFD;Deleting elements <br>
&#xFFFD;Traversing a list<br>
2<br>
<hr>
<a name="3"></a><b>Introduction</b><br>
3<br>
<hr>
<a name="4"></a><b>What is this?</b><br>
5<br>
8<br>
3<br>
null<br>
4<br>
<hr>
<a name="5"></a><b>Database Records</b><br>
&#xFFFD;A record is a fixed col ection of things of different types.<br>&#xFFFD;E.g. records at a mobile phone provider:<br>
Client ID <br>
1234<br>
Phone number <br>
+44 7887 4444444<br>
Owner <br>
Rupert Taylor<br>
Start date <br>
04/10/2001<br>
Credit <br>
&#xFFFD;24.53<br>
Type of contract  Ultra<br>International opt. No<br>Free minutes left  42<br>
5<br>
<hr>
<a name="6"></a><b>Records as Objects</b><br>
class Mobile {<br>
public int clientID;<br>public String number;<br>public String name;<br>public Date startdate;<br>public int credit;<br>public char contract;<br>public boolean intl;<br>public int seconds;<br>...<br>public Mobile(int id, String nu, String na, ...) {<br>
clientID = c; number = nu; name = na; ....<br>
}<br>
6<br>
}<br>
<hr>
<a name="7"></a><b>Pointers to Records</b><br>
&#xFFFD; In Java, variables cannot contain objects (record instances, <br>in this case), but pointers to them<br>&#xFFFD; Every reference type can have value nul , which refers to no <br>object at all<br>
Mobile x = null;<br>
&#xFFFD; Several variables may refer to the same object:<br>
Mobile y = new Mobile(1234,<br>
&quot;+44 7887 4444444&quot;,&quot;Rupert&quot;,...);<br>
Mobile z = y;<br>
7<br>
<hr>
<a name="8"></a><b>Are two records equal?</b><br>
Consider:<br>
Mobile x = new Mobile(1234,<br>
&quot;+44 7887 4444444&quot;,&quot;Rupert&quot;,...);<br>
Mobile y = new Mobile(1234,<br>
&quot;+44 7887 4444444&quot;,&quot;Rupert&quot;,...);<br>
Mobile z = x;<br>
x == z is <br>x == y is<br>
x.compareTo(y), however, can be defined to return 0 to indicate that <br>both objects contain the same values<br>
8<br>
<hr>
<a name="9"></a><b>What would happen here?</b><br>
Consider:<br>
Mobile x = new Mobile(1234,<br>
&quot;+44 7887 4444444&quot;,&quot;Rupert&quot;,...);<br>
Mobile y = new Mobile(1234,<br>
&quot;+44 7887 4444444&quot;,&quot;Rupert&quot;,...);<br>
Mobile z = x;<br>z.name = &quot;Anne&quot;;<br>y.clientID = 555;<br>
What are the values of:<br>x.name <br>
x.clientID<br>
y.name <br>
y.clientID<br>
9<br>
z.name <br>
z.clientID<br>
<hr>
<a name="10"></a><b>What are links? </b><br>
All object variables in Java are actually pointers<br>
A pointer is a link to some object, i.e. a piece of memory:<br>
&#xFFFD; Links can be thought of as arrows, addresses or references<br>&#xFFFD; They point at an object that is somewhere in the system&apos;s memory<br>
10<br>
<hr>
<a name="11"></a><b>Pointers to an address</b><br>
Foo p;<br>
When you create and assign objects, the system <br>
<b>null</b><br>
al ocates memory and assigns addresses<br>
Foo p = new Foo();<br>
memory <b>address E1E42FB:</b><br>
<b>E1E42FB</b><br>
New object of <br>class Foo<br>
Foo q = p;<br>
Creating a pointer to the same object <br>
<b>E1E42FB</b><br>
at address  <b>E1E42FB</b><br>
11<br>
<hr>
<a name="12"></a><b>Pointers are links</b><br>
Foo p;<br>
In Java you don&apos;t need to worry about the <br>
<b>null</b><br>
address, just what you are pointing at.<br>
Foo p = new Foo();<br>
memory address <b>E1E42FB:</b><br>
New object of <br>class Foo<br>
Foo q = p;<br>
In official Java parlance, they are cal ed <br><i>references</i>.<br>
12<br>
<hr>
<a name="13"></a><b>Links in Java</b><br>
<b>All </b>variables whose type is a class (or interface) of objects are actually <br>pointers (&quot;references&quot;) to an instance of such class (or to null if empty).<br>
This means that the <b>same </b>object can be assigned to different variables<br>
... and, importantly, the same object&apos;s methods and parameters can be <br>accessed through different variables<br>
13<br>
<hr>
<a name="14"></a><b>Singly Linked Lists</b><br>
14<br>
<hr>
<a name="15"></a><b>Singly linked lists</b><br>
How do you remove a value from the middle of an array?<br>How would you do it in real life, e.g. in a long written list?<br>In real life, to add something at the middle of a long list what do you do?<br>How would you do it with arrays?<br>
Singly linked lists use pointers as links to the next element in the list.<br>
15<br>
<hr>
<a name="16"></a><b>Nodes in singly linked lists</b><br>
Each node contains a value and a pointer to the next node:<br>public class Node {<br>
public int info;<br>
info<br>
public Node next;<br>
next<br>
...<br>
}<br>
Node h;<br>
5<br>
8<br>
3<br>
null<br>
16<br>
<hr>
<a name="17"></a><b>A node implementation in a singly linked list</b><br>
public class Node {<br>
public int info;<br>public Node next;<br>
public Node(int i, Node n) {<br>
info = i; next = n;<br>
}<br>
public Node(int i) {<br>
this(i, null);<br>
}<br>
}<br>
17<br>
<hr>
<a name="18"></a><b>Adding elements at the head of a list</b><br>
Node h<br>
Node h = null;<br>
null<br>
Node h<br>
3<br>
h = new Node(3);<br>
null<br>
Node h<br>
h = new Node(8,h);<br>
8<br>
3<br>
null<br>
Node h<br>
h = new Node(5,h);<br>
5<br>
8<br>
3<br>
null<br>
18<br>
<hr>
<a name="19"></a><b>Adding elements at the tail</b><br>
Node h<br>
Node h = null;<br>
null<br>
Node h<br>
5<br>
h = new Node(5);<br>
null<br>
Node h<br>
h.next = new Node(8);<br>
5<br>
8<br>
null<br>
Node h<br>
h.next.next = new Node(3);<br>
5<br>
8<br>
3<br>
null<br>
19<br>
<hr>
<a name="20"></a><b>Pointers to the head and tail</b><br>
Adding elements at the tail is faster1 if we keep a  pointer to the last <br>element (if any). We define a new class to hold the head and tail pointers:<br>
SLList<br>Node head;<br>Node tail;<br>
5<br>
8<br>
3<br>
null<br>
1. Faster than adding elements at the tail while having only a pointer to the <br>head.<br>
20<br>
<hr>
<a name="21"></a><b>The singly linked list class</b><br>
public class SLList {<br>
private Node head = null;<br>private Node tail = null;<br>
public boolean isEmpty() {<br>
return head == null;<br>
}<br>
public void addToHead(int el) <br>
{...}<br>
public void addToTail(int el) { ... }<br>
public int deleteFromHead() {...}<br>
}<br>
21<br>
<hr>
<a name="22"></a><b>Special cases</b><br>
An empty list:<br>
SLList<br>Node head;<br>
null<br>
Node tail;<br>
null<br>
A list with one element:<br>
SLList<br>Node head;<br>Node tail;<br>
5<br>
null<br>
22<br>
<hr>
<a name="23"></a><b>What shouldn&apos;t happen in singly linked lists</b><br>
&#xFFFD; Loops<br>&#xFFFD; Errors with pointers, e.g.<br>
tail does not point to head.next. ... .next<br>
&#xFFFD; Tail node with non-null pointer<br>&#xFFFD; Non-tail node with null pointer<br>
23<br>
<hr>
<a name="24"></a><b>Operations in singly linked lists</b><br>
&#xFFFD; Adding an element at the head<br>&#xFFFD; Adding an element at the tail<br>&#xFFFD; Deleting the head element<br>&#xFFFD; Deleting the tail element<br>
24<br>
<hr>
<a name="25"></a><b>Adding an element at the head</b><br>
There are two cases:<br>
&#xFFFD; The list contains at least one element<br>
(so the tail stays the same)<br>
&#xFFFD; The list is empty (head = tail = nul )<br>
(we need to set the tail)<br>
public void addToHead(int el) {<br>
head = new Node(el, head);<br>if(tail == null)<br>
tail = head;<br>
}<br>
25<br>
<hr>
<a name="26"></a><b>Adding an element at the tail</b><br>
Two cases again:<br>
&#xFFFD; If the list is empty, we need to set the head<br>&#xFFFD; Otherwise, we need to set the pointer of the old tail<br>
public void addToTail(int el) {<br>
if (! isEmpty()) {<br>
tail.next = new Node(el);<br>tail = tail.next;<br>
}<br>else<br>
head = tail = new Node(el);<br>
}<br>
26<br>
<hr>
<a name="27"></a><b>Deleting the head element</b><br>
SLList<br>Node head;<br>Node tail;<br>
Just move the<br>head pointer:<br>
5<br>
8<br>
3<br>
null<br>
(Special case:<br>head == tail<br>
SLList<br>Node head;<br>
-&gt;<br>
Node tail;<br>
head = nul ;<br>tail = nul ;)<br>
5<br>
8<br>
3<br>
null<br>
27<br>
<hr>
<a name="28"></a><b>Deleting the head element (2)</b><br>
If the list has more than one element, change the head<br>Otherwise, make the list empty<br>
public int deleteFromHead() {<br>
int el = head.info;<br>if(head == tail) // one or no elements<br>
head = tail = null;<br>
else<br>
head = head.next;<br>
return el;<br>
}<br>
28<br>
<hr>
<a name="29"></a><b>Deleting the last element </b><br>
We need to set tail to the second last node<br>... but it&apos;s more easily said than done:<br>
if(head == tail) // one or no elements<br>
head = tail = null;<br>
else <br>
aux = sll.head<br>while (aux.next!=tail)<br>
aux = aux.next<br>
aux.next = null<br>sll.tail = aux<br>
29<br>
<hr>
<a name="30"></a><b>Traversing a list  </b><br>
1<br>
2<br>
3<br>
null<br>
Function printList()<br>aux = sll.head<br>While (aux! = null)<br>
print aux.info<br>aux = aux.next<br>
... so to traverse the list, iteratively (or recursively!) evaluate <br>the rest of the list (i.e., next)<br>
30<br>
<hr>
<a name="31"></a><b>Applications of singly linked lists  </b><br>
&#xFFFD; A list requires O(n) space<br>&#xFFFD; The operations we have defined each take O(1) time<br>&#xFFFD; Lists can represent the following ADTs:<br>
&#xFFFD; Stack uses <br>
&#xFFFD; for push  <br>&#xFFFD; for pop <br>
&#xFFFD; Queue uses<br>
&#xFFFD; for enqueue   <br>
&#xFFFD; for dequeue   <br>
&#xFFFD; Lists may also be used directly in many algorithms<br>&#xFFFD; Important high-level programming languages strongly rely on linked lists <br>
(e.g., Lisp)<br>
31<br>
<hr>
<a name="32"></a><b>Other uses?  </b><br>
It is possible to implement priority queues, stacks, queues and heaps using <br>linked lists. However, is this efficient?<br>
Let us have a closer look:<br>
&#xFFFD; priority queues: inserting a new element in a sorted singly linked list takes O(?)<br>&#xFFFD; heaps: searching a parent or child in a singly linked list is O(?)<br>
32<br>
<hr>
<a name="33"></a><b>Some observations</b><br>
&#xFFFD; Extensible arrays efficiently implement the Stack ADT, as well as the <br>
array operations, overhead for additional space<br>
&#xFFFD; Singly linked lists:<br>
&#xFFFD; efficiently implement the Stack and Queue ADTs, and have many other uses<br>&#xFFFD; can only move in one direction, accessing elements in the middle or rear part is <br>
difficult<br>
&#xFFFD; incur overhead for the pointers<br>
33<br>
<hr>
<a name="34"></a><b>Reading</b><br>
&#xFFFD; Weiss: Chapter 15 (Stacks and Queues), and section 16.1 and 16.2 <br>
(Linked Lists)  <br>
&#xFFFD; Drozdek: Sections 1.4 (Java and Pointers), 3.1 (Singly Linked Lists), 4.1 <br>
(Stacks) and 4.2 (Queues)  <br>
Next week: Circular lists and Doubly linked lists<br>
Drozdek: sections 3.2 (doubly linked lists) and 3.3 (circular lists) OR Weiss: <br>
section 16.3 (doubly linked lists and circular lists)<br>
34<br>
<hr>
<a name="35"></a>City, University of London<br>Northampton Square<br>London<br>EC1V 0HB<br>United Kingdom<br>
T: +44 (0)20 7040 8406<br>E: ug-compsci@city.ac.uk<br>www.city.ac.uk/department-computer-science<br>
35<br>
<hr>



<a name="1"></a><b>IN2002 Data Structures and Algorithms </b><br>
Lecture 5 &#xFFFD; Other Linked Lists<br>
Aravin Naren<br>Semester 1, 2018/19<br>
1<br>
<hr>
<a name="2"></a><b>Learning Objectives </b><br>
&#xFFFD; Understand and be able to use the data structures <br>circular lists and doubly linked lists<br>
&#xFFFD; Be able to understand, apply and develop <br>algorithms to handle the lists above. Including:<br>
&#xFFFD;Adding elements<br>
&#xFFFD;Deleting elements <br>
&#xFFFD;Traversing a list<br>
2<br>
<hr>
<a name="3"></a><b>Pointers and Linked Lists</b><br>
3<br>
<hr>
<a name="4"></a><b>Database Records</b><br>
All object variables in Java are actually pointers<br>
A pointer is a link to some object, i.e. a piece of memory:<br>
&#xFFFD; Links can be thought of as arrows, addresses or references<br>&#xFFFD; They point at an object that is somewhere in the system&apos;s <br>
memory<br>
4<br>
<hr>
<a name="5"></a><b>Links and their behaviour</b><br>
Links point at objects<br>
Node p;<br>
5<br>
8<br>
3<br>
Node q;<br>
null<br>
p is <br>q.info is <br>p.next is <br>q.next.info is <br>q.next.next is <br>p.next.next.info is <br>
5<br>
<hr>
<a name="6"></a><b>Links and their behaviour </b><br>
Links point at objects<br>
Node p;<br>
5<br>
8<br>
3<br>
Node q;<br>
null<br>
p.next = null;<br>
p = null; <br>
6<br>
<hr>
<a name="7"></a><b>Assigning to links</b><br>
r<br>
p<br>
5<br>
8<br>
3<br>
null<br>
q<br>
r<br>
p = null;<br>
p<br>
5<br>
8<br>
3<br>
7<br>
q<br>
<hr>
<a name="8"></a><b>Assigning to links</b><br>
r<br>
p<br>
5<br>
8<br>
3<br>
null<br>
q<br>
r<br>
p.next = null;<br>
p<br>
5<br>
8<br>
3<br>
q<br>
null<br>
8<br>
<hr>
<a name="9"></a><b>Assigning to links</b><br>
p<br>
5<br>
8<br>
3<br>
null<br>
q<br>
p.next = null;<br>
p<br>
5<br>
8<br>
3<br>
q<br>
9<br>
<hr>
<a name="10"></a><b>Evaluation of links</b><br>
p<br>
5<br>
8<br>
3<br>
null<br>
q<br>
r = q.next.next;<br>s = p.next;<br>
s<br>
r<br>
p<br>
5<br>
8<br>
3<br>
q<br>
10<br>
<hr>
<a name="11"></a><b>Singly linked lists</b><br>
Our implementation uses two types of objects:<br>
&#xFFFD;<i>SLList</i>, which has two components: <i>head </i>and <i>tail<br></i>&#xFFFD;<i>Node</i>, which has two components: <i>info </i>and <i>next</i><br>
<i>head</i>, <i>tail </i>and <i>next </i>are of type <i>Node</i>, so they contain links<br><i>info </i>is of the type of information elements you want to store<br>
11<br>
<hr>
<a name="12"></a><b>Traversing a singly linked list</b><br>
<i>Function printList():<br>node1  head of list<br>WHILE node1 is not nul</i><br>
<i>print value of node1<br>node1  next of node1</i><br>
... so to traverse the list, iteratively (or recursively!) <br>evaluate the rest of the list (i.e., use next)<br>
12<br>
<hr>
<a name="13"></a><b>Circular Lists</b><br>
13<br>
<hr>
<a name="14"></a><b>A Circular List</b><br>
CList<br>
We use object type <i>CList</i>, which has <br>
Node tail;<br>
one component: <i>tail</i><br>
The head is <i>tail.next</i><br>
5<br>
8<br>
3<br>
14<br>
<hr>
<a name="15"></a><b>Circular lists in Java</b><br>
public class CList {<br>
private Node tail = null;<br>
public boolean isEmpty() {<br>
return tail == null;<br>
}<br>
public void addToHead(int el) {...}<br>
public void addToTail(int el) {...}<br>
public int deleteFromHead () {...}<br>
15<br>
}<br>
<hr>
<a name="16"></a><b>Some special cases</b><br>
An empty list <br>
A list with one element<br>
CList<br>
CList<br>
Node tail;<br>
Node tail;<br>
null<br>
3<br>
16<br>
<hr>
<a name="17"></a><b>Adding at the head of a circular list </b><br>
17<br>
<hr>
<a name="18"></a><b>Adding at the head of a circular list... in Java </b><br>
Remember that head is really tail.next<br>
public void addToHead(int el) {<br>
if (isEmpty()) {<br>
// create a new node pointing at itself<br>tail = new Node(el);<br>tail.next = tail;<br>
} else { // update the head<br>
tail.next = new Node(el, tail.next);<br>
}<br>
}<br>
18<br>
<hr>
<a name="19"></a><b>Adding at the tail of a circular list </b><br>
19<br>
<hr>
<a name="20"></a><b>Adding at the tail of a circular list ... in Java</b><br>
public void addToTail(int el) {<br>
addToHead(el);<br>tail = tail.next;<br>
}<br>
20<br>
<hr>
<a name="21"></a><b>Deleting the head of a circular list </b><br>
21<br>
<hr>
<a name="22"></a><b>Deleting the head of a circular list ... in Java</b><br>
public int deleteFromHead() {<br>
int el = tail.next.info;<br>if (tail == tail.next)<br>
tail=null;<br>
else<br>
tail.next = tail.next.next;<br>
return el;<br>
}<br>
22<br>
<hr>
<a name="23"></a><b>Traversing a circular list</b><br>
23<br>
<hr>
<a name="24"></a><b>Traversing a circular list... in Java </b><br>
Consider that the end of the circular list is not marked by <i>null</i>, but by <i>tail</i>:<br>
public void printList() {<br>
if (! isEmpty()) {<br>
Node p = tail;<br>do {<br>
p = p.next;<br>System.out.println(p.info);<br>
} while (p != tail);<br>
}<br>
}<br>
24<br>
<hr>
<a name="25"></a><b>Example Analysis: Traversing a circular list </b><br>
public void printList() {<br>
if (! isEmpty()) {<br>
Node p = tail;<br>do {<br>
p = p.next;<br>System.out.println(p.info);<br>
} while (p != tail);<br>
}<br>
}<br>One loop. Execution starts after tail, and ends at tail. Therefore loop <br>executed once for each element. Running time is <i>O</i>(<i>n</i>).<br>Only Node p uses memory, none allocated in loop. Memory usage is <i>O</i>(1). <br>
25<br>
Both apply to best, worst, and average case.<br>
<hr>
<a name="26"></a><b>Analysis of circular lists</b><br>
They perform like singly linked lists:<br>
&#xFFFD; efficient support of the Stack and Queue ADTs<br>&#xFFFD; store n elements in O(n) space<br>&#xFFFD; all defined operations take O(1) time<br>&#xFFFD; cannot efficiently delete last element<br>&#xFFFD; can be traversed from head to tail, but not the other way around <br>
Applications: resource sharing, load balancing<br>
26<br>
<hr>
<a name="27"></a><b>Doubly Linked Lists</b><br>
27<br>
<hr>
<a name="28"></a><b>Doubly Linked Lists</b><br>
Each node has two pointers: one to its successor and<br>another to its predecessor<br>
DLList<br>head<br>tail<br>
8<br>
3<br>
5<br>
null<br>
null<br>
28<br>
<hr>
<a name="29"></a><b>A node in a doubly linked list </b><br>
public class DLLNode {<br>
public int info;<br>public DLLNode next, prev;<br>
public DLLNode(int i, DLLNode n, DLLNode p) {<br>
info = i; next = n; prev = p;<br>
}<br>
public DLLNode(int i) {<br>
this(i, null, null);<br>
}<br>
}<br>
29<br>
<hr>
<a name="30"></a><b>The doubly linked list class</b><br>
public class DLList {<br>
private DLLNode head = null;<br>private DLLNode tail = null;<br>
public boolean isEmpty() {<br>
return head == null;<br>
}<br>
public void addToHead(int el) {...}<br>public void addToTail(int el) {...}<br>public int deleteFromHead() {...}<br>public int deleteFromTail() {...}<br>
}<br>
30<br>
<hr>
<a name="31"></a><b>Adding an element at the tail</b><br>
Suppose we want to add an element 72 to the tail of the list<br>
DLList<br>head<br>tail<br>
8<br>
3<br>
5<br>
72<br>
null<br>
null<br>
31<br>
<hr>
<a name="32"></a><b>Adding an element at the tail (step 1):<br>create a new node and reset tail</b><br>
tail = new DLLNode(el, null, tail);<br>
DLList<br>head<br>tail<br>
8<br>
3<br>
5<br>
72<br>
null<br>
null<br>
null<br>
32<br>
<hr>
<a name="33"></a><b>Adding an element at the tail (step 2):<br>connect the node to the list</b><br>
tail.prev.next = tail;<br>
DLList<br>head<br>tail<br>
8<br>
3<br>
5<br>
72<br>
null<br>
null<br>
33<br>
<hr>
<a name="34"></a><b>Adding an element at the tail... in Java</b><br>
If the list is not empty, create and connect the node<br>Otherwise, just create a new node.<br>
public void addToTail(int el) {<br>
if (! isEmpty()) {<br>
tail = new DLLNode(el, null, tail);<br>tail.prev.next = tail;<br>
} else<br>
head = tail = new DLLNode(el);<br>
}<br>
34<br>
<hr>
<a name="35"></a><b>Deleting the last node</b><br>
DLList<br>head<br>tail<br>
8<br>
3<br>
5<br>
19<br>
null<br>
null<br>
35<br>
<hr>
<a name="36"></a><b>Deleting the last node (step 1):<br>move the tail pointer</b><br>
tail = tail.prev;<br>
DLList<br>head<br>tail<br>
8<br>
3<br>
5<br>
19<br>
null<br>
null<br>
36<br>
<hr>
<a name="37"></a><b>Deleting the last node (step 2):<br>disconnect the last node</b><br>
tail.next = null;<br>
DLList<br>head<br>tail<br>
8<br>
3<br>
5<br>
19<br>
null<br>
null<br>
null<br>
37<br>
<hr>
<a name="38"></a><b>Deleting the last node... in Java</b><br>
If the list has more than one node, move tail and disconnect last node. <br>Otherwise, empty the list<br>
public int deleteFromTail() {<br>
int el = tail.info;<br>if (head == tail)<br>
head = tail = null;<br>
else {<br>
tail = tail.prev;<br>tail.next = null;<br>
}<br>return el;<br>
}<br>
38<br>
<hr>
<a name="39"></a><b>Deleting any node</b><br>
If we wish to delete the node p points to<br>
DLList<br>head<br>
<b>p</b><br>
tail<br>
8<br>
3<br>
5<br>
12<br>
null<br>
39<br>
<hr>
<a name="40"></a><b>Deleting any node</b><br>
If we wish to delete the node p points to, we need to bridge over it:<br>p.next.prev = p.prev;<br>
DLList<br>
p.prev.next = p.next;<br>
head<br>
<b>p</b><br>
tail<br>
8<br>
3<br>
5<br>
12<br>
null<br>
We may also need to adjust head and/or tail.<br>
40<br>
<hr>
<a name="41"></a><b>Deleting any node... in Java</b><br>
public void delete(DLLNode p) {<br>
if (p.prev == null)<br>
head = p.next;<br>
else<br>
p.prev.next = p.next;<br>
if (p.next == null)<br>
tail = p.prev;<br>
else<br>
p.next.prev = p.prev;<br>
}<br>
What happens if it has only one node?<br>
41<br>
<hr>
<a name="42"></a><b>Traversing a doubly linked list... in Java</b><br>
It is just as easy to go in either direction:<br>
public void forwards() {<br>
for (DLLNode p = head; p != null; p = p.next)<br>
System.out.println(p.info);<br>
}<br>
public void backwards() {<br>
for (DLLNode p = tail; p != null; p = p.prev)<br>
System.out.println(p.info);<br>
}<br>
42<br>
<hr>
<a name="43"></a><b>Java Traversal Specialist Classes: Iterators</b><br>
Iterators encapsulate traversal. In Java defined in java.util<br>
interface Iterator&lt;E&gt; {<br>
boolean<br>
hasNext(); // Returns true if the<br>
// iteration has more elements.<br>
E next(); // Returns the next element in the <br>
// iteration.<br>
void  remove(); // Removes from the underlying<br>
// collection the last element returned by<br>// the iterator. <br>
}<br>
43<br>
<hr>
<a name="44"></a><b>Java Traversal Specialist Classes: ListIterators</b><br>
ListIterators support backwards traversal and addition.<br>
interface ListIterator&lt;E&gt; extends Iterator&lt;E&gt; {<br>
boolean<br>
hasPrevious(); // Returns true if the<br>
// iterator has further elements when traversing <br>// in reverse direction.<br>
E previous(); // Returns the previous element in <br>
// the list.<br>
void add(E e); // Inserts the specified element <br>
// into the list.<br>
... // more methods <br>
}<br>
44<br>
<hr>
<a name="45"></a><b>Reading</b><br>
&#xFFFD; Weiss: Section 16.3 (doubly linked lists and circular lists)  <br>
&#xFFFD; Drozdek: Sections 3.2 (doubly linked lists) and 3.3 (circular <br>
lists)  <br>
Next session (IN 2 WEEKS TIME): Hash tables<br>
Drozdek: Chapter 10 (Hashing) OR Weiss: Chapter 19 (Hash tables)<br>
45<br>
<hr>
<a name="46"></a>City, University of London<br>Northampton Square<br>London<br>EC1V 0HB<br>United Kingdom<br>
T: +44 (0)20 7040 8406<br>E: ug-compsci@city.ac.uk<br>www.city.ac.uk/department-computer-science<br>
46<br>
<hr>



<a name="1"></a><b>IN2002 Data Structures and Algorithms </b><br>
Lecture 6 &#xFFFD; Hash Tables<br>
Aravin Naren<br>Semester 1, 2018/19<br>
1<br>
<hr>
<a name="2"></a><b>Learning Objectives </b><br>
&#xFFFD; Understand and be able to use the data structures <br>set, tables and hash tables<br>
&#xFFFD; Be able to understand, apply and develop <br>algorithms to handle the data structures above. <br>Including:<br>
&#xFFFD;Store key-value pairs<br>
&#xFFFD;Retrieve values by key<br>
&#xFFFD;Delete key-value pairs<br>
2<br>
<hr>
<a name="3"></a><b>Sets</b><br>
3<br>
<hr>
<a name="4"></a><b>Sets</b><br>
Sets in maths are a collection of things, no matter in which <br>order.<br>Sets are the simplest case of a table, in which the key is the <br>value<br>
&#xFFFD; The set stores values<br>&#xFFFD; The set can receive new values and store them<br>&#xFFFD; The set al ows checking whether a value is stored<br>&#xFFFD; Values can be deleted from the set<br>
There are many ways of implementing sets<br>
4<br>
<hr>
<a name="5"></a><b>An abstract data type set</b><br>
public interface Set {<br>
// Add the key to the set<br>void insert(int key);<br>
// Is the key in the set?<br>boolean search(int key);<br>
// Delete the key from the set, if present<br>void delete(int key);<br>
}<br>
5<br>
<hr>
<a name="6"></a><b>Known set implementations</b><br>
Unordererd array:<br>
Unordered linked list:<br>
&#xFFFD; insert at the end: O(1)<br>
&#xFFFD; insert at head: O(1)<br>
&#xFFFD; (sequential) search: O(n)<br>
&#xFFFD; (sequential) search: O(n)<br>
&#xFFFD; delete and swap: O(1)<br>
&#xFFFD; delete: O(1)<br>
&#xFFFD; search and delete: O(n)<br>
&#xFFFD; search and delete: O(n)<br>
Ordered array:<br>&#xFFFD; insert in proper place: O(n)<br>&#xFFFD; binary search: O(log n)<br>&#xFFFD; delete and shift: O(n)<br>&#xFFFD; search and delete: O(n)<br>
6<br>
<hr>
<a name="7"></a><b>How can we do it faster ?</b><br>
Main problem: searching the right index.<br>
Takes long when using comparisons<br>
Idea: use <b>Hashing</b><br>
&#xFFFD; calculate the index from the key: gives constant time for finding <br>
the address.<br>
7<br>
<hr>
<a name="8"></a><b>Some more implementations of sets</b><br>
Times for various implementations:<br>
<b>insert </b><br>
<b>search  delete</b><br>
unordered array <br>
O(1) <br>
O(n) <br>
O(n)<br>
ordered array <br>
O(n) <br>
O(log n)  O(n)<br>
linked list <br>
O(1) <br>
O(n) <br>
O(n)<br>
simple tree (best)<br>
O(log n)  O(log n)  O(log n)<br>
(worst) <br>
O(n) <br>
O(n) <br>
O(n)<br>
balanced search tree<br>
O(log n)  O(log n)  O(log n)<br>
<b>hash table </b><br>
<b>O(1) </b><br>
<b>O(1) </b><br>
<b>O(1)</b><br>
8<br>
<hr>
<a name="9"></a><b>How to obtain O(1) in a set of integers?</b><br>
First approach:<br>&#xFFFD; take an array int array[max+1]; where max is the <br>
highest value to store<br>
&#xFFFD; initialise the values in the array to -1<br>&#xFFFD; store the values in slot index = key.<br>
E.g., array[24] = 24;<br>
9<br>
<hr>
<a name="10"></a><b>First approach...</b><br>
insertion of key takes O(1):<br>void insert(int key){ array1[key] = key;}<br>
search for key takes O(1):<br>boolean search(int key) {<br>
if( array1[key] != -1) return true;<br>else<br>
return false;<br>
}<br>
deletion of key takes O(1):<br>void delete(int key) { array1[key] = -1;}<br>
10<br>
<hr>
<a name="11"></a><b>Example</b><br>
Store 24, 31, 42 and 81 in set<br>
We get O(1), but:<br>
&#xFFFD; the maximum value (81) must be known when creating the array<br>
&#xFFFD; terribly wasteful (array of size 82 for 4 values!)<br>
11<br>
<hr>
<a name="12"></a><b>How to use less space</b><br>
Keep the index inside the array bounds.<br>
Remember the modulo operator ?<br>
index &lt;- (key mod length) + 1<br>
makes sure the key is inside the array <br>(Java, &apos;mod&apos; is &apos;%&apos; and &apos;+1&apos; is not needed)<br>
12<br>
<hr>
<a name="13"></a><b>Ideal case </b><br>
Store 24, 31, 42 and 81 in set:<br>&#xFFFD; Ideally, we could create int array2[4]; and <br>
store value in array2[value % 4]; still O(1)<br>
&#xFFFD; To search value, check at array2[key % 4]; still O(1)<br>&#xFFFD; To delete value, delete array2[key % 4]<br>
This is a <b>hash table</b><br>
13<br>
<hr>
<a name="14"></a><b>Tables (maps)</b><br>
14<br>
<hr>
<a name="15"></a><b>Tables (maps)</b><br>
In sets, the keys were the data.<br>More often we have indexed data:<br>
&#xFFFD; There are other data associated to the keys<br>&#xFFFD; Examples: dictionaries, phone books, price lists, tables of contents<br>
It must be possible to add/remove elements<br>Examples:<br>
&#xFFFD; files/databases in general<br>&#xFFFD; files in a drive<br>&#xFFFD; variables in memory<br>&#xFFFD; commands in a language<br>
15<br>
<hr>
<a name="16"></a><b>What is done in a table</b><br>
&#xFFFD; Data is stored as key-value pairs<br>&#xFFFD; Data is retrieved by key<br>
Implementations:<br>
&#xFFFD; ordered and unordered arrays<br>&#xFFFD; lists<br>&#xFFFD; hash tables<br>&#xFFFD; search trees<br>
16<br>
<hr>
<a name="17"></a><b>An abstract data type table</b><br>
public interface Table {<br>
// Set the value associated with the key<br>void store(Key key, Data value);<br>
// Search for the key, returning true if found<br>boolean search(Key key);<br>
// If the key exists, return the value<br>// associated with it<br>int getValue(Key key);<br>
// Delete the key-value, if present<br>void delete(Key key);<br>
}<br>
17<br>
<hr>
<a name="18"></a><b>The same example revisited </b><br>
Store 24, 31, 42 and 81 in set:<br>Ideally, we could create int array2[4]; and store<br>value in array2[key % 4]; still O(1)<br>
What if we want to store more values?<br>&#xFFFD; There is no more room in the array<br>
What if we want to store 82 instead of 81?<br>&#xFFFD; The fact that 82&gt;81 is not a problem<br>&#xFFFD; However, 82 mod 4 is 2, and array2[2] already contains a value: 42 (this is <br>
called a <b>collision</b>)<br>
18<br>
<hr>
<a name="19"></a><b>Handling collisions</b><br>
Solution to the problems above:<br>
&#xFFFD; produce an array that has a size equal or reasonably greater than the number of <br>
elements you will want to store<br>
&#xFFFD; handle collision using some suitable strategy<br>
19<br>
<hr>
<a name="20"></a><b>Hashing</b><br>
20<br>
<hr>
<a name="21"></a><b>Hashing</b><br>
A <b>hash function </b>calculates the <i>index </i>for a <i>key</i><br>
<i>index &lt;- hash(key) </i>e.g.,  <i>key mod len</i><br>
Ideally there should be one unique index for each key (<b>perfect hash <br>function</b>)<br>
&#xFFFD; Pro: there would be no collisions<br>&#xFFFD; Con: we may not have enough space<br>
21<br>
<hr>
<a name="22"></a><b>Avoiding collisions</b><br>
General strategy:<br>
&#xFFFD; Avoid collisions by distributing the keys uniformly over the addresses, <br>
even when there are patterns in the keys occurrence.<br>
Pattern examples:<br>
&#xFFFD; more small than large numbers<br>&#xFFFD; more even than odd numbers (or divisible by 4,10, ...)<br>
For modulo function: choose <i>len </i>prime<br>
22<br>
<hr>
<a name="23"></a><b>What when collisions occur?</b><br>
In case of collision, the possible strategies are to:<br>
&#xFFFD;store the value with the currently stored ones (buckets, closed <br>
hashing)<br>
&#xFFFD;look for another empty space and store the value there (open <br>
addressing, open hashing)<br>
&#xFFFD;modify the hashing function<br>
23<br>
<hr>
<a name="24"></a><b>Buckets</b><br>
The idea is to store duplicates together<br>
&#xFFFD;this could be done by using an array with pointers to arrays<br>&#xFFFD;address may be assigned to several keys<br>&#xFFFD;table of fixed size will overflow<br>
24<br>
<hr>
<a name="25"></a><b>A hash table with chaining</b><br>
&#xFFFD;Define the table as an array of objects of type Node,<br>&#xFFFD;and create linked lists when collisions occur<br>
null<br>
31<br>
81 null<br>
42<br>
22<br>
12<br>
32 null<br>
null<br>
24<br>
84<br>
4 null<br>
25<br>
<hr>
<a name="26"></a><b>A hash table class in Java</b><br>
class HashTable implements Set {<br>
private Node[] table;<br>
public HashTable(int size) {<br>
table = new Node[size];<br>
}<br>private int hash(int key) {<br>
return key%table.length;<br>
}<br>public void insert int key { ... }<br>public boolean search(int key) { ...}<br>public void delete(int key) { ... }<br>
26<br>
}<br>
<hr>
<a name="27"></a><b>Searching</b><br>
To search <i>key</i>, sequential search is performed in the linked list <i>table[hash(key)]</i><br>
null<br>
31<br>
81 null<br>
42<br>
22<br>
12<br>
32 null<br>
null<br>
24<br>
84<br>
4 null<br>
Search for 22, 6, 100<br>
27<br>
<hr>
<a name="28"></a><b>Searching</b><br>
To search <i>key</i>, sequential search is performed in the linked list <i>table[hash(key)]</i><br>
<i>Function search (key) :<br>p  table[hash(key)]<br>WHILE (p  null)</i><br>
<i>IF value of p = key THEN</i><br>
<i>Return key</i><br>
<i>p  next of p</i><br>
<i>Return null</i><br>
Insert and delete also work as with linked lists<br>
28<br>
<hr>
<a name="29"></a><b>Inserting  </b><br>
Insert 16, 25<br>
null<br>
31<br>
81 null<br>
42<br>
22<br>
12<br>
32 null<br>
null<br>
24<br>
84<br>
4 null<br>
29<br>
<hr>
<a name="30"></a><b>Deleting  </b><br>
Delete 81, 22, 31<br>
null<br>
31<br>
81 null<br>
42<br>
22<br>
12<br>
32 null<br>
null<br>
24<br>
84<br>
4 null<br>
30<br>
<hr>
<a name="31"></a><b>Analysis of hash table operations</b><br>
The cost of operations is proportional to <br>
<b>load factor = number of elements / size of table</b><br>
&#xFFFD; If we use a fixed table size, the cost of operations will be O(n), though with a very small <br>
constant factor<br>
&#xFFFD; If we keep the <b>load factor bounded</b>, the cost of operations will be <b>O(1)</b>. For this, the <br>
table would need to be extended when adding elements (remember extensible arrays).<br>
31<br>
<hr>
<a name="32"></a><b>Extending the hash table</b><br>
&#xFFFD; Simple scheme: create a new table, insert all the keys into it and discard the old one<br>&#xFFFD; Cost is proportional to the size of the table, say <i>cn</i>, so analysis is similar to extensible <br>
arrays<br>
&#xFFFD; If we <b>extend the table by doubling its size</b>, the cost of n insertions is at most<br>
<i>cn + cn/2 + cn/22 + ... + c = c (2n -1)        O(n)</i><br>
&#xFFFD; This yields an average, <b>amortised time of O(1) </b>per insertion<br>&#xFFFD; However, this cost is unevenly distributed<br>
32<br>
<hr>
<a name="33"></a><b>Hash functions</b><br>
&#xFFFD; Java has a method hashCode for every Object<br>&#xFFFD; A <b>uniform distribution of keys </b>is essential<br>&#xFFFD; Division modulo a prime number (or a number with no small factors) is simple <br>
and often works well<br>
&#xFFFD; More complex transformations may be more uniform<br>&#xFFFD; For strings, combine the characters in some way<br>
&#xFFFD; For example, method hashCode for  String s computes<br>
310 s[n-1]+ 311 s[n-2]+ ... +31n-2 s[1] + 31n-1 s[0]<br>
33<br>
<hr>
<a name="34"></a><b>Open addressing</b><br>
34<br>
<hr>
<a name="35"></a><b>An alternative: Open Addressing</b><br>
Idea: to <b>save the space used by the pointers</b>, put the overflowing <br>entries (collisions) into the same array.<br>
Need to define <b>probing </b>method for where to put and search <br>elements:<br>
&#xFFFD; <b>Linear probing</b>: place the key in the next free slot<br>&#xFFFD; <b>Quadratic probing<br></b>&#xFFFD; <b>Double hashing</b><br>
35<br>
<hr>
<a name="36"></a><b>Linear probing</b><br>
When inserting a key k:<br>
&#xFFFD; First try <i>h(k)<br></i>&#xFFFD; If that is used, try <i>(h(k) + 1) mod n</i>, <br>then <i>(h(k) + 2) mod n</i>, and so on<br>
On finding a free slot, place the key in it<br>
&#xFFFD; All locations in the array can be tried if necessary<br>&#xFFFD; Simple, but subject to clustering<br>
36<br>
<hr>
<a name="37"></a><b>Linear probing &#xFFFD; Insertion </b><br>
5 slots<br>Hash function h(n) = n%5<br>Insert 26, 3, 11<br>
37<br>
<hr>
<a name="38"></a><b>Hashing with linear probing</b><br>
public class Set {<br>
private static String[] table;<br>public Set (int size){ table=new String[size];}<br>public boolean search(String key) {<br>
for(int i = key.hashCode()%table.length;<br>
table[i] != null; i=(i+1)%table.length){<br>
if (table[i].equals(key))<br>
return true;<br>
}<br>return false;<br>
}<br>
38<br>
}<br>
<hr>
<a name="39"></a><b>Hashing with linear probing &#xFFFD; Search</b><br>
5 slots<br>Hash function h(n) = n%5<br>Search 26, 11, 5<br>
0<br>1 26<br>
2 11<br>
3 3<br>
4<br>
39<br>
<hr>
<a name="40"></a><b>Nearly full tables</b><br>
When the table is nearly ful , performance degrades sharply<br>
40<br>
<hr>
<a name="41"></a><b>Clustering caused by linear probing</b><br>
Overflowing addresses tend to group in a region of the array<br>
41<br>
<hr>
<a name="42"></a><b>Deleting elements</b><br>
Deletion requires creating a marker of deleted elements<br>
42<br>
<hr>
<a name="43"></a><b>Inserting after deleting elements...</b><br>
After the deletion above, insert 6<br>
43<br>
<hr>
<a name="44"></a><b>Quadratic probing</b><br>
Try <i>h(k) mod n</i>, <i>(h(k) <b>+ 12</b>) mod n</i>, <i>(h(k) <b>+ 22</b>) mod n</i>, <i>(h(k) <b>+ 32</b>) mod n</i>, and so on <br>until a free slot is found<br>
Probes i and j coincide if <i>n </i>divides i2 - j2 = (i - j)(i + j):<br>
&#xFFFD; If <i>n </i>is prime, this means <i>n </i>divides i - j or i + j, so i = j or i + j = n; so the sequence visits at <br>
least (n+1)/2 locations.<br>
&#xFFFD; (h(k) - 12) mod n, (h(k) - 22) mod n, and so on cover some of the other half (under some <br>
conditions al ).<br>
So it works better to try <i>h(k) mod n</i>, <i>(h(k) <b>+ 12</b>) mod n</i>, <i>(h(k) <b>-12</b>) mod n</i>,               <br><i>(h(k) <b>+ 22</b>) mod n</i>, <i>(h(k) <b>- 22</b>) mod n</i>, and so on.<br>
44<br>
<hr>
<a name="45"></a><b>Quadratic probing</b><br>
Now insert 6<br>
45<br>
<hr>
<a name="46"></a><b>Analysing quadratic probing</b><br>
&#xFFFD; <b>Keys that hash to different addresses probe different sequences of </b><br>
<b>addresses, eliminating primary clustering</b><br>
&#xFFFD; Keys that hash to the same address probe the same sequence of <br>
locations, so there is still secondary clustering, but this is less serious as <br>it is more distributed<br>
&#xFFFD; Ideally, to avoid secondary clustering, each probe should be different <br>
from those that came before<br>
&#xFFFD; An approximation to this is to use a second, independent hash function <br>
(double hashing)<br>
46<br>
<hr>
<a name="47"></a><b>Double hashing</b><br>
We need <b>two hash functions </b><i>h1 </i>and <i>h2</i>, such that <i>h2(k) </i>is never divisible <br>by <i>n </i>nor equal to 0<br>
&#xFFFD; Try locations <i>h1(k) mod n</i>, <i>(h1(k) + h2(k)) mod n</i>, <i>(h1(k) + 2 h2(k)) mod n</i>, <br>
and so on<br>
&#xFFFD; This eliminates both primary and secondary clustering, but hashing twice <br>
costs some time<br>
&#xFFFD; We could also use a quadratic version:<br>
&#xFFFD; <i>h1(k) mod n</i>, <i>(h1(k) + h2(k)12) mod n</i>, <i>(h1(k)+h2(k)22) mod n</i>, and so on<br>
47<br>
<hr>
<a name="48"></a><b>Double hashing example </b><br>
A good choice is to choose a prime p &lt; size and<br>h2(k) = p - (k % p)          (while h1(k) = k % n)<br>
7 slots; h1(k) = k%7; p=5; h2(k) = 5-(k%5)<br>
Insert 11, 18, 4<br>
Remember try:<br>h1(k) mod n; (h1(k) + h2(k)) mod n; (h1(k) + 2h2(k)) mod n<br>
48<br>
<hr>
<a name="49"></a><b>Times for successful search</b><br>
49<br>
<hr>
<a name="50"></a><b>Times for unsuccessful search</b><br>
50<br>
<hr>
<a name="51"></a><b>Table/set operations</b><br>
<b>Search</b>:<br>hash to initial index and then follow probe sequence until<br>
&#xFFFD; the key is found, success,<br>&#xFFFD; an empty location is reached, failure<br>
<b>Insert </b>is like search, but put the key in the empty location<br>
<b>Delete </b>is harder, as many probe sequences pass through a given location. <br>Solution: indicate deletion with a special value<br>
51<br>
<hr>
<a name="52"></a><b>Sets in Java</b><br>
There is a number of relevant interfaces and classes in the <br>package <b>java.util</b><br>
Interface <b>Set </b>defines a set ADT (extensive interface)<br>Implementations:<br>
&#xFFFD; <b>HashSet </b>(using a hash table)<br>&#xFFFD; <b>LinkedHashSet </b>(remembers insertion order)<br>
Interface <b>SortedSet </b>extends set ADT<br>Implementations:<br>
&#xFFFD; <b>TreeSet </b>(keeps keys sorted)<br>
52<br>
<hr>
<a name="53"></a><b>Tables and Hashing in Java</b><br>
There is a number of relevant interfaces and classes in the <br>package <b>java.util</b><br>
Interface <b>Map </b>defines a table ADT (extensive interface)<br>Implementations:<br>
&#xFFFD; <b>HashMap </b>(<b>Hashtable </b>old sync. version)<br>&#xFFFD; <b>IdentityHashMap </b>(test for reference-identical keys)<br>
Interface <b>SortedMap </b>extends a map ADT<br>Implementations:<br>
&#xFFFD; <b>TreeMap </b>(keeps keys sorted)<br>
53<br>
<hr>
<a name="54"></a><b>When to use Hashtables ?</b><br>
&#xFFFD; Hash tables have relatively low access times for large <br>
numbers of elements<br>
&#xFFFD; Hashing may be too expensive<br>&#xFFFD; For small collections, simple arrays can be better<br>&#xFFFD; May have high computing overhead when growing<br>&#xFFFD; Good when used for access by name (methods in compiler, <br>
telephone numbers in DB)<br>
&#xFFFD; HT do not know anything about order (except <br>
SortedMap/Set)<br>
54<br>
<hr>
<a name="55"></a><b>Reading</b><br>
&#xFFFD; Weiss: Chapter 19 (Hash tables)  <br>
&#xFFFD; Drozdek: Chapter 10 (Hashing)   <br>
Next session: Trees<br>
Drozdek: Sections 6.1 to 6.6 OR Weiss: Chapters 17 and 18.1-18.3<br>
55<br>
<hr>
<a name="56"></a>City, University of London<br>Northampton Square<br>London<br>EC1V 0HB<br>United Kingdom<br>
T: +44 (0)20 7040 8406<br>E: ug-compsci@city.ac.uk<br>www.city.ac.uk/department-computer-science<br>
56<br>
<hr>



<a name="1"></a><b>IN2002 Data Structures and Algorithms </b><br>
Lecture 7 &#xFFFD; Trees<br>
Aravin Naren<br>Semester 1, 2018/19<br>
1<br>
<hr>
<a name="2"></a><b>Learning Objectives </b><br>
&#xFFFD; Understand and be able to use the data structures <br>trees and binary search trees<br>
&#xFFFD; Be able to understand, apply and develop <br>algorithms to handle the data structures above. <br>Including:<br>
&#xFFFD;Access to keys in trees<br>
&#xFFFD;Inserting keys in trees<br>&#xFFFD;Delete keys from trees<br>
2<br>
<hr>
<a name="3"></a><b>Trees*</b><br>
* Seen in this module lecture 3<br>
3<br>
<hr>
<a name="4"></a><b>Trees</b><br>
&#xFFFD; Trees are useful for hierarchical systems:<br>
&#xFFFD; organisations<br>
&#xFFFD; geographical regions<br>
&#xFFFD; classes<br>&#xFFFD; language processing<br>
&#xFFFD; Artificial hierarchies can be created (e.g., heaps)<br>&#xFFFD; Because of branching, trees can hold many keys without <br>
having great height<br>
&#xFFFD; Recursive definition is often used<br>
4<br>
<hr>
<a name="5"></a><b>Tree terminology  (reminder)</b><br>
&#xFFFD; <b>Trees </b>are composed of nodes <br>and branches<br>&#xFFFD; <b>Nodes </b>contain a label (data) and <br>branches to other nodes<br>&#xFFFD; <b>Root </b>is the top node<br>&#xFFFD; <b>Leaves </b>are nodes that have no <br>branches deriving from them<br>
5<br>
<hr>
<a name="6"></a><b>More tree terminology  (reminder)</b><br>
&#xFFFD; The nodes n2,n3 at the end of a <br>
node n1&apos;s branches are its <br><b>children</b>, and n1 is the <b>parent </b>of <br>n2,n3.<br>
&#xFFFD; The root is thus a node with no <br>
parents.<br>
&#xFFFD; The leaves are nodes with no <br>
children.<br>
6<br>
<hr>
<a name="7"></a><b>Tree properties  (reminder)</b><br>
&#xFFFD; The tree&apos;s <b>height </b>is the number of <br>
edges on the longest downward <br>path between the root and a leaf<br>
&#xFFFD; The <b>depth </b>of a node is the <br>
number of edges from the node to <br>the tree&apos;s root node. It refers to <br>the distance to the root<br>
&#xFFFD; A node&apos;s <b>level </b>is its <b>depth + 1<br></b>&#xFFFD; A tree&apos;s <b>size </b>is the number of <br>
nodes it contains<br>
7<br>
Note that trees have no loops<br>
<hr>
<a name="8"></a><b>A well-known example</b><br>
Common file systems are <br>organised as trees.<br>
8<br>
<hr>
<a name="9"></a><b>Representation in Trees</b><br>
9<br>
<hr>
<a name="10"></a><b>Representation in trees</b><br>
Nodes represent things.<br>
Branches represent links between the nodes,<br>i.e., links between what nodes represent.<br>
All this information is implicit in the tree.<br>
10<br>
<hr>
<a name="11"></a><b>A &quot;pre-sorting&quot; tree</b><br>
&#xFFFD; This tree represents an abstract <br>
hierarchy: &quot;greater than&quot;<br>
&#xFFFD; Nodes represent numbers<br>&#xFFFD; Branches represent ordinality <br>
(&quot;greater than&quot;)<br>
&#xFFFD; Does this tree look familiar?<br>
11<br>
<hr>
<a name="12"></a><b>About tree algorithms</b><br>
&#xFFFD; Any node in the tree can be <br>
considered the root of a subtree<br>
&#xFFFD; This allows a recursive definition:<br>
<b>A tree is either empty or a tree-<br>node with a label (data) and <br>branches to other trees</b><br>
12<br>
<hr>
<a name="13"></a><b>Binary Trees</b><br>
13<br>
<hr>
<a name="14"></a><b>Building a binary tree</b><br>
&#xFFFD; <b>Binary tree:</b><br>
&#xFFFD; each node has at most two <br>
branches<br>
14<br>
<hr>
<a name="15"></a><b>Binary trees in Java</b><br>
public class TreeNode {<br>
public int key;<br>public TreeNode left, right;<br>
public TreeNode(int k, TreeNode l,TreeNode r) {<br>
key = k; left = l; right = r;<br>
}<br>
public TreeNode(int k) {<br>
this(k, null, null);<br>
}<br>
}<br>
15<br>
<hr>
<a name="16"></a><b>Building a binary tree</b><br>
TreeNode t =<br>
new TreeNode(5,<br>
new TreeNode(4),<br>new TreeNode(6, new TreeNode(7), null));<br>
16<br>
<hr>
<a name="17"></a><b>Recursion in trees</b><br>
Tree algorithms can be defined recursively, by evaluating the current tree and the <br>trees branching from it<br>
public int size(TreeNode t) {<br>
if (t == null)<br>
return 0;<br>
return size(t.left) + 1 + size(t.right);<br>
}<br>public int height(TreeNode t) {<br>
if (t == null)<br>
return 0;<br>
return 1 + Math.max(height(t.left), height(t.right));<br>
}<br>
17<br>
<hr>
<a name="18"></a><b>Tree Traversals</b><br>
18<br>
<hr>
<a name="19"></a><b>Tree traversals</b><br>
Many applications involve visiting the nodes in a certain order.<br>
Let&apos;s say we have procedure<br>void visit(TreeNode p);<br>which, for example, prints the node&apos;s label.<br>This can be done in different sequences.<br>
For simplicity, we will define the traversals for binary trees.<br>
19<br>
<hr>
<a name="20"></a><b>Depth First Traversals</b><br>
20<br>
<hr>
<a name="21"></a><b>Depth First Traversal</b><br>
&#xFFFD; Nodes are visited going as far as <br>
possible through the first branch<br>
&#xFFFD; Once a leaf is found, the <br>
algorithm backtracks until it can <br>find an unvisited branch<br>
21<br>
<hr>
<a name="22"></a><b>Recursive definition</b><br>
&#xFFFD; When a depth-first traversal is in a node, it must:<br>
&#xFFFD; <b>visit </b>that node, (V)<br>
&#xFFFD; traverse the <b>left </b>subtree (L)<br>
&#xFFFD; traverse the <b>right </b>subtree (R)<br>
&#xFFFD; However, this could be done in any order:<br>
&#xFFFD; if visit is done first (VLR), then it is a <b>preorder </b>traversal<br>
&#xFFFD; if visit is done in between (LVR), then it is <b>inorder </b>traversal<br>
&#xFFFD; if visit is done last (LRV), then it is <b>postorder </b>traversal<br>
22<br>
<hr>
<a name="23"></a><b>Preorder traversal</b><br>
The sequence is:<br>&#xFFFD; visit the current node first<br>&#xFFFD; traverse the left subtree<br>&#xFFFD; traverse the right subtree<br>
<i>Function preorder (node):<br>IF node  null THEN</i><br>
<i>visit node<br>preorder (left child of node)<br>preorder (right child of node)</i><br>
23<br>
<hr>
<a name="24"></a><b>... preorder traversal</b><br>
24<br>
<hr>
<a name="25"></a><b>(stack ADT)</b><br>
public interface Stack&lt;T&gt; {<br>
// Is the stack empty?<br>
boolean isEmpty();<br>
// Push one element onto the stack<br>void push(T elt);<br>
// Remove and return the most recently pushed<br>// element not already popped.<br>// Precondition: ! isEmpty()<br>T pop();<br>
}<br>
25<br>
<hr>
<a name="26"></a><b>... iterative preorder traversal </b><br>
The trick is to realise that the<br>preorder actually keeps a stack<br>
26<br>
<hr>
<a name="27"></a><b>... iterative preorder traversal</b><br>
void iterativePreorder(TreeNode p) {<br>
if (p != null){<br>
Stack&lt;TreeNode&gt; stack = new StackImpl&lt;TreeNode&gt;();<br>stack.push(p); // add root<br>do {<br>
p = stack.pop();<br>visit(p);  // visit after popping<br>if (p.right != null)<br>
stack.push(p.right); // push right<br>
if (p.left != null)<br>
stack.push(p.left); // push left<br>
} while (!stack.isEmpty()); // ready for next level<br>
}<br>
27<br>
}<br>
<hr>
<a name="28"></a><b>Inorder traversal</b><br>
The sequence is:<br>&#xFFFD; traverse the left subtree<br>&#xFFFD; visit the current node<br>&#xFFFD; traverse the right subtree<br>
<i>Function inorder (node):<br>IF node  null THEN</i><br>
<i>inorder (left child of node)<br>visit node<br>inorder (right child of node)</i><br>
28<br>
<hr>
<a name="29"></a><b>... inorder traversal</b><br>
29<br>
<hr>
<a name="30"></a><b>... iterative inorder traversal</b><br>
void iterativeInorder(TreeNode p) {<br>
Stack&lt;TreeNode&gt; stack = new StackImpl&lt;TreeNode&gt;();<br>for(;;) {<br>
while (p != null) { // go as far as<br>
stack.push(p);   // possible down<br>p = p.left;      // on the left side<br>
}<br>if (stack.isEmpty())<br>
break;    // stop when stack is empty<br>
p = stack.pop();    // leftmost unvisited node<br>visit(p);    // visit<br>p = p.right;    // continue on right side<br>
}<br>
30<br>
}<br>
<hr>
<a name="31"></a><b>... iterative inorder traversal</b><br>
31<br>
<hr>
<a name="32"></a><b>Postorder traversal</b><br>
The sequence is:<br>&#xFFFD; traverse the left subtree<br>&#xFFFD; traverse the right subtree<br>&#xFFFD; visit the node<br>
<i>Function postorder (node):<br>IF node  null THEN</i><br>
<i>postorder (left child of node)<br>postorder (right child of node)<br>visit node</i><br>
32<br>
<hr>
<a name="33"></a><b>... postorder traversal</b><br>
33<br>
<hr>
<a name="34"></a><b>Iterative postorder traversal</b><br>
We only store the parent <br>nodes, not the current <br>ones.<br>
We need to store with the <br>nodes information on <br>whether we are traversing <br>the left or right branch.<br>
34<br>
<hr>
<a name="35"></a><b>Analysis</b><br>
&#xFFFD; In all cases the memory complexity equals the depth of the tree.<br>&#xFFFD; In balanced binary trees the depth is O(log n), and so is the <br>
memory complexity.<br>
&#xFFFD; This memory complexity occurs in the recursion stack and in the <br>
explicit stack. The recursive  algorithm is simpler than the iterative <br>one.<br>
&#xFFFD; The choice of pre/in/post-order depends on how interested you are <br>
in the nodes that are not leaves<br>
35<br>
<hr>
<a name="36"></a><b>Breadth First Traversals</b><br>
36<br>
<hr>
<a name="37"></a><b>Breadth First Traversal</b><br>
If you are not so interested in leaves,<br>you may want to visit the nodes closer<br>to the root first (also cal ed level-order).<br>In this case, you traverse the tree by<br>levels:<br>&#xFFFD; Use a queue of nodes<br>&#xFFFD; The queue contains initially the root <br>
only<br>
&#xFFFD; Until the queue is empty,<br>
&#xFFFD; Remove and visit the first node in the <br>
queue<br>
&#xFFFD; Add its children at the back of the queue<br>
37<br>
<hr>
<a name="38"></a><b>Stepping through the breadth-first traversal</b><br>
38<br>
<hr>
<a name="39"></a><b>The queue after visiting node 4</b><br>
39<br>
<hr>
<a name="40"></a><b>The queue after visiting node 5</b><br>
40<br>
<hr>
<a name="41"></a><b>(queue ADT)</b><br>
As with stacks, the Queue interface can be used directly:<br>
public interface Queue&lt;T&gt; {<br>
boolean isEmpty();<br>void enqueue(T elt);<br>T dequeue();<br>
}<br>
41<br>
<hr>
<a name="42"></a><b>Breadth-first traversal &#xFFFD; Java</b><br>
void breadthFirst(TreeNode p) {<br>
if (p != null){<br>
Queue&lt;TreeNode&gt; queue = new QueueImpl&lt;TreeNode&gt;();<br>queue.enqueue(p); // add root<br>while (!queue.isEmpty()) {<br>
p = queue.dequeue(); // remove<br>visit(p); // visit<br>if (p.left != null) // add left child<br>
queue.enqueue(p.left);<br>
if (p.right != null) // add right child<br>
queue.enqueue(p.right);<br>
}<br>
}<br>
42<br>
}<br>
<hr>
<a name="43"></a><b>Analysis of breadth-first</b><br>
&#xFFFD; The queue will contain at any one time the rest of the current level and part of <br>
the next level<br>
&#xFFFD; The queue will be at its largest at the level with the most nodes<br>&#xFFFD; In a binary, perfectly balanced tree, this will occur at the lowest level. The size <br>
would be of O(n).<br>
43<br>
<hr>
<a name="44"></a><b>Binary Search Trees</b><br>
44<br>
<hr>
<a name="45"></a><b>What if trees pre-sort (in some way)?</b><br>
The search could concentrate<br>in sections of the tree,<br>gaining some time:<br>On average, O(log n) can<br>be obtained<br>
The worst cases can be<br>kept close to O(log n)<br>as well, so long as the<br>tree is close to balanced<br>
45<br>
<hr>
<a name="46"></a><b>Binary Search Trees</b><br>
e.g. look for 5:<br>
5&lt;8, go left<br>5&gt;3, go right<br>5&lt;6, go left<br>5&gt;4, go right<br>5=5, found it!<br>
46<br>
<hr>
<a name="47"></a><b>What do branches represent?</b><br>
Branches represent <b>ordering</b>:<br>
Any key in the left subtree is lower than the parent&apos;s key<br>Any key in the right subtree is larger than the parent&apos;s key<br>... so no keys can be repeated<br>
<b>Inorder </b>traversal produces an ordered sequence<br>Most operations visit only one <b>single path </b>down from the root.<br>If the tree is reasonably balanced, this takes O(log n)<br>
47<br>
<hr>
<a name="48"></a><b>Search trees as sets</b><br>
public class Tree implements Set {<br>
private TreeNode root = null;<br>
// Is the element in the tree?<br>public boolean search(int el) { .... }<br>
// Add the element to the tree<br>public void insert(int el) { ... }<br>
// Remove the element from the tree<br>public void delete(int el) { ... }<br>
48<br>
}<br>
<hr>
<a name="49"></a><b>Searching a binary search tree</b><br>
public boolean search(int el) {<br>
TreeNode p = root;<br>while (p != null) {<br>
if (el == p.key)<br>
Does this remind you of <br>
return true;<br>
some other algorithm?<br>
if (el &lt; p.key)<br>
p = p.left;<br>
else if (el &gt; p.key)<br>
p = p.right;<br>
}<br>return false;<br>
49<br>
}<br>
<hr>
<a name="50"></a><b>Inserting a key into a search tree</b><br>
Search for the key<br>
If the key is present, do nothing<br>
Otherwise, replace the null pointer you found at the end of <br>the search with a new node containing the key<br>
(this requires a pointer to the parent node!)<br>
50<br>
<hr>
<a name="51"></a><b>Insertion example</b><br>
18<br>
Insert 16, 9, 1, 32<br>
17<br>
29<br>
15<br>
25<br>
36<br>
51<br>
<hr>
<a name="52"></a><b>Insertion: Java code</b><br>
public void insert(int el) {<br>
if (root == null)  // the tree is empty<br>
root = new TreeNode(el);<br>
else {<br>
TreeNode prev, p = root;<br>do {<br>
if (el == p.key) return;  // node present<br>prev = p;<br>
// remember parent<br>
if (el &lt; p.key) p = p.left;<br>else p = p.right;<br>
} while (p != null);  // until leaf found<br>if (el &lt; prev.key)  // determine left/right<br>
prev.left = new TreeNode(el);<br>
else<br>
prev.right = new TreeNode(el);<br>
}<br>
52<br>
}<br>
<hr>
<a name="53"></a><b>Deletion</b><br>
p<br>
First find the node containing<br>
x<br>
the key to be deleted.<br>
If both its children are nul ,<br>we just delete it from its parent.<br>
If one child is nul , we can<br>simply delete the node and<br>replace it with its non-null child.<br>
p<br>
53<br>
<hr>
<a name="54"></a><b>Deletion example</b><br>
18<br>
17<br>
29<br>
Delete 9 and 32<br>
15<br>
25<br>
36<br>
9<br>
16<br>
32<br>
54<br>
<hr>
<a name="55"></a><b>Deletion example</b><br>
18<br>
17<br>
29<br>
Delete 36, 16 and 15<br>
15<br>
25<br>
36<br>
9<br>
16<br>
32<br>
55<br>
<hr>
<a name="56"></a>p<br>
x<br>
delete<br>
<b>Deletion (cntd.)</b><br>
If neither child is nul , replace  <br>
s<br>
node (x) with its direct successor<br>(s), which is the left-most node in the <br>right subtree. This can be easily <br>removed as it has at most one child <br>(see previous slide) .<br>
p<br>
Alternatively, its direct predecessor<br>
s<br>
can also be used.<br>In either case it may make the<br>tree unbalanced.<br>
56<br>
<hr>
<a name="57"></a><b>Deletion example</b><br>
18<br>
Delete 15 and 18<br>
17<br>
29<br>
15<br>
25<br>
36<br>
9<br>
16<br>
32<br>
57<br>
<hr>
<a name="58"></a><b>Analysis of binary search trees</b><br>
&#xFFFD; Search, delete and insert have the height of the tree as the worst case for running <br>
time.<br>
&#xFFFD; Search, delete and insert take <i>O(log n), </i>where <i>n </i>is the number of nodes in the <br>
tree, if the tree is close to perfectly balanced.<br>
&#xFFFD; Otherwise, they can be as bad as <i>O(n)<br></i>&#xFFFD; <b>Problem</b>: insertion and deletion make the tree less balanced.<br>&#xFFFD; <b>Solution</b>: keep the tree approximately balanced, without making insertion and <br>
deletion too expensive<br>
58<br>
<hr>
<a name="59"></a><b>Reading</b><br>
&#xFFFD; Weiss: Chapters 17 and 18.1-18.3  <br>
&#xFFFD; Drozdek: Sections 6.1 to 6.6   <br>
Next session: Advanced Trees<br>
Drozdek: Sections 6.7, 6.8, and 7.1.1 OR Weiss: Sections 18.4, 18.8, <br>
21.1-21.3, 21.5-21.7<br>
59<br>
<hr>
<a name="60"></a>City, University of London<br>Northampton Square<br>London<br>EC1V 0HB<br>United Kingdom<br>
T: +44 (0)20 7040 8406<br>E: ug-compsci@city.ac.uk<br>www.city.ac.uk/department-computer-science<br>
60<br>
<hr>



<a name="1"></a><b>IN2002 Data Structures and Algorithms </b><br>
Lecture 8 &#xFFFD; Advanced Trees<br>
Aravin Naren<br>Semester 1, 2018/19<br>
1<br>
<hr>
<a name="2"></a><b>Learning Objectives </b><br>
&#xFFFD; Understand and be able to use the data structures <br>binary search trees, splay trees and B-trees<br>
&#xFFFD; Be able to understand, apply and develop <br>algorithms to handle the data structures above. <br>Including:<br>
&#xFFFD;Access to keys in trees<br>
&#xFFFD;Balancing trees<br>
&#xFFFD;Adjusting trees<br>
2<br>
<hr>
<a name="3"></a><b>Balanced Trees</b><br>
3<br>
<hr>
<a name="4"></a><b>Remember...Analysis of binary search trees</b><br>
&#xFFFD; Search, delete and insert have the height of the tree as the <br>
worst case for running time.<br>
&#xFFFD; Search, delete and insert take <i>O(log n), </i>where <i>n </i>is the <br>
number of nodes in the tree, if the tree is close to perfectly <br>balanced.<br>
&#xFFFD; Otherwise, they can be as bad as <i>O(n)<br></i>&#xFFFD; <b>Problem</b>: insertion and deletion make the tree less <br>
balanced.<br>
&#xFFFD; <b>Solution</b>: keep the tree approximately balanced, without <br>
making insertion and deletion too expensive<br>
4<br>
<hr>
<a name="5"></a><b>The importance of trees being balanced</b><br>
&#xFFFD; To access a node in a binary search tree, the path is visited <br>
from the root to the node.<br>
&#xFFFD; This means that the maximum number of nodes visited is <br>
equal to the height of the tree.<br>
&#xFFFD; In a perfectly balanced tree, this is log(n)+1.<br>
5<br>
<hr>
<a name="6"></a><b>A not-so-balanced tree</b><br>
&#xFFFD; The maximum number of levels of a tree with <i>n </i>node is <i>n</i>.<br>
6<br>
<hr>
<a name="7"></a><b>Should the tree be kept balanced?</b><br>
The <b>height <i>h </i>of the tree </b>will be between <b>log(<i>n</i>)+1 and <i>n</i></b>, <br>so the time complexity of access to the tree will be between <br>O(log n) and O(n)<br>
Ideally, the tree should be kept <b>perfectly balanced</b>, with <br><b><i>h </i>= log (<i>n</i>) + 1</b>. Doing this after insertion or deletion takes <br>O(n) time, which defeats the purpose of efficiency.<br>
Solution: keep the tree balanced enough to obtain O(log n) <br>height.<br>
7<br>
<hr>
<a name="8"></a><b>Some approximate balance definitions</b><br>
<b>Weight-balanced trees</b>:<br>each node has 1/k &lt;= <i>size(right)/size(left) </i>&lt;= k<br><b>AVL trees </b>(height-balanced):<br>each node has  -1 &lt;= <i>height(right) - height(left) </i>&lt;= 1<br>
(AVL-balance)<br>
<b>Red-Black trees</b>: each node is either red or black, and no red <br>node can have a red child.<br>Each full path from the root contains the same number of <br>black nodes.<br>
8<br>
<hr>
<a name="9"></a><b>Balancing Trees</b><br>
9<br>
<hr>
<a name="10"></a><b>Tree Rotations</b><br>
&#xFFFD; Rotation is a basic operation in <br>
many tree re-balancing schemes<br>
&#xFFFD; Rotations keep the search tree <br>
structure<br>
&#xFFFD; Rotations can be applied <br>
anywhere in the tree<br>
10<br>
<hr>
<a name="11"></a><b>Tree Rotation in Java</b><br>
public TreeNode rotateLeft(TreeNode oldRoot) {<br>
TreeNode newRoot = oldRoot.getRight();<br>if(newRoot != null){<br>
oldRoot.setRight(newRoot.getLeft());<br>newRoot.setLeft(oldRoot);<br>
}<br>
oldRoot<br>
newRoot<br>
return newRoot;<br>// needs to checked<br>// by caller<br>
A newRoot<br>
oldRoot<br>
C<br>
}<br>
11<br>
B<br>
C<br>
A<br>
B<br>
<hr>
<a name="12"></a><b>Left and Right Tree Rotations</b><br>
&#xFFFD; Rotations can be applied in two directions<br>
12<br>
<hr>
<a name="13"></a><b>Left Tree Rotation Example </b><br>
18<br>
17<br>
29<br>
15<br>
25<br>
36<br>
9<br>
16<br>
32<br>
13<br>
<hr>
<a name="14"></a><b>Right Tree Rotation Example </b><br>
18<br>
17<br>
29<br>
15<br>
25<br>
36<br>
9<br>
16<br>
32<br>
14<br>
<hr>
<a name="15"></a><b>Re-balancing an AVL tree</b><br>
If insertion invalidates the AVL condition (-1 &lt;= <i>height(right) - height(left) <br></i>&lt;= 1), use rotations to restore it:<br>&#xFFFD; For insertion, at most two O(1) rotations are required (but finding the <br>
position still takes O(log n) )<br>
&#xFFFD; Deletions may require rotating any nodes in the path to the changed <br>
node, O(log n)<br>
&#xFFFD; No re-balancing at lookup-only access<br>
15<br>
<hr>
<a name="16"></a><b>Rebalancing by Single Rotation</b><br>
If root has AVL-balance &lt; -1 or AVL-balance &gt; 1 and<br>child balance on higher subtree side has same sign or is 0<br>
+2<br>
0<br>
s<br>
t<br>
+1<br>
0<br>
y<br>t<br>
s<br>
x<br>u<br>
A<br>
x<br>
u<br>
B<br>
A<br>
B<br>
C<br>
16<br>
C<br>
<hr>
<a name="17"></a><b>Rebalancing by Single Rotation Example </b><br>
18<br>
17<br>
29<br>
15<br>
9<br>
16<br>
17<br>
<hr>
<a name="18"></a><b>Rebalancing by Double Rotation</b><br>
If root has AVL-balance &lt; -1 or AVL-balance &gt; 1 and<br>higher subtree side child AVL-balance has opposite sign<br>
+2<br>
+2<br>
0<br>
s<br>
x<br>s<br>
t<br>
-1<br>
+1<br>
u<br>
y<br>t<br>
s<br>
x<br>u<br>
A<br>
A<br>
0<br>
0<br>
t<br>
z<br>u<br>
D<br>
A<br>
B<br>
C<br>
D<br>
B<br>
18<br>
B<br>
C<br>
C<br>
D<br>
C<br>
<hr>
<a name="19"></a><b>Rebalancing by Double Rotation Example </b><br>
18<br>
7<br>
29<br>
15<br>
9<br>
16<br>
19<br>
<hr>
<a name="20"></a><b>AVL Tree Rebalancing Animation</b><br>
&#xFFFD; Inserting 12, 23, 200, 17, 15, 20, 18<br>&#xFFFD; Then deleting 15, etc.<br>
AVL Tree<br>
20<br>
<hr>
<a name="21"></a><b>Splay Trees</b><br>
21<br>
<hr>
<a name="22"></a><b>Splay Trees</b><br>
&#xFFFD; A splay tree rearranges itself after each access<br>&#xFFFD; Moves the accessed node to root (splay operation)<br>&#xFFFD; Frequently accessed keys get closer to the root<br>&#xFFFD; No need for additional information to be stored<br>
22<br>
<hr>
<a name="23"></a><b>Splay step operations</b><br>
There are three cases (plus a symmetric one), and maximally two rotations <br>per splay:<br>&#xFFFD; Until accessed node is the root:<br>&#xFFFD; If the accessed node&apos;s parent is the root (zig), rotate the accessed node <br>
up.<br>
&#xFFFD; If the accessed node is a left child and its parent is a left child as well <br>
(zig-zig), rotate the parent up and then rotate the accessed node up.*<br>
&#xFFFD; Otherwise (zig-zag), rotate to the accessed node up twice (standard <br>
double rotation).<br>
* Also applies to right child and right child<br>
23<br>
<hr>
<a name="24"></a><b>An example splay operation </b><br>
After accessing 6, repeatedly apply splay(6):<br>
1<br>
2<br>
3<br>
4<br>
5<br>
zig-zig<br>
6<br>
24<br>
<hr>
<a name="25"></a><b>Example splay (cntd.)</b><br>
6<br>
1<br>
1<br>
6<br>
3<br>
3<br>
2<br>
5<br>
2<br>
5<br>
4<br>
4<br>
zig<br>
After the third splay, 6 is at the <br>root of the tree.<br>
25<br>
<hr>
<a name="26"></a><b>Example splay zig zag</b><br>
After accessing 4, repeatedly apply splay(4):<br>
6<br>
6<br>
1<br>
1<br>
3<br>
4<br>
2<br>
5<br>
3<br>
5<br>
4<br>
2<br>
zig-zag<br>
zig-zag<br>
26<br>
<hr>
<a name="27"></a><b>Example splay zig zag (cntd.)</b><br>
4<br>
1<br>
6<br>
3<br>
5<br>
2<br>
After the second splay, 4 is at the root of the tree. <br>Note that 6 is still closer to the root than initially.<br>
27<br>
<hr>
<a name="28"></a><b>Splay trees are self-organising</b><br>
There are three cases (plus a symmetric one), and maximally two rotations <br>per splay:<br>&#xFFFD; Until accessed node is the root:<br>&#xFFFD; If the accessed node&apos;s parent is the root (zig), rotate the accessed node <br>
up.<br>
&#xFFFD; If the accessed node is a left child and its parent is a left child as well <br>
(zig-zig), rotate the parent up and then rotate the accessed node up.*<br>
&#xFFFD; Otherwise (zig-zag), rotate to the accessed node up twice (standard <br>
double rotation).<br>
* Also applies to right child and right child<br>
28<br>
<hr>
<a name="29"></a><b>Splay Tree Animation</b><br>
&#xFFFD; Inserting 1, 2, 3, 4, 5, 6<br>&#xFFFD; Then finding 1, 4, etc.<br>&#xFFFD; Then deleting ...<br>
Splay tree<br>
29<br>
<hr>
<a name="30"></a><b>Multi-Way Search Trees</b><br>
30<br>
<hr>
<a name="31"></a><b>Multi-way search trees</b><br>
Each node has <i>m </i>subtrees, interleaved with <i>m-1 </i>keys stored in ascending <br>order<br>
All keys in subtrees to the left of key <i>k </i>are smaller than <i>k<br></i>All keys in subtrees to the right of key <i>k </i>are greater<br>Large <i>m </i>is useful for external storage (hard disk)<br>Small <i>m </i>is better for internal storage (RAM)<br>... and binary search trees are multi-way trees with <i>m = 2</i><br>
31<br>
<hr>
<a name="32"></a><b>B-Trees</b><br>
A B-tree of order <i>m </i>is a multi-way search tree for which:<br>&#xFFFD; the root has at least one key<br>&#xFFFD; every non-root node has <i>k </i>subtrees and <i>k-1 </i>keys with  <i>m/2 + 1 &lt;= k &lt;= m<br></i>&#xFFFD; leaves have all subtrees empty<br>&#xFFFD; non-leaf nodes have non-empty subtrees<br>&#xFFFD; all leaves are at the same level<br>The last condition guarantees that B-trees are approximately balanced.<br>For hard disk storage, one node is one HD block. <br>
32<br>
<hr>
<a name="33"></a><b>A B-tree of order 4 and height 3</b><br>
50<br>
10 23 32<br>
68 80<br>
6 8<br>
16 18<br>
24 27<br>
34 38 45<br>
54 62<br>
70 76<br>
81 92<br>
33<br>
<hr>
<a name="34"></a><b>Insertion into a B-tree</b><br>
Always insert new keys into a leaf<br>If the node overflows, split it:<br>
&#xFFFD; where k is the middle key of the overflowed node<br>&#xFFFD; if the parent node overflows, repeat<br>&#xFFFD; it the root overflows, create a new root on top and split<br>
34<br>
<hr>
<a name="35"></a><b>Insertion into a B-tree Example</b><br>
Insert 83 then 90<br>
50<br>
10 23 32<br>
68 80<br>
6 8<br>
16 18<br>
24 27<br>
34 38 45<br>
54 62<br>
70 76<br>
81 92<br>
35<br>
<hr>
<a name="36"></a><b>Insertion into a B-tree Example (cntd.)</b><br>
Insert 83 (then 90) <br>
50<br>
10 23 32<br>
68 80<br>
6 8<br>
16 18<br>
24 27<br>
34 38 45<br>
54 62<br>
70 76<br>
81 83 92<br>
36<br>
<hr>
<a name="37"></a><b>Insertion into a B-tree Example (cntd.)</b><br>
Insert 90<br>
50<br>
10 23 32<br>
68 80 83<br>
6 8<br>
16 18<br>
24 27<br>
34 38 45 54 62<br>
70 76<br>
81<br>
90 92<br>
37<br>
<hr>
<a name="38"></a><b>Deletion from a B-tree</b><br>
&#xFFFD; If the key to be deleted is in a non-leaf node, swap it with a neighbouring <br>
key in a leaf and delete it<br>
&#xFFFD; If deletion leaves a node half empty, redistribute keys with a sibling node<br>&#xFFFD; If sibling node is only half full, combine with it (reverse of splitting)<br>&#xFFFD; If the root node ends up with no keys and one pointer, its child becomes <br>
the new root<br>
38<br>
<hr>
<a name="39"></a><b>B-Tree Animation</b><br>
&#xFFFD; Inserting ...<br>&#xFFFD; Then finding ...<br>&#xFFFD; Then deleting ...<br>
B-Tree<br>
39<br>
<hr>
<a name="40"></a><b>Reading</b><br>
&#xFFFD; Weiss: Sections 18.4, 18.8, 21.1-21.3, 21.5-21.7<br>
&#xFFFD; Drozdek: Sections 6.7, 6.8, and 7.1.1   <br>
Next session: Graphs<br>
Drozdek: Sections 8.1, 8.2 and 8.3 OR Weiss: Sections 13.1-13.4<br>
40<br>
<hr>
<a name="41"></a>City, University of London<br>Northampton Square<br>London<br>EC1V 0HB<br>United Kingdom<br>
T: +44 (0)20 7040 8406<br>E: ug-compsci@city.ac.uk<br>www.city.ac.uk/department-computer-science<br>
41<br>
<hr>



<a name="1"></a><b>IN2002 Data Structures and Algorithms </b><br>
Lecture 9 (10 last week) &#xFFFD; Graphs<br>
Aravin Naren<br>Semester 1, 2018/19<br>
1<br>
<hr>
<a name="2"></a><b>Learning Objectives </b><br>
&#xFFFD; Understand and be able to use the data structures <br>graphs<br>
&#xFFFD; Be able to understand, apply and develop <br>algorithms to handle graphs. Including:<br>
&#xFFFD;Traversals<br>
&#xFFFD;Shortest paths<br>
2<br>
<hr>
<a name="3"></a><b>Trees and Graphs</b><br>
3<br>
<hr>
<a name="4"></a><b>Trees and graphs</b><br>
&#xFFFD; Trees represent a set of elements and their relations.<br>&#xFFFD; Each element is stored in a node.<br>&#xFFFD; Relations go from parent to child nodes.<br>&#xFFFD; A node can have at most one parent.<br>
&#xFFFD; Graphs extend the idea by removing the parent-child <br>
restriction.<br>
4<br>
<hr>
<a name="5"></a><b>Nodes and links between nodes</b><br>
&#xFFFD; In heaps, the links represent the fact that child nodes have <br>
lower values than their parents.<br>
In binary search trees, left links represent the fact that <br>all values in the left subtree are less than its parent,<br>and all values in the right subtree are greater than it.<br>
&#xFFFD; The value of a node and the knowledge of what its branches <br>
represent allows guiding algorithms.<br>
5<br>
<hr>
<a name="6"></a><b>Non-hierarchical relations</b><br>
&#xFFFD; Trees al ow a node only to have one parent.<br>&#xFFFD; Nodes may be related in the same way to different parent <br>
nodes (e.g. family tree, web pages).<br>
&#xFFFD; A situation associated with this are loops, which usual y <br>
breaks tree algorithms.<br>
&#xFFFD; Graphs provide a more general structure.<br>
6<br>
<hr>
<a name="7"></a><b>Graphs</b><br>
Graphs al ow the connection of any node to any other node<br>
Think of maps, dependencies, relationships, flow networks, <br>etc.<br>
Algorithms to treat graphs vary, and often work by deriving a <br>tree out of the graph<br>
7<br>
<hr>
<a name="8"></a><b>Graph components</b><br>
8<br>
<hr>
<a name="9"></a><b>Representing systems</b><br>
<b>Nodes </b>can represent states (places, conditions, situations), or <br>actions.<br>
<b>Edges </b>represent links between the nodes: e.g., changes of <br>state or precedence of actions.<br>
Graphs are usual y classified according to the information <br>edges carry.<br>
9<br>
<hr>
<a name="10"></a><b>Simple graphs</b><br>
&#xFFFD; A simple graph consists of a set V <br>
of vertices, with at most one edge <br>between each pair of vertices<br>
a<br>
&#xFFFD; In simple graphs, edges represent <br>
b<br>
c<br>
a mutual relation between the <br>nodes<br>
&#xFFFD; An edge is determined by the two <br>
d<br>
nodes it joins<br>
10<br>
<hr>
<a name="11"></a><b>Example: the tube (simple graph)</b><br>
Euston<br>
Kings X<br>
Angel<br>
Old St<br>
Warren St<br>
Russel  Sq<br>
Farringdon<br>
Barbican<br>
Moorgate<br>
Liverpool St<br>
Holborn<br>
Chancery Ln<br>
St Paul&apos;s<br>
Bank<br>
What can this graph tell us?<br>
11<br>
<hr>
<a name="12"></a><b>Directed graphs</b><br>
A directed graph (or digraph) <br>consists of:<br>
a<br>
&#xFFFD; a set V of vertices<br>&#xFFFD; a set E of edges (in a fully <br>
b<br>
c<br>
connected digraph, E is <br>equivalent to V x V)<br>
d<br>
12<br>
<hr>
<a name="13"></a><b>Directed graphs (2)</b><br>
&#xFFFD; A graph can be viewed as representing a binary relation on <br>
V.<br>
&#xFFFD; An edge is determined by the precedent node, and the <br>
dependent node<br>
&#xFFFD; Simple graphs have a directed graph equivalent, but directed <br>
graphs may not have a simple graph equivalent<br>
13<br>
<hr>
<a name="14"></a><b>Example: the tube (directed graph)</b><br>
Euston<br>
Kings X<br>
Angel<br>
Old St<br>
Warren St<br>
Russel  Sq<br>
Farringdon<br>
Barbican<br>
Moorgate<br>
Liverpool St<br>
Holborn<br>
Chancery Ln<br>
St Paul&apos;s<br>
What can this graph tell us?<br>
Bank<br>
14<br>
<hr>
<a name="15"></a><b>Weighted graphs</b><br>
Edges contain additional information: <br>a number representing time, cost or <br>
a<br>
1<br>
0.8<br>
distance, for example.<br>
1<br>
This number is the &quot;weight&quot; of the <br>
b<br>
1.5 c<br>
edge .<br>
1 1<br>
If you are only considering &quot;number of <br>
d 1<br>
moves&quot;, then the weight is 1 for each <br>move (e.g., for each edge).<br>The weight (or cost) of a path is the <br>sum of the weights of its edges.<br>
15<br>
<hr>
<a name="16"></a><b>Example: the tube (weighted graph)</b><br>
2<br>
2.5<br>
Euston<br>
Kings X<br>
2<br>
Angel<br>
2<br>
1.5 1.5<br>
2<br>
2.5<br>
1.5 1.5<br>
Old St<br>
2<br>
2<br>
Warren St<br>
Russel  Sq<br>
Farringdon<br>
1.5<br>
1.5<br>
1.5<br>
1.5<br>
1<br>
1<br>
1<br>
Barbican<br>
1<br>
Moorgate<br>
Liverpool St<br>
Holborn<br>
1<br>
2<br>
1<br>
2<br>
Chancery Ln 2<br>
2.5 2.5 3<br>
2<br>
St Paul&apos;s 2<br>
3<br>
Bank<br>
What can this graph tell us?<br>
2<br>
16<br>
<hr>
<a name="17"></a><b>Some definitions</b><br>
&#xFFFD; A vertex vi is said to be <b>adjacent </b>to a vertex vj if there is an <br>
edge from vi to vj .<br>
&#xFFFD; A <b>path </b>(or walk) from v1 to vn is a sequence of consecutive <br>
edges: v1--&gt;v2--&gt;v3--&gt; .... --&gt;vn .<br>
&#xFFFD; A <b>circuit </b>is a path from a vertex to itself, without repeating <br>
any edges.<br>
&#xFFFD; A <b>cycle </b>is a circuit in which no vertex is repeated.<br>
17<br>
<hr>
<a name="18"></a><b>Representing Graphs</b><br>
18<br>
<hr>
<a name="19"></a><b>Representing graphs</b><br>
This far we have talked about what graphs represent<br>
... but how can graphs be represented in a system?<br>
Basical y you need to represent the nodes and the links.<br>
19<br>
<hr>
<a name="20"></a><b>Adjacency matrix</b><br>
a<br>
An adjacency matrix is a <br>
b<br>
c<br>
|V| x |V| matrix a such that aij is 1 <br>
when there is an edge that goes <br>
d<br>
from vi to vj.<br>
nodes<br>
Nodes are thus represented as <br>
<b>a</b><br>
<b>b</b><br>
<b>c</b><br>
<b>d</b><br>
rows and columns, and edges are <br>
a<br>
0<br>
1<br>
1<br>
1<br>
represented as elements of the <br>
b<br>
1<br>
0<br>
0<br>
0<br>
matrix.<br>
c<br>
0<br>
1<br>
0<br>
1<br>
edges<br>
d<br>
1<br>
0<br>
0<br>
0<br>
20<br>
<hr>
<a name="21"></a><b>Adjacency list</b><br>
a<br>
Adjacency lists show<br>
b<br>
c<br>
the dependants of a<br>node in linked lists.<br>
d<br>
Nodes can be<br>
nodes<br>
edges<br>
represented as <br>
a<br>
b<br>
c<br>
d null<br>
elements in a linked<br>list as well<br>
b<br>
a null<br>
c<br>
b<br>
d null<br>
null d<br>
a null<br>
21<br>
<hr>
<a name="22"></a><b>Adjacency list variant</b><br>
a<br>
Nodes can also be <br>
b<br>
c<br>
represented as <br>elements in an array.<br>
d<br>
For sparse graphs <br>an expandable <br>
nodes<br>
edges<br>
array a good <br>
b<br>
a<br>
c<br>
d null<br>
solution.<br>
b<br>
a null<br>
c<br>
b<br>
d null<br>
d<br>
a null<br>
22<br>
<hr>
<a name="23"></a><b>Graph traversals</b><br>
23<br>
<hr>
<a name="24"></a><b>Graph traversals</b><br>
As with trees, graphs may be traversed depth-first or breadth-<br>first<br>The algorithms are very similar to those for trees, except that <br>encountered vertices need to be marked so that circuits do not <br>lead to infinite traversing.<br>Depth-first traversal is used in other algorithms:<br>
&#xFFFD; <b>Topological sort</b>: order the vertices so no edge goes<br>
backwards<br>
&#xFFFD; <b>Strongly connected elements</b>: sets of vertices,<br>
each of which can be reached from any other<br>
24<br>
<hr>
<a name="25"></a><b>Depth-first traversal</b><br>
<i>Function dft(Vertex v):<br>visit v<br>FOR ALL vertices u adjacent to v</i><br>
<i>IF u has not been visited THEN</i><br>
<i>dft(u)</i><br>
<i>Function depthFirstSearch():<br>FOR ALL vertices v</i><br>
<i>IF v has not been visited THEN</i><br>
<i>dft(v)</i><br>
25<br>
<hr>
<a name="26"></a><b>Depth-first traversal </b><br>
a<br>
b<br>
c<br>
d<br>
e<br>
f<br>
g<br>
h<br>
i<br>
j<br>
26<br>
<hr>
<a name="27"></a><b>Breadth-first traversal</b><br>
<i>Function breadthFirstSearch():<br>create queue q<br>FOR ALL vertices v</i><br>
<i>IF v has not been visited</i><br>
<i>visit v </i><br>
Note that only new <br>
<i>enqueue v in q</i><br>
vertices are added <br>
<i>WHILE q is not empty</i><br>
to the queue<br>
<i>u  vertex dequeued from q<br>FOR ALL vertices w adjacent to u</i><br>
<i>IF w has not been visited</i><br>
<i>visit w<br>enqueue w in q</i><br>
27<br>
<hr>
<a name="28"></a><b>Breadth-first traversal  </b><br>
a<br>
b<br>
c<br>
d<br>
e<br>
f<br>
g<br>
h<br>
i<br>
j<br>
28<br>
<hr>
<a name="29"></a><b>Shortest Path Algorithms</b><br>
29<br>
<hr>
<a name="30"></a><b>Shortest path algorithms</b><br>
<b>all-to-all </b>A simple algorithm takes O(|V|3) time, this can be improved a bit.<br><b>one-to-all </b>There are several algorithms; we consider Dijkstra&apos;s, which <br>assumes all weights are positive.<br><b>all-to-one </b>Use a one-to-all algorithm on the reversed graph.<br><b>one-to-one </b>No faster algorithm is known than using a one-to-all algorithm <br>until the desired target is reached<br>
30<br>
<hr>
<a name="31"></a><b>Dijkstra&apos;s shortest path algorithm</b><br>
The algorithm maintains:<br>
&#xFFFD; A set <b>toBeChecked </b>of vertices whose shortest path is not yet known. Initially <br>
this set is V<br>
&#xFFFD; An array <b>currDist </b>giving the length of shortest path from start to every other <br>
vertex using the checked nodes. Initially 0 for start and - (or infinite) for every <br>other vertex<br>
&#xFFFD; An array <b>predecessor </b>giving the previous vertex on the current shortest path, if <br>
any<br>
Until toBeChecked is empty:<br>
&#xFFFD; extract from toBeChecked the closest vertex<br>&#xFFFD; update adjacent vertices<br>
31<br>
<hr>
<a name="32"></a><b>Example of Dijkstra&apos;s algorithm</b><br>
Shortest distance from d<br>
<b>a</b><br>
<b>b</b><br>
<b>c</b><br>
<b>d</b><br>
<b>e</b><br>
<b>f</b><br>
<b>g</b><br>
<b>h</b><br>
<b>i</b><br>
<b>j</b><br>
toBeChecked<br>
x<br>
x<br>
x<br>
x<br>
x<br>
x<br>
x<br>
x<br>
x<br>
x<br>
currDist<br>
-<br>
-<br>
-<br>
0<br>
-<br>
-<br>
-<br>
-<br>
-<br>
-<br>
predecessor<br>
32<br>
<hr>
<a name="33"></a><b>Example of Dijkstra&apos;s algorithm (2)</b><br>
<b>a</b><br>
<b>b</b><br>
<b>c</b><br>
<b>d</b><br>
<b>e</b><br>
<b>f</b><br>
<b>g</b><br>
<b>h</b><br>
<b>i</b><br>
<b>j</b><br>
toBeChecked<br>
x<br>
x<br>
x<br>
x<br>
x<br>
x<br>
x<br>
x<br>
x<br>
currDist<br>
4<br>
-<br>
-<br>
0<br>
-<br>
-<br>
-<br>
1<br>
-<br>
-<br>
predecessor<br>
d<br>
d<br>
33<br>
lowest unchecked goes next<br>
<hr>
<a name="34"></a><b>Example of Dijkstra&apos;s algorithm (3) </b><br>
<b>a</b><br>
<b>b</b><br>
<b>c</b><br>
<b>d</b><br>
<b>e</b><br>
<b>f</b><br>
<b>g</b><br>
<b>h</b><br>
<b>i</b><br>
<b>j</b><br>
toBeChecked<br>currDist<br>predecessor<br>
lowest unchecked goes next<br>
34<br>
<hr>
<a name="35"></a><b>Example of Dijkstra&apos;s algorithm (4) </b><br>
<b>a</b><br>
<b>b</b><br>
<b>c</b><br>
<b>d</b><br>
<b>e</b><br>
<b>f</b><br>
<b>g</b><br>
<b>h</b><br>
<b>i</b><br>
<b>j</b><br>
toBeChecked<br>currDist<br>predecessor<br>
lowest unchecked goes next<br>
35<br>
<hr>
<a name="36"></a><b>Example of Dijkstra&apos;s algorithm (5) </b><br>
<b>a</b><br>
<b>b</b><br>
<b>c</b><br>
<b>d</b><br>
<b>e</b><br>
<b>f</b><br>
<b>g</b><br>
<b>h</b><br>
<b>i</b><br>
<b>j</b><br>
toBeChecked<br>currDist<br>predecessor<br>
lowest unchecked goes next<br>
36<br>
<hr>
<a name="37"></a><b>Example of Dijkstra&apos;s algorithm (6) </b><br>
<b>a</b><br>
<b>b</b><br>
<b>c</b><br>
<b>d</b><br>
<b>e</b><br>
<b>f</b><br>
<b>g</b><br>
<b>h</b><br>
<b>i</b><br>
<b>j</b><br>
toBeChecked<br>currDist<br>predecessor<br>
lowest unchecked goes next<br>
37<br>
<hr>
<a name="38"></a><b>Example of Dijkstra&apos;s algorithm (skipped to the end)</b><br>
<b>a</b><br>
<b>b</b><br>
<b>c</b><br>
<b>d</b><br>
<b>e</b><br>
<b>f</b><br>
<b>g</b><br>
<b>h</b><br>
<b>i</b><br>
<b>j</b><br>
toBeChecked<br>currDist<br>
4<br>
9<br>
11<br>
0<br>
5<br>
8<br>
12<br>
1<br>
9<br>
11<br>
predecessor<br>
d<br>
f<br>
f<br>
a<br>
e<br>
j<br>
d<br>
f<br>
i<br>
38<br>
<hr>
<a name="39"></a><b>Dijkstra&apos;s algorithm</b><br>
<i>FOR all vertices v</i><br>
<i>currDist[v] &lt;- infinity;</i><br>
<i>currDist[start] &lt;- 0;<br>toBeChecked &lt;- V;<br>WHILE toBeChecked is not empty</i><br>
<i>v &lt;- a vertex in toBeChecked with minimal currDist(v);<br>remove v from toBeChecked;<br>FOR all vertices u adjacent to v and in toBeChecked</i><br>
<i>IF currDist[u] &gt; currDist[v] + weight(vu)</i><br>
<i>currDist[u] &lt;- currDist[v] + weight(vu);<br>predecessor[u] &lt;- v;</i><br>
39<br>
<hr>
<a name="40"></a><b>Analysis of Dijkstra&apos;s algorithm</b><br>
With adjacency list representation:<br>
&#xFFFD; The outer while loop is executed O(|V|) times, and on each iteration, <br>
extracting vertices takes O(|V|) time<br>
&#xFFFD; The inner for loop is executed a total of O(|E|) times, performing O(1) <br>
work each time<br>
&#xFFFD; Giving a total of O(|V|2) time (because |E| &lt;= |V|2)<br>
40<br>
<hr>
<a name="41"></a><b>Graph Problems</b><br>
41<br>
<hr>
<a name="42"></a><b>Graph problems</b><br>
<b>Polynomial </b>time algorithms exist for the following problems:<br>
&#xFFFD; all-to-all shortest paths<br>&#xFFFD; topological sort order the vertices so no edge goes backwards<br>&#xFFFD; strongly connected components sets of vertices, each of which can be reached <br>
from any other<br>
&#xFFFD; minimal spanning tree: find a minimal cost tree that covers al  vertices (Kruskal <br>
algorithm)<br>
&#xFFFD; network flow (Dinic algorithm)<br>
42<br>
<hr>
<a name="43"></a><b>Hard graph problems</b><br>
Recall <b>NP-complete </b>problems: the best known algorithms are exponential, <br>and if any one has a polynomial algorithm, it can be adapted to all of them.<br>Hence it is conjectured that no such algorithm exists.<br>NP-complete graph problems include:<br>
&#xFFFD; travelling salesman: Find the shortest circuit that includes all vertices<br>&#xFFFD; longest cycle<br>&#xFFFD; largest clique<br>
Other problems are unclassified, e.g., testing whether two graphs are <br>equivalent (isomorphic).<br>
43<br>
<hr>
<a name="44"></a><b>Reading</b><br>
&#xFFFD; Weiss: Sections 13.1-13.4  <br>
&#xFFFD; Drozdek: Sections 8.1, 8.2 and 8.3   <br>
Next session: Revision<br>
44<br>
<hr>
<a name="45"></a>City, University of London<br>Northampton Square<br>London<br>EC1V 0HB<br>United Kingdom<br>
T: +44 (0)20 7040 8406<br>E: ug-compsci@city.ac.uk<br>www.city.ac.uk/department-computer-science<br>
45<br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Sample Answers to Exercise Sheet 2 </b><br>
 <br> <br>
 <br>
 <br>
1. The function power presented in the lecture is rather inefficient. Use the equations: <br> <br>
<i>x2n = xn &#xFFFD;xn <br>x2n+1 = x&#xFFFD;xn&#xFFFD;xn </i><br>
 <br>to write a more efficient <b>recursive </b>algorithm. How much time does the new version take? <br> <br>/** <br>* Calculate x^n more efficiently. <br>* @param x The base. <br>* @param n The exponent (must not be negative). <br>*/ <br>double power(double x, int n) { <br>
if (n == 0) <br>
return 1.0; <br>
double p = power(x, n/2); // p=x^(n/2) int division! <br>p *= p; // p = x^(n-n%2) <br>if (n%2 != 0) // odd n needs one more factor <br>
p *= x; // p = x^n <br>
return p; <br>
} <br> <br>
  The call tree for this function looks like this: <br>
 <br>
power(x, n) <br>
power(x, n/2) <br>
power(x, n/4) <br>
... <br>
 <br>
and this will have depth log n. As the function without the recursive call takes constant time, <br>the whole function takes O(log n) time. To achieve this, it is crucial that   we   call <br>power(x, n/2) only once and store its value in p to use the result twice. In other words: <br>using power(n, n/2) * power(n, n/2) makes it O(<i>n</i>) again. <br> <br> <br> <br>2. Consider the function: <br> <br>
<i>int sumOfSquares(int n) { </i><br>
<i>if (n == 0) </i><br>
<i>return 0; </i><br>
<i>return n*n + sumOfSquares(n-1); </i><br>
<i>} </i><br>
 <br>Is it tail recursive? Can you convert it to iterative? If so, how? If not, why not? <br>
<hr>
<a name="2"></a>  This function computes the sum n2 + ... + 22 + 12 and takes time O(n). <br>
 <br>
  The last call the function makes is n*n + sumOfSquares(n-1). The function is not tail <br>
recursive because the last call it makes is to operator `+&apos; rather than the recursive call <br>&quot;sumOfSquares&quot;. <br> <br>
  The same function can be expressed as tail recursive by creating an auxiliary function: <br>
 <br>int sumOfSquares(int n) { <br>
return sos(n, 0); <br>
} <br>int sos(int n, int sum) { <br>
if (n==0) <br>
return sum; <br>
return sos(n-1, n*n + sum); <br>
} <br> <br> <br>
  This version can be easily converted to iterative: <br>
 <br>int sumOfSquares(int n) { <br>
int sum = 0; <br>for ( ; n&gt;0; n-=1) <br>
sum = n*n + sum; <br>
return sum; <br>
} <br> <br>
  A skilled programmer can of course convert the original version to iterative, too, <br>
using a stack. But for a tail-recursive function it works easily without a stack. <br>
 <br> <br>
 <br>
3. The array priority queue implementation provided in the lecture notes assumed a sorted <br>array, where the method <i>add </i>contains a call to a method <i>insert</i>. Provide the algorithm for the <br>method <i>insert</i> (pseudocode or a programming language are fine). <br> <br>void insert(array data, int size, int element) { <br>
int position  1; <br>// find the position in the array where the new element <br>// needs to be added <br>WHILE (position &lt; size AND data[position] &lt; element) <br>
position++; <br>
// move all larger existing elements up one position <br>int inPlace  size <br>WHILE (inPlace &gt; position) <br> <br>
data[inPlace]  data[inPlace-1]; <br>
 <br>
inPlace--; <br>
// insert the new element in its correct place <br>data[position]  element; <br>
} <br>
<hr>
<a name="3"></a>  Note that finding the position here has been done using sequential search. It could <br>
also have been done using binary search. That would have improved the time <br>complexity of the first loop, but not of the second. Hence, the overall complexity <br>would remain unchanged. <br>
 <br> <br> <br>4. Had the priority queue been implemented using an unsorted array, there would be some <br>differences to the implementation of its basic operations (<i>isEmpty</i>, <i>add</i>, <i>extractMax</i>). Discuss <br>which of these would need to be changed and why, while providing new algorithms for those <br>requiring changes (again, pseudocode or a programming language are fine). <br> <br>
  isEmpty remains the same, as what really matters is simply whether there are any <br>
elements in the array or not. <br>
  add would be faster and changed, as we would simply add the new element to the end <br>
of the existing array. <br>
 <br>void add(int elt) { <br>
count++; <br>data[count]  elt; <br>
} <br> <br>
  extractMax would be slower and changed, as we would need to traverse the whole <br>
array keeping track of the largest value found so far and its position. Then remove that <br>element and reshuffle all other elements that were in the array in positions after it, <br>actually removing the largest element. <br> <br>
int extractMax() { <br>
int largest  data[1] <br>int position  1 <br>int i  1 <br>// find largest value and its position <br>WHILE i &lt; count <br> <br>
i++ <br>
 <br>
IF largest &lt; data[i] <br>
 <br>
 <br>
largest  data[i] <br>
 <br>
 <br>
position  i <br>
// reshuffle other elements <br>i  position <br>WHILE i &lt; count <br> <br>
data[i]  data[i+1] <br>
 <br>
i++ <br>
count-- <br>Return largest <br>
} <br>
 <br> <br> <br>
<hr>
<a name="4"></a><b>And a bit of programming. You are not expected to tackle this during the tutorial slot, <br>but at some later time, at your own convenience. Note that answers to this will be <br>released much later than for the other questions, giving you time to experiment with it. <br> <br></b>5. A cocktail shaker sort designed by Donald Knuth is a modification of bubble sort in which <br>the direction of bubbling changes in each iteration: In one iteration, the smallest element is <br>bubbled up; in the next, the largest is bubbled down; in the next, the second smallest is <br>bubbled up; and so forth. Implement the new algorithm and discuss its complexity. <br>
 <br>
<b>And a bit of programming. Answers to this will be released much later, giving you time <br>to experiment with it. </b><br>
 <br> <br> <br> <br>
<b>Refresher Powers and Logs (justify your answers)  <br></b>// TO BE USED FOR REVISION OUTSIDE THE TUTORIAL <br> <br>6. What is 23  (2 power 3)? <br>
a) 9  <br>
  No, 9 = 3*3 = 32 <br>
b) 6  <br>
  No, 6=2*3 <br>
c) 8  <br>
  Yes, 8 = 2*2*2 = 23 <br>
d) 5 <br>
  No, 5=2+3 <br>
 <br>
7. What is the log2 16  (logarithm of 16 base 2)? <br>
a) 1  <br>
  No, 21 = 2, 1 = log 2 2  (or log 2 base 2) <br>
b) 2  <br>
  No, 22 = 2*2 = 4, 2 = log 2 4  (or log 4 base 2) <br>
c) 3  <br>
  No, 23 = 2*2*2 = 8, 3 = log 2 8  (or log 8 base 2) <br>
d) 4 <br>
  Yes, 24 = 2*2*2*2 = 16, 4 = log 2 16  (or log 16 base 2) <br>
 <br>8. What is the log4 16  (logarithm of 16 base 4)? <br>
a) 1  <br>
  No, 41=4, 1 = log 4 4   (or log 4 base 4) <br>
b) 2  <br>
  Yes, 42 = 4*4 = 16, 2 = log 4 16   (or log 16 base 4) <br>
c) 3  <br>
  No, 43 = 4*4*4 = 64, 3 = log 4 64    (or log 64 base 4) <br>
d) 4 <br>
  No, 44 = 4*4*4*4 = 256, 4 = log 4 256    (or log 256 base 4) <br>
 <br>
 <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Exercise Sheet 3 </b><br>
 <br> <br> <br>1. Only one of the following trees is a heap. Indicate which one and why the others are not. <br> <br>
a)   <br>
19<br>
10<br>
12<br>
8<br>
7<br>
9<br>
3<br>
0<br>
4<br>
1<br>
6<br>
5<br>
2<br>
 <br>
 <br>b) <br>
17<br>
11<br>
15<br>
7<br>
5<br>
9<br>
10<br>
2<br>
4<br>
1<br>
3<br>
8<br>
6<br>
0<br>
 <br>
 <br>c) <br>
19<br>
10<br>
12<br>
8<br>
7<br>
9<br>
3<br>
2<br>
4<br>
1<br>
6<br>
 <br>
 <br>d) <br>
19<br>
10<br>
12<br>
8<br>
3<br>
9<br>
2<br>
4<br>
1<br>
6<br>
5<br>
 <br>
 <br> <br> <br>
<hr>
<a name="2"></a> <br>2. Show the heaps that are generated as you add the following sequence of keys to an empty <br>heap (one at a time): 6, 3, 11, 9, 8, 5, 4, 12. <br> <br> <br>3. Only one of the following arrays is not a heap. Indicate which one. <br>
a)  12 11 8 10 3 4 6 7 5 1 2 <br>b)  30 17 16 15 14 3 2 8 11 7 6 5 <br>c)  20 8 14 7 1 5 10 3 6 <br>
 <br> <br>4. Consider heap 16 14 10 8 7 9 3 <br>
a.  Show it in tree format. <br>b.  Show the heaps that result if extractMax is applied repeatedly until the heap is empty. <br>
 <br> <br>5. Provide pseudocode for a queue implemented using an array. This implies the functions <br><i>isEmpty</i>, <i>enqueue</i>, and <i>dequeue</i>. <br> <br> <br>6. Write functions  voi d  add( i nt   el t )  and  i nt   ext r act Max( )  in Java, <br>implementing the pseudocode in the lecture nodes. <br> <br> <br>7. Work through the steps of sorting the keys 7 4 1 8 5 2 9 6 3 0 using heap sort. Focus on the <br>major steps: show the state of the array after each insertion and extraction from the heap. <br> <br> <br><b>And a bit of programming. You are not expected to tackle this during the tutorial <br>slot, but at some later time, at your own convenience. Note that answers to this <br>will be released much later than for the other questions, giving you time to <br>experiment with it. </b> <br> <br>8. Write a recursive program with the declaration <br> <br>publ i c  st at i c  voi d  per mut e(   St r i ng  st r ) ;  <br> <br>that prints all the permutations of the characters in the string str. If str is &quot;abc&quot;, then the strings <br>output are abc, acb, bac, bca, cab, and cba. <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Answers to Exercise Sheet 3 </b><br>
 <br> <br> <br>1. Only one of the following trees is a heap. Indicate which one and why the others are not. <br> <br>
a)   <br>
19<br>
10<br>
12<br>
8<br>
7<br>
9<br>
3<br>
0<br>
4<br>
1<br>
6<br>
5<br>
2<br>
 <br>
  This is not a heap because the leaves are not as far left as possible: (2) is a child of (3) <br>
even though (9) has room for one more child. <br>
 <br>b) <br>
17<br>
11<br>
15<br>
7<br>
5<br>
9<br>
10<br>
2<br>
4<br>
1<br>
3<br>
8<br>
6<br>
0<br>
 <br>
  This is not a heap because it is not a binary tree: (9) has more than two children. <br>
 <br>c) <br>
19<br>
10<br>
12<br>
8<br>
7<br>
9<br>
3<br>
2<br>
4<br>
1<br>
6<br>
 <br>
  This is a heap because it is a perfectly balanced binary tree with all its leaves as far <br>
left as possible, and with no child larger than its parent. <br>
 <br>d) <br>
<hr>
<a name="2"></a>19<br>
10<br>
12<br>
8<br>
3<br>
9<br>
2<br>
4<br>
1<br>
6<br>
5<br>
 <br>
  This is not a heap because (6) is larger than its parent (3) and (12) has only one child <br>
(making the tree unbalanced). <br>
 <br> <br>2. Show the heaps that are generated as you add the following sequence of keys to an empty <br>heap (one at a time): 6, 3, 11, 9, 8, 5, 4, 12. <br> <br>
  This is what the heaps look like after adding each element. <br>
 <br>
1) 6<br>
2)<br>
6<br>
3)<br>
11<br>
3<br>
3<br>
6<br>
4)<br>
11<br>
5)<br>
11<br>
9<br>
6<br>
9<br>
6<br>
3<br>
3<br>
8<br>
 <br>
 <br>
7)<br>
6)<br>
11<br>
11<br>
9<br>
6<br>
9<br>
6<br>
3<br>
8<br>
5<br>
3<br>
8<br>
5<br>
4<br>
 <br>
 <br>
8)<br>
12<br>
11<br>
6<br>
9<br>
8<br>
5<br>
4<br>
3<br>
 <br>
 <br> <br> <br> <br>
<hr>
<a name="3"></a> <br>3. Only one of the following arrays is not a heap. Indicate which one. <br>
a)  12 11 8 10 3 4 6 7 5 1 2 <br>b)  30 17 16 15 14 3 2 8 11 7 6 5 <br>c)  20 8 14 7 1 5 10 3 6 <br>
 <br>
  For this, we build the heaps in tree format and check whether the children have lower <br>
values than their parents: <br>
 <br>
a)<br>
12<br>
b)<br>
30<br>
11<br>
8<br>
17<br>
16<br>
10<br>
3<br>
4<br>
6<br>
15<br>
14<br>
3<br>
2<br>
7<br>
5<br>
1<br>
2<br>
    8 11 7<br>
6<br>
5<br>
 <br>
 <br> <br>
c)<br>
20<br>
8<br>
14<br>
7<br>
1<br>
5<br>
10<br>
3<br>
6<br>
 <br>
 <br>
  So &quot;a&quot; and &quot;c&quot; are heaps; and &quot;b&quot; is not (&quot;b&quot; has node &quot;5&quot; as a child of &quot;3&quot;, which is <br>
smaller. <br>
 <br> <br>4. Consider heap 16 14 10 8 7 9 3  <br>
a.  Show it in tree format. <br>
 <br>
a)<br>
16<br>
14<br>
10<br>
8<br>
7<br>
9<br>
3<br>
 <br>
 <br>
b.  Show the heaps that result if extractMax is applied repeatedly until the heap is empty. <br>
 <br>
<hr>
<a name="4"></a>1)<br>
16<br>
2)<br>
14<br>
14<br>
10<br>
8<br>
10<br>
8<br>
7<br>
9<br>
3<br>
3<br>
7<br>
9<br>
   <br>
 <br>
3)<br>
10<br>
4)<br>
9<br>
8<br>
9<br>
8<br>
7<br>
3<br>
7<br>
3<br>
   <br>
 <br>
5)<br>
8<br>
6)<br>
7<br>
3<br>
7<br>
7)<br>
3<br>
3<br>
  <br>
 <br>
5. Provide pseudocode for a queue implemented using an array. This implies the functions <br><i>isEmpty</i>, <i>enqueue</i>, and <i>dequeue</i>. <br> <br><i>public class ArrayQueue implements Queue {</i> <br><i> </i><br>
<i> </i><br>
<i>private int[] a;</i> <br>
<i> </i><br>
<i> </i><br>
<i>private int count = 0;</i> <br>
<i> </i><br>
<i> </i><br>
<i>public ArrayQueue(int size) {a = new int[size];}</i> <br>
<i> </i><br>
 <br>
<i> </i><br>
<i> </i><br>
<i>public boolean isEmpty() {  return count == 0; }</i> <br>
<i> </i><br>
<i> </i><br>
<i>public void enqueue(int elt) { a[count++] =  elt; }</i> <br>
<i> </i><br>
<i> </i><br>
<i>public int dequeue() {  </i><br>
<i> </i><br>
<i> </i><br>
<i> </i><br>
<i>int value = a[0]; </i><br>
<i> </i><br>
<i> </i><br>
<i> </i><br>
<i>int i = 1; </i><br>
<i> </i><br>
<i> </i><br>
<i> </i><br>
<i>while (i&lt;count) { </i><br>
<i> </i><br>
<i> </i><br>
<i> </i><br>
<i> </i><br>
<i>a[i-1] = a[i]; </i><br>
<i> </i><br>
<i> </i><br>
<i> </i><br>
<i> </i><br>
<i>i++; </i><br>
<i> </i><br>
<i> </i><br>
<i> </i><br>
<i>} </i><br>
<i> </i><br>
<i> </i><br>
<i> </i><br>
<i>count--; <br>return value;  </i><br>
<i>}</i> <br>
<i>}</i> <br> <br> <br> <br> <br>
<hr>
<a name="5"></a>6. Write functions  voi d  add( i nt   el t )  and  i nt   ext r act Max( )  in Java, <br>implementing the pseudocode in the lecture nodes. <br> <br>/** <br>* Add an element to a heap. <br>* @param elt The element to add. <br>*/ <br>public void add(int elt) { <br>
int pos = count; // add after last element <br>while (pos &gt; 0 &amp;&amp; data[parent(pos)] &lt; elt) { // while <br>
// heap condition not satisfied <br>data[pos] = data[parent(pos)]; // move parent down <br>pos = parent(pos); // move to parent position <br>
} <br>data[pos] = elt; // insert elt <br>count++; // increment after adding <br>
} <br> <br>/** <br>* Get the greatest element, remove it, and reorganise the <br>* heap. <br>* @return The greatest element of the heap. <br>*/ <br>public int extractMax() { <br>
int max = data[0]; // max is a 0, make a copy <br>count--; // decrement count to use it as index <br>data[0] = data[count]; // move last elt to 0 <br>moveDown(data, 0, count - 1); // reorganise <br>return max; // return the old max <br>
} <br> <br>/** <br>* Reorganizes a heap by moving the elt &apos;first&apos; down until <br>* heap condition is satisfied. <br>* @param data The data array. <br>* @param first Index of element to move down. <br>* @param last Index of last valid position in heap. <br>*/ <br>void moveDown(int data[], int first, int last) { <br>
while (left(first) &lt;= last) {// determine <br>
int largest = left(first); // the greater child <br>if (right(first) &lt;= last // if greater <br>
&amp;&amp; data[largest] &lt; data[right(first)]) <br>largest = right(first); // use right <br>// test heap condition <br>
if (data[first] &gt;= data[largest]) // if heap <br>
break; // cond. satisfied, we can finish <br>
swap(data, first, largest); // swap w. greater child <br>first = largest; // start again from greater child <br>
} <br>
} <br> <br> <br> <br>
<hr>
<a name="6"></a><b>And a bit of programming  (note that answers to this will be released much <br>later than for the other questions, giving you time to experiment with it) <br></b> <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Exercise Sheet 4 </b><br>
 <br> <br>1. Suppose we have Node p and Node q referring to the same list of nodes containing <br>[5, 8, 3]. Draw the list, and the results of the following statements, applied in order: <br> <br>p.next = null; <br>p = null; <br> <br> <br>2. Suppose we have Node p referring to a list of nodes containing [3, 5, 4, 1]. Draw <br>the list, and the results of the following statements, applied in order: <br> <br>p.next = p.next.next; <br>p.next = new Node(7, p.next); <br>p.next.next = new Node(8); <br>p.next.next = p; <br> <br> <br>3. Work out (using pictures) what the following procedure does: <br> <br>public void modify(SLList list) { <br>
if (list.head != null &amp;&amp; list.head.next != null) { <br>
Node tmp = list.head.next; <br>list.head.next = tmp.next; <br>tmp.next = list.head; <br>list.head = tmp; <br>
} <br>
} <br> <br> <br>4.  <br>a) Write a method that checks whether two singly linked lists have the same elements (in any <br>order). You should not modify either list. What time (in big-O notation) does this method <br>take? <br> <br>b) What would be the time complexity if you were checking whether the lists have the same <br>elements in the same order? <br> <br> <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Answers to Exercise Sheet 4 </b><br>
 <br> <br>1. Suppose we have Node p and Node q referring to the same list of nodes containing <br>[5, 8, 3]. Draw the list, and the results of the following statements, applied in order: <br> <br>p.next = null; <br>p = null; <br> <br>
  The initial list is: <br>
Node p<br>
Node q<br>
5<br>
8<br>
3<br>
null<br>
 <br>
 <br>p.next = null; <br>
Node p<br>
Node q<br>
5<br>
null<br>
 <br>
 <br>
  We would have both p and q referring to the same list with a single element (with info <br>
5). <br>
 <br> <br>p = null; <br> <br>
<hr>
<a name="2"></a>Node p<br>
Node q<br>
null<br>
5<br>
null<br>
 <br>
  This sets the value of p to null (no longer refers to a list), whereas q still refers to the <br>
same list as before. <br>
 <br> <br> <br>2. Suppose we have Node p referring to a list of nodes containing [3, 5, 4, 1]. Draw <br>the list, and the results of the following statements, applied in order: <br> <br>p.next = p.next.next; <br>p.next = new Node(7, p.next); <br>p.next.next = new Node(8); <br>p.next.next = p; <br> <br>
  The initial list is: <br>
Node p<br>
3<br>
5<br>
4<br>
1<br>
null<br>
 <br>
 <br>p.next = p.next.next; <br>
<hr>
<a name="3"></a>Node p<br>
3<br>
5<br>
4<br>
1<br>
null<br>
 <br>
  We could have omitted the node with value 5 above, because nothing is pointing to it, <br>
so it is not really in the list any longer. <br>
 <br> <br>p.next = new Node(7, p.next); <br>
Node p<br>
7<br>
3<br>
5<br>
4<br>
1<br>
null<br>
 <br>
p.next.next = new Node(8); <br>
Node p<br>
7<br>
8<br>
null<br>
3<br>
5<br>
4<br>
1<br>
null<br>
 <br>
  We could have omitted the nodes with values 5, 4 and 1 above, because nothing is <br>
pointing to them, so they are not really in the list any longer. <br>
 <br>p.next.next = p; <br>
<hr>
<a name="4"></a>Node p<br>
7<br>
8<br>
null<br>
3<br>
5<br>
4<br>
1<br>
null<br>
 <br>
  OR, ignoring all the &quot;dead&quot; elements... <br>
Node p<br>
3<br>
7<br>
 <br>
 <br>3. Work out (using pictures) what the following procedure does: <br> <br>public void modify(SLList list) { <br>
if (list.head != null &amp;&amp; list.head.next != null) { <br>
Node tmp = list.head.next; <br>list.head.next = tmp.next; <br>tmp.next = list.head; <br>list.head = tmp; <br>
} <br>
} <br> <br> <br>
  Let&apos;s try the code on this list: <br>
head tail<br>
null<br>
 <br>
if (list.head != null &amp;&amp; list.head.next != null) { <br>
<hr>
<a name="5"></a>  Checks that the list is not empty and has at least two elements. <br>
 <br>
 <br>Node tmp = list.head.next; <br>
head tail<br>
null<br>
tmp<br>
 <br>
 <br> <br>list.head.next = tmp.next; <br>
head tail<br>
null<br>
tmp<br>
 <br>
 <br>tmp.next = list.head; <br>
head tail<br>
null<br>
tmp<br>
 <br>
 <br>list.head = tmp; <br>
<hr>
<a name="6"></a>head tail<br>
null<br>
tmp<br>
 <br>
  So what the algorithm does is to switch the two first elements in the list. <br>
 <br> <br>4.  <br>a) Write a method that checks whether two singly linked lists have the same elements (in any <br>order). You should not modify either list. What time (in big-O notation) does this method <br>take? <br>
  Assuming that there are no duplicates and that the lists have the same length: <br>
 <br>boolean comparelists(SLList list1, SLList list2) { <br>
Node p1 = list1.head ; <br>while (p1 != null) { <br>
Node p2 = list2.head; <br>while (p2.info != p1.info) { <br>
if (p2 == null) <br>
return false; <br>
p2 = p2.next; <br>
} <br>p1 = p1.next; <br>
} <br>return true; <br>
} <br> <br>
  This function is O(n2) time. The outside loop traverses list p1, requiring O(n) <br>
iterations. The internal loop traverses p2, requiring O(n) each time. Since the loops <br>are nested, the overall time is O(n)xO(n) = O(n2)  <br>
 <br>
  Note that comparing lengths requires O(n) time, so it would not change the time <br>
complexity found in this case. <br>
 <br> <br>b) What would be the time complexity if you were checking whether the lists have the same <br>elements in the same order? <br> <br>
  O(n), as for this, both lists would be traversed in parallel, at the same time. In other <br>
words, the nodes of list1 are visited one at the time (O(n)), and only one node of list2 <br>is visited in each iteration (O(1)). O(n)xO(1) = O(n). <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Exercise Sheet 5 </b><br>
 <br> <br>1. Work out (using pictures) what the following procedure does on circular lists: <br> <br>public void modify(CList list) { <br>
if (! isEmpty()) { <br>
Node tmp = tail.next; <br>tail.next = tail.next.next; <br>tmp.next = tmp; <br>
} <br>
} <br> <br>Consider the cases where the list has more than one node, only one node, or no nodes. <br> <br> <br>2. Write functions that return the maximum of the numbers of  (where the info in each node is <br>a number): <br> <br>
a)  a circular list <br>b)  a doubly linked list <br>
 <br> <br>3. Write a procedure to swap the first two nodes of a doubly linked list. <br>Have you covered all the cases? <br> <br> <br><b>And a bit of programming. You are not expected to tackle this during the tutorial <br>slot, but at some later time, at your own convenience. </b> <br> <br>4. Write a program that takes as input two ordered circular lists and produces a third ordered <br>circular list containing the elements from both of the input lists. <br> <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Answers to Exercise Sheet 5 </b><br>
 <br> <br>1. Work out (using pictures) what the following procedure does on circular lists: <br> <br>public void modify(CList list) { <br>
if (! isEmpty()) { <br>
Node tmp = tail.next; <br>tail.next = tail.next.next; <br>tmp.next = tmp; <br>
} <br>
} <br> <br>Consider the cases where the list has more than one node, only one node, or no nodes. <br> <br> <br>
  First we create a circular list with random information to test the code on: <br>
tail<br>
3<br>
5<br>
4<br>
1<br>
 <br>
 <br>if (! isEmpty()) checks that the list has at least one node <br> <br>Node tmp = tail.next; <br>
tmp<br>
tail<br>
3<br>
5<br>
4<br>
1<br>
 <br>
 <br>tail.next = tail.next.next; <br> <br>
<hr>
<a name="2"></a>tmp<br>
tail<br>
3<br>
5<br>
4<br>
1<br>
 <br>
 <br>tmp.next = tmp; <br>
tmp<br>
tail<br>
3<br>
5<br>
4<br>
1<br>
 <br>
 <br> <br> <br>
  So the function removes the head from the list, and creates a new circular list <br>
containing only the former head. However, this new circular list is not returned by the <br>function. <br>
 <br>
  With only one node, nothing happens: <br>
tail<br>
tail<br>
tmp<br>
1<br>
1<br>
 <br>
  With no nodes, nothing happens. <br>
 <br> <br>2. Write functions that return the maximum of the numbers of  (where the info in each node is <br>a number): <br> <br>
<hr>
<a name="3"></a>a)  A circular list <br>int findmax() { <br>
if (! notEmpty()) { <br>
node p = tail.next; <br>int max = p.info; <br>while (p != tail) { <br>
p = p.next; <br>if (p.info &gt; max) <br>
max = p.info; <br>
} <br>return max; <br>
} else <br>
return Integer.MIN_VALUE; <br>// This value indicates the empty list. <br>
} <br>
 <br>
b)  A doubly linked list <br>
 <br>int findmax() { <br>
if (! notEmpty()) { <br>
node p = head; <br>int max = p.info; <br>while (p != tail) { <br>
p = p.next; <br>if (p.info &gt; max) <br>
max = p.info; <br>
} <br>return max; <br>
} else <br>
return Integer.MIN_VALUE; <br>// This value indicates the empty list. <br>
} <br> <br> <br>3. Write a procedure to swap the first two nodes of a doubly linked list. <br>Have you covered all the cases? <br> <br>
  We first want to check that the list has at least two nodes. A convenient test is to <br>
compare head and tail If the list has only one node, they will be equal. If the list is <br>empty, they will both be null, and therefore also equal. If the list has at least two <br>nodes, the two pointers will refer to different nodes. <br>
 <br>
  The simplest thing is just to swap the info components of the first two nodes <br>
(provided there are at least two): <br>
 <br>void swapFirstTwo() { <br>
if (head != tail) { <br>
int tmp = head.infor; <br>head.info = head.next.info; <br>head.next.info = tmp; <br>
} <br>
<hr>
<a name="4"></a>} <br> <br>
  But the intention of the question was an exercise in pointer manipulation. An easy <br>
method is to introduce a pointer to the node after the head, and update head at the very <br>end: <br>
 <br>void swapFirstTwo() { <br>
if (head != tail) { <br>
DLLNode neck = head.next; <br>head.next = neck.next; <br>neck.next = head; <br>head.prev = neck; <br>neck.prev = null; <br>if (tail == neck) // two element list <br>
tail = head; <br>
head = neck; <br>
} <br>
} <br> <br> <br>
  Note that if the second node is also the last one, tail must be set to the old first node. <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Exercise Sheet 6 </b><br>
 <br> <br>1. Demonstrate the insertion of the keys 5, 28, 19, 20, 33, 12, 17, 10 into a hash table of 9 <br>slots. The hash function is h(k) = k mod 9, and collisions are resolved by chaining. How <br>much difference would it make if the keys were presented in a different order? <br> <br> <br>2. Demonstrate the insertion of the keys 5, 28, 19, 15, 17, 20, 16 and 30 into a hash table of <br>11 slots, with hash function h(k) = k mod 11, and collisions resolved by open addressing, <br>using a) linear probing, and b) quadratic probing. What are the average and worst cases for <br>search? <br> <br> <br>3. Write delete for a hash table with chaining. <br> <br> <br>4. Suppose we have a hash table of size m, with hash function h(k) = k mod m, and with <br>collisions resolved by chaining. Suppose further that all the keys we will insert divide evenly <br>by 4 (for example, they are pointers on a certain architecture). What happens if m is 20? 19? <br>18? In general, which values of m give better performance? <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Answers to Exercise Sheet 6 </b><br>
 <br> <br>1. Demonstrate the insertion of the keys 5, 28, 19, 20, 33, 12, 17, 10 into a hash table of 9 <br>slots. The hash function is h(k) = k mod 9, and collisions are resolved by chaining. How <br>much difference would it make if the keys were presented in a different order? <br> <br>
  The hashing function is h(k) = k mod 9 <br>  5 is placed in slot 5 mod 9 = 5 <br>  28 is placed in slot 28 mod 9 = 1 <br>  19 is to be placed in slot 19 mod 9 = 1, so it is added to the singly linked list <br>  ...and so on <br>
 <br>
0<br>
1<br>
2<br>
3<br>
4<br>
5<br>
6<br>
7<br>
8<br>
null<br>
null<br>
null<br>
10<br>
20<br>
12<br>
5<br>
33<br>
17<br>
null null<br>
null<br>
null<br>
null<br>
19<br>
28<br>
null<br>
 <br>
  Adding the elements in a different order would change the ordering of the elements in <br>
each singly linked list, but this would not affect the average performance of search or <br>insertion. <br>
 <br> <br>2. Demonstrate the insertion of the keys 5, 28, 19, 15, 17, 20, 16 and 30 into a hash table of <br>11 slots, with hash function h(k) = k mod 11, and collisions resolved by open addressing, <br>using a) linear probing, and b) quadratic probing. What are the average and worst cases for <br>search? <br> <br>
a)  Linear probing <br>
 <br>
  5 mod 11 = 5 is empty, so 5 if placed in the slot <br>  28 mod 11 = 6 is empty, so 28 is placed in the slot, <br>  ... and the same happens with 19 and 15. <br>  However, 17 mod 11 = 6, which is occupied. Consecutive slots are tried until an <br>
empty one is found: <br>
<hr>
<a name="2"></a>0<br>
1<br>
2<br>
3<br>
4<br>
5<br>
6<br>
7<br>
8<br>
9<br>
10<br>
15<br>
5<br>
28 17 19<br>
 <br>
  20 mod 11 = 9, which is empty. <br>  16 mod 11 = 5, but it is occupied, so the consecutive slots are tried <br>
0<br>
1<br>
2<br>
3<br>
4<br>
5<br>
6<br>
7<br>
8<br>
9<br>
10<br>
15<br>
5<br>
28 17 19 20 16<br>
 <br>
  30 mod 11 is 8, but it is occupied, so the consecutive slots are tried until an empty one <br>
is found <br>
0<br>
1<br>
2<br>
3<br>
4<br>
5<br>
6<br>
7<br>
8<br>
9<br>
10<br>
30<br>
15<br>
5<br>
28 17 19 20 16<br>
 <br>
  The average case for a successful search here is equivalent to the average of the times <br>
it takes to insert the keys in the hash table (17/8 = 2.125). The worst successful search <br>case would be equivalent to the worst insertion case (16, which required checking 6 <br>slots). <br>
  The worst unsuccessful search would involve searching the first element in the largest <br>
cluster, i.e., slot 4. For example, to search for 26 (26 mod 11 = 4), 9 slots would need <br>to be checked before realising that it is not there. The average case for an unsuccessful <br>search here is 4.5 in the cluster ([2+...+9]/8) and 1 on each of the three empty <br>elements, giving ~4.27.. on average. <br>
 <br>
<hr>
<a name="3"></a> <br>
b)  Quadratic probing <br>
 <br>
  Again, 5, 28, 19 and 15 find empty slots straight away. <br>  17 mod 11 = 6, which is occupied, so then (6 + 1) mod 11 = 7 is tried and found to be <br>
empty. <br>
0<br>
1<br>
2<br>
3<br>
4<br>
5<br>
6<br>
7<br>
8<br>
9<br>
10<br>
15<br>
5<br>
28 17 19<br>
 <br>
  20 mod 11 = 9, which is empty. However, 16 mod 11 is 5, which is occupied, so then <br>
the quadratic probing tries (5 + 1^2) mod 11 = 6, (5 &#xFFFD; 1^2) mod 11 = 4, (5 + 2^2) mod <br>11 = 9, and (5 &#xFFFD; 2^2) mod 11 = 1, which is empty. <br>
0<br>
1<br>
2<br>
3<br>
4<br>
5<br>
6<br>
7<br>
8<br>
9<br>
10<br>
16<br>
15<br>
5<br>
28 17 19 20<br>
 <br>
  Inserting 30 requires looking at 30 mod 11 = 8, (8 + 1^2) mod 11 = 9, (8 &#xFFFD; 1^2) mod <br>
11 = 7, (8 + 2^2) mod 11 = 1, (8 &#xFFFD; 2^2) mod 11 = 4, (8 + 3^2) mod 11 = 6, (8 &#xFFFD; 3^2) <br>mod 11 = -1. Since this is negative we add the table length to the result to bring us <br>back into the bounds of the table (-1+11= 10). Slot 10 is empty, so 30 is stored there. <br>
0<br>
1<br>
2<br>
3<br>
4<br>
5<br>
6<br>
7<br>
8<br>
9<br>
10<br>
16<br>
15<br>
5<br>
28 17 19 20 30<br>
 <br>
<hr>
<a name="4"></a>  Once again, the average case for a successful search here is equivalent to the average <br>
of the times it took to insert the keys in the hash table. The worst successful search <br>case would be equivalent to the worst insertion case (30, which required checking 7 <br>slots). The worst and average unsuccessful search is not as clearly cut as with linear <br>probing. We can calculate it for each case, but there is no general dependency on the <br>cluster length. For example, to search for 27 (27 mod 11 = 5), 7 slots would need to <br>be checked before realising that it is not in the hash table. <br>
 <br> <br>3. Write delete for a hash table with chaining. <br> <br>
  For deleting a key, we first need to find the right slot, then search through the chain <br>
and then delete the node from the chain. <br>
 <br>void delete(int key) { <br>
int index = hash(key); // find the slot address <br>Node p = table[index]; // head of the chain <br>if (p != null) { // if chain is not empty <br>
if (p.info == key) // if head contains key <br>
table[index] = p.next; // remove head <br>
else { // otherwise <br>
while (p.next != null &amp;&amp; //until chain <br>
p.next.info != key) { // end or key <br>
p = p.next; // found, go forward <br>
if (p.next != null) // !end =&gt; key found <br>
p.next = p.next.next; // delete <br>
} <br>
} <br>
} <br> <br> <br>4. Suppose we have a hash table of size m, with hash function h(k) = k mod m, and with <br>collisions resolved by chaining. Suppose further that all the keys we will insert divide evenly <br>by 4 (for example, they are pointers on a certain architecture). What happens if m is 20? 19? <br>18? In general, which values of m give better performance? <br> <br>
  If m is 20, only slots 0, 4, 8, 12 and 16 will be used, and will have longer chains. If m <br>
is 18, half of the slots are used (the even-numbered ones). If m is 19, all the slots are <br>used. <br>
  For this distribution of keys, we should choose an odd value for m, so that the keys <br>
will be distributed across all the slots. <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Exercise Sheet 7 </b><br>
 <br> <br>1. Write out a preorder, inorder, postorder and breadth-first traversals of the following binary <br>tree: <br> <br>
6<br>
11<br>
17<br>
15<br>
13<br>
12<br>
16<br>
1<br>
9<br>
3<br>
8<br>
2<br>
7<br>
10<br>
 <br>
 <br>Indicate the contents of the node visited and the stack/queue at each point in the preorder, <br>inorder, postorder and breadth-first traversals. <br> <br> <br>2. Write a recursive function that reverses the order of the nodes in each level of a binary tree. <br> <br> <br>3. Write a non-recursive function using a stack to compute the size of a binary tree. <br> <br> <br>4. Show the binary search tree that results from inserting the following sequence of keys: 6, <br>3, 11, 9, 8, 5, 4, 2, 12, 7, 1, 10. <br> <br> <br>5. What kind of tree is produced if the same keys are inserted in ascending order? What if <br>they are inserted in descending order? <br> <br> <br>6. A possible sorting algorithm is to add all the keys of an array to a binary search tree and <br>then read off its inorder traversal. Is this related to any of the sorting algorithms previously <br>considered? <br> <br> <br>7. Show the tree that results from the tree built in exercise 4 if you delete10? What if you <br>deleted 3 instead? <br> <br> <br> <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Exercise Sheet 7 </b><br>
 <br> <br>1. Write out a preorder, inorder, postorder and breadth-first traversals of the following binary <br>tree: <br> <br>
6<br>
11<br>
17<br>
15<br>
13<br>
12<br>
16<br>
1<br>
9<br>
3<br>
8<br>
2<br>
7<br>
10<br>
 <br>
 <br>Indicate the contents of the node visited and the stack/queue at each point in the preorder, <br>inorder, postorder and breadth-first traversals. <br> <br> <br> <br>
  Preorder:     // visit the node, traverse left, then traverse right; use stack to keep track of <br>
nodes to visit given the order of the recursive calls <br>
 <br>
Node visited <br>
Stack <br>
 <br>
6 <br>
6 <br>
11  17 <br>
11 <br>
15  17 <br>
15 <br>
16  1  17 <br>
16 <br>
1  17 <br>
1 <br>
8  17 <br>
8 <br>
17 <br>
17 <br>
13  12 <br>
13 <br>
9  12 <br>
9 <br>
2  12 <br>
2 <br>
12 <br>
12 <br>
3 <br>
3 <br>
7  10 <br>
7 <br>
10 <br>
10 <br>
 <br>
 <br> <br> <br>
 <br>
<hr>
<a name="2"></a>  Inorder:     // traverse left, visit node, then traverse right; use stack to keep track of nodes <br>
to visit given the order of the recursive calls <br>
 <br>
Node visited <br>
Stack <br>
 <br>
16  15  11  6 <br>
16 <br>
15  11  6 <br>
15 <br>
8  1  11  6 <br>
8 <br>
1  11  6 <br>
1 <br>
11  6 <br>
11 <br>
6 <br>
6 <br>
9  13  17 <br>
9 <br>
2  13  17 <br>
2 <br>
13  17 <br>
13 <br>
17 <br>
17 <br>
7  3  12 <br>
7 <br>
3  12 <br>
3 <br>
10  12 <br>
10 <br>
12 <br>
12 <br>
 <br>
 <br> <br> <br>
  Postorder:      // traverse left, traverse right, then visit the node; use stack to keep track of <br>
nodes to visit given the order of the recursive calls <br>
 <br>
Node visited <br>
Stack <br>
16 <br>
15L  11L  6L <br>
8 <br>
1L  15R  11L  6L <br>
1 <br>
15R  11L  6L <br>
15 <br>
11L  6L <br>
11 <br>
6L <br>
2 <br>
9R  13L  17L  6R <br>
9 <br>
13L  17L  6R <br>
13 <br>
17L  6R <br>
7 <br>
3L  12L  17R  6R <br>
10 <br>
3R  12L  17R  6R <br>
3 <br>
12L  17R  6R <br>
12 <br>
17R  6R <br>
17 <br>
6R <br>
6 <br>
 <br>
 <br> <br>
 <br>
<hr>
<a name="3"></a>  Breadth-first:     // visit one level at a time (left to right); use a queue to keep track of <br>
nodes to visit. <br>
 <br>
Node visited <br>
Queue <br>
 <br>
6 <br>
6 <br>
11  17 <br>
11 <br>
17  15 <br>
17 <br>
15  13  12 <br>
15 <br>
13  12  16  1 <br>
13 <br>
12  16  1  9 <br>
12 <br>
16  1  9  3 <br>
16 <br>
1  9  3 <br>
1 <br>
9  3  8 <br>
9 <br>
3  8  2 <br>
3 <br>
8  2  7  10 <br>
8 <br>
2  7  10 <br>
2 <br>
7  10 <br>
7 <br>
10 <br>
10 <br>
 <br>
 <br> <br>2. Write a recursive function that reverses the order of the nodes in each level of a binary tree. <br> <br>
void reverse(TreeNode t) { <br>
if (t != null) { <br>
tmp = t.left; <br>t.left = t.right; <br>t.right = tmp; <br>reverse(t.left); <br>reverse(t.right); <br>
} <br>
} <br>
 <br> <br> <br>3. Write a non-recursive function using a stack to compute the size of a binary tree. <br> <br> <br>
  Any traversal could be adapted by creating a counter and adding 1 to it each time a node <br>
is visited. The exercise asks for an iterative function using stacks, so preorder or inorder <br>would be appropriate.  <br>
 <br>
  Using the preorder function: <br>
 <br>
int iterativeSize(TreeNode p) { <br>
int count = 0; // we create the counting variable <br>if (p != null){ <br>
Stack stack = new StackImpl(); <br>stack.push(p); <br>do { <br>
p = (TreeNode)stack.pop(); <br>
<hr>
<a name="4"></a>count ++; // we add 1 when we visit <br>if (p.right != null) <br>
stack.push(p.right); <br>
if (p.left != null) <br>
stack.push(p.left); <br>
} while (! stack.isEmpty()); <br>
} <br>return count; // return the count <br>
  } <br> <br> <br>4. Show the binary search tree that results from inserting the following sequence of keys: 6, <br>3, 11, 9, 8, 5, 4, 2, 12, 7, 1, 10. <br> <br>
  The first element (6) is added at the root, and any subsequent elements are added by <br>
following the left branch when their value is lower than the root, or the right branch <br>when it is greater. For example, the last element added was (10), which is larger than <br>6; so the right branch is followed and 11 is found. 10 is lower than 11, so the left <br>branch is followed and 9 is found. 10 is greater than 9 and nothing is in 9&apos;s right <br>branch, so then we place 10 there. <br>
6<br>
3<br>
11<br>
2<br>
5<br>
9<br>
12<br>
1<br>
4<br>
8<br>
10<br>
7<br>
 <br>
 <br> <br>5. What kind of tree is produced if the same keys are inserted in ascending order? What if <br>they are inserted in descending order? <br> <br>
  By placing the keys in order (ascending or descending), a &quot;backbone&quot; tree is <br>
produced. For example, in ascending order: <br>
<hr>
<a name="5"></a>1<br>
2<br>
3<br>
4<br>
5<br>
6<br>
...<br>
 <br>
 <br> <br>
 <br>
<hr>
<a name="6"></a>6. A possible sorting algorithm is to add all the keys of an array to a binary search tree and <br>then read off its inorder traversal. Is this related to any of the sorting algorithms previously <br>considered? <br> <br>
  When adding keys to the binary tree, what is being done can be seen as finding a <br>
pivot, placing it at the root, and partitioning the rest by placing the values lower than <br>the root to the left, and the values larger than the root to the right. A pivot is found for <br>each one of these subtrees and a similar partitioning process takes place. The <br>procedure is thus similar to what quicksort does. <br>
 <br> <br>7. Show the tree that results from the tree built in exercise 4 if you delete10? What if you <br>deleted 3 instead? <br> <br>
  Removing a leaf node is easy: the element is simply deleted. <br>
 <br>
6<br>
3<br>
11<br>
2<br>
5<br>
9<br>
12<br>
1<br>
4<br>
8<br>
7<br>
 <br>
 <br>
  To remove the 3, some procedure should be followed. Since the 3 has the two <br>
branches, the &quot;harder case&quot; of deletion seen in the lecture is applied: <br>
 <br>
6<br>
4<br>
11<br>
2<br>
5<br>
9<br>
12<br>
1<br>
8<br>
10<br>
7<br>
 <br>
 <br>
<hr>
<a name="7"></a>  As you may have realised, this is not the only possible way of doing the deletion. In <br>
your textbooks you may find other possible algorithms that will, for example, place <br>the 2 where the 3 was, and have the (5) subtree. <br>
 <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Exercise Sheet 8 </b><br>
 <br> <br>1. Is this an AVL balanced tree? Justify your answer.  <br> <br> <br>
46<br>
21<br>
57<br>
15<br>
49<br>
92<br>
1<br>
18<br>
47<br>
73<br>
16<br>
48<br>
70<br>
80<br>
 <br>
 <br> <br> <br>2. Create an AVL balanced tree while inserting the values in this order: 1, 10, 100, 3, 50, 15, <br>23, and 48. <br> <br> <br>3. Delete the nodes 1 then 23 from the resulting tree above. <br> <br> <br>4. Show the splay tree that results from accessing the keys: 3 and then 6 on the tree below. <br> <br>
1 <br>
2 <br>
3 <br>
4 <br>
5 <br>
6 <br>
 <br>
 <br> <br>5. Create a B-Tree of order 3 with the keys: 1, 10, 100, 3, 50, 15 (in that order). <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Sample Answers to Exercise Sheet 8 </b><br>
 <br> <br>1. Is this an AVL balanced tree? Justify your answer.  <br> <br> <br>
46<br>
21<br>
57<br>
15<br>
49<br>
92<br>
1<br>
18<br>
47<br>
73<br>
16<br>
48<br>
70<br>
80<br>
 <br>
 <br>
  This tree is not AVL-balanced. Although the root is AVL balanced (both sides have the <br>
same depth), the same cannot be said of all nodes (see 21, 49 and 92). <br>
 <br> <br> <br>2. Create an AVL balanced tree while inserting the values in this order: 1, 10, 100, 3, 50, 15, <br>23, and 48. <br> <br>
 <br>
  This is the final tree <br>
 <br>
10<br>
1<br>
50<br>
3<br>
23<br>
100<br>
15<br>
48<br>
 <br>
 <br>3. Delete the nodes 1 then 23 from the resulting tree above. <br> <br>
  This is the final tree <br>
 <br>
<hr>
<a name="2"></a>15<br>
10<br>
50<br>
3<br>
48<br>
100<br>
 <br>
4. Show the splay tree that results from accessing the keys: 3 and then 6 on the tree below. <br> <br>
1 <br>
2 <br>
3 <br>
4 <br>
5 <br>
6 <br>
 <br>
 <br>
 <br>
  This is the final tree <br>
 <br>
6 <br>
3 <br>
2 <br>
5 <br>
1 <br>
4 <br>
 <br>
 <br> <br>5. Create a B-Tree of order 3 with the keys: 1, 10, 100, 3, 50, 15 (in that order). <br> <br> <br> <br> <br>
  This is the final tree <br>
 <br>
<hr>
<a name="3"></a> <br>
10 <br>
50 <br>
1 <br>
3 <br>
15 <br>
 <br>
100   <br>
<hr>



<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Answers to Exercise Sheet 9 </b><br>
 <br> <br>1. You are given a graph below. Please answer items a and b. <br> <br>
g<br>
a<br>
f<br>
c<br>
e<br>
b<br>
d<br>
 <br>
 <br>
a)  What is the order in which the various nodes are visited using breadth first traversal, <br>
starting at node &quot;a&quot;? <br>
 <br> <br>
b)  What is the order in which the various nodes are visited using depth first traversal, <br>
starting at node &quot;a&quot;? <br>
 <br> <br> <br>2. The knight is a chess piece that can move only in L shaped patterns, jumping two squares <br>horizontally and one square vertically, or two squares vertically and one horizontally. This <br>means that in one move, the knight--shown as an X in the table below--can move to any of <br>the squares marked by an O: <br> <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
O   <br>
O   <br>
 <br>
 <br>
 <br>
O   <br>
 <br>
 <br>
O   <br>
 <br>
 <br>
 <br>
 <br>
X   <br>
 <br>
 <br>
 <br>
 <br>
O   <br>
 <br>
 <br>
O   <br>
 <br>
 <br>
 <br>
O   <br>
O   <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>Now consider a knight on a board composed of the following 3 x 4 squares: <br> <br>
A  b  c <br>
d <br>
E  f <br>
g  h <br>
I <br>
j <br>
k  l <br>
 <br>
<hr>
<a name="2"></a> <br>
a)  Show using adjacency lists the possible moves the knight can make in the 3X4 board. <br>
 <br> <br>
b)  Show the possible moves of the knight as a simple graph (i.e., showing positions a, b, <br>
... l  as vertices, and the possible moves as edges). You may want to move the vertices <br>around to make the graph clearer. <br>
 <br> <br>
c)  Use Dijkstra&apos;s shortest path algorithm to find the lowest number of moves from a to b. <br>
i. <br>
Convert the simple graph into a weighted graph. Consider the number of <br>moves; what weight should you assign to each edge? <br>
 <br>
ii. <br>
The initial state of arrays toBeChecked, currDist and predecessor is: <br>
 <br>
 <br>
a <br>
b <br>
c <br>
D <br>
e <br>
f <br>
g <br>
h <br>
i <br>
j <br>
k <br>
l <br>
toBeChecked   <br>
x <br>
x <br>
X <br>
x <br>
x <br>
x <br>
x <br>
x <br>
x <br>
x <br>
x <br>
currDist <br>
0 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
predecessor <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br>
 <br> <br>
Show the state of arrays toBeChecked, currDist and predecessor after each iteration of <br>Dijkstra&apos;s algorithm. You may stop when a shortest path has been found from a to b. <br>
 <br> <br>
<hr>



<a name="1"></a><b>IN2002 Data Structures and Algorithms </b><br>
Lecture1 - Introduction<br>
Aravin Naren<br>Semester 1, 2018/19<br>
1<br>
<hr>
<a name="2"></a><b>Credit where credit is due</b><br>
&#xFFFD; The slides and material for this module have been <br>
evolving over the years. Some are brand new and <br>some are adapted/adopted from previous years <br>and/or previous module leaders at City.<br>
2<br>
<hr>
<a name="3"></a><b>What this module is about</b><br>
An abstract approach to programming as:<br>&#xFFFD; organising information (<i>data structures</i>)<br>&#xFFFD; performing computation (<i>algorithms</i>)<br>
Essential for computing professionals:<br>&#xFFFD; knowledge of common <i>data structures </i>and <i>algorithms<br></i>&#xFFFD; knowledge of when and how to use them<br>&#xFFFD; ability to analyse and develop them<br>
3<br>
<hr>
<a name="4"></a><b>Context</b><br>
Builds on concepts from...<br>&#xFFFD; Computation and Reasoning<br>
&#xFFFD; Algorithms<br>&#xFFFD; Complexity analysis<br>
&#xFFFD; Systems Architecture<br>
&#xFFFD; How the operating systems handle programs execution<br>
&#xFFFD; Programming<br>
&#xFFFD; Describing algorithms<br>&#xFFFD; Executing algorithms<br>
Provides the basis for...<br>
&#xFFFD; Any work relying on the creation and/or modification of programs<br>
4<br>
<hr>
<a name="5"></a><b>Learning Objectives</b><br>
&#xFFFD; Explain the workings of standard data structures and <br>
algorithms<br>
&#xFFFD; Analyse the space and time complexity of algorithms<br>&#xFFFD; Identify the most important abstract data types and the ways <br>
in which they may be implemented<br>
&#xFFFD; Select appropriate data structures and algorithms for <br>
particular practical situations<br>
&#xFFFD; Describe an implementation using plain English or <br>
pseudocode<br>
&#xFFFD; Devise appropriate algorithms to address specific problems<br>
5<br>
<hr>
<a name="6"></a><b>How to reach the learning goals</b><br>
&#xFFFD; Work continuously<br>&#xFFFD; Attend the lectures (arrive on time!)<br>&#xFFFD; Go to the tutorials and do the exercises<br>&#xFFFD; Use interactive examples<br>&#xFFFD; Program the algorithms yourself<br>&#xFFFD; Work through all the exercises<br>&#xFFFD; Read the relevant sections in the textbook<br>&#xFFFD; Do additional exercises<br>
6<br>
<hr>
<a name="7"></a><b>Course Text</b><br>
Weiss, Mark Allen: <i>Data Structures &amp; Problem Solving using <br>Java (4th edition). </i>Pearson Addison-Wesley, 2014<br>
...or, alternatively,<br>
Drozdek, Adam: Data Structures and Algorithms in Java (4th<br>edition).  Cengage 2013<br>
Earlier editions will do fine, and other books on data structures <br>and algorithms will help, too.<br>
7<br>
<hr>
<a name="8"></a><b>Organisation<br></b>Module Lecturer: Aravin Naren <br>
&lt;aravin.naren.1@city.ac.uk&gt;  <br>
Office hours: A302 (College Building)<br>
usual y Thu 15:00-16:50 <br>
check on-line (via Moodle) for potential changes<br>Lectures: 2 hours / week<br>
Thursdays; 9:00 - 10:50 in A130<br>
Tutorial/Lab: 1 hour / week<br>
Leaving 120 hours for reading, coursework preparation, etc...<br>
Material on Moodle, with discussion board for mutual help<br>
8<br>
<hr>
<a name="9"></a><b>Exercises</b><br>
Exercise sheets wil  be available on Moodle every week. The exercises <br>wil  be the topic of the tutorials.<br>
On even weeks wil  include a programming exercise.<br>
Doing the exercises is <b>essential </b>in preparing for the assessments.<br>
9<br>
<hr>
<a name="10"></a><b>Questions &amp; Discussion</b><br>
Discussion forum on Moodle<br>
&#xFFFD; We read it frequently and reply/comment as appropriate<br>Asking specific questions<br>
&#xFFFD; Moodle, tutorials, lectures, TAs surgeries and module leader&apos;s office <br>
hours<br>
Note that Moodle wil  also be used for announcements<br>
10<br>
<hr>
<a name="11"></a><b>Assessment</b><br>
Formative:<br>
&#xFFFD; 3 Multiple Choice Quizzes in weeks 3, 5 and 7<br>Summative:<br>
&#xFFFD;<br>
Oral exam (viva) late in the term based on lectures and tutorials, <br>worth 30% of overal  marks<br>
&#xFFFD;<br>
Written open books exam in January, worth 70% of overal  marks<br>
11<br>
<hr>
<a name="12"></a><b>Feedback</b><br>
Tutorials<br>
&#xFFFD; Formative feedback, but you must do the exercises first<br>Quizzes<br>
&#xFFFD; Formative feedback online via Moodle<br>Viva<br>
&#xFFFD; Immediately, face to face<br>Exam<br>
&#xFFFD; Observations on general performance via Moodle<br>
12<br>
<hr>
<a name="13"></a><b>2016-2017 Year Results</b><br>
Overal<br>
&#xFFFD;<br>
135 ful y enrol ed by exam time<br>
&#xFFFD;<br>
92 passed 1st attempt (68%)<br>
&#xFFFD;<br>
26 passed resit (another 19%)<br>
&#xFFFD;<br>
4 failed resit (3% of students)<br>
&#xFFFD;<br>
14 did not attempt the resit (another 10%)<br>
13<br>
<hr>
<a name="14"></a><b>2017-2018 Year Results</b><br>
Overal<br>
&#xFFFD;<br>
149 ful y enrol ed by exam time<br>
&#xFFFD;<br>
130 passed 1st attempt (87%)<br>
14<br>
<hr>
<a name="15"></a><b>Some input from previous students</b><br>
Advice for new students<br>
&#xFFFD;<br>
Practice on examples (tutorials and exercises) and seek feedback<br>
Advantages of the module<br>
&#xFFFD;<br>
Real world applicability<br>
&#xFFFD;<br>
Thought provoking<br>
&#xFFFD;<br>
Connection to other modules<br>
&#xFFFD;<br>
Important for job interviews<br>
Changes over the years<br>
&#xFFFD;<br>
Changed some slides &amp; reshuffled some of the material<br>
&#xFFFD;<br>
Made the link to programming more explicit<br>
&#xFFFD;<br>
Made MCQs formative<br>
&#xFFFD;<br>
Changed the exam format<br>
15<br>
<hr>
<a name="16"></a><b>Rules of Engagement</b><br>
&#xFFFD; Fol ow the student charter<br>
&#xFFFD; Do NOT disturb others during the lectures<br>
&#xFFFD; If you are more than FIVE minutes late to the lecture, then wait <br>
for the break to come in<br>
&#xFFFD; Don&apos;t use your mobile phones, Ipods, etc.<br>
&#xFFFD; Keep them off or silent mode<br>
&#xFFFD; Don&apos;t hold paral el conversations during the lectures<br>
&#xFFFD; Do give us constructive feedback off line as we are moving along<br>
&#xFFFD; We wil  fol ow the University rules<br>
&#xFFFD; We wil  strive to give you the best learning experience possible<br>
16<br>
<hr>
<a name="17"></a><b>Synopsis</b><br>
&#xFFFD;<br>
Revisit intro to algorithms, pseudocode, time and space complexity<br>
&#xFFFD;<br>
Recursion<br>
&#xFFFD;<br>
Pointers<br>
&#xFFFD;<br>
Abstract data types<br>
&#xFFFD; Priority queues, heaps, stacks, queues<br>&#xFFFD; Linked lists<br>
&#xFFFD; Singly linked lists, doubly linked lists and circular lists<br>
&#xFFFD;<br>
Hash tables<br>
&#xFFFD;<br>
Advanced trees<br>
&#xFFFD;<br>
Graphs<br>
17<br>
<hr>
<a name="18"></a><b>Week 1: Basic Concepts</b><br>
18<br>
<hr>
<a name="19"></a><b>Basic Concepts</b><br>
&#xFFFD; What are Algorithms and Data Structures?<br>
&#xFFFD; Describing an algorithm<br>&#xFFFD; Properties of algorithms<br>
&#xFFFD; Data structure: static arrays<br>&#xFFFD; Algorithm type: search<br>
19<br>
<hr>
<a name="20"></a><b>Data Structures and Algorithms*</b><br>
<b>System</b><br>
Representation<br>
Algorithms<br>
Data structures<br>
Task<br>
Reality<br>
20<br>
* See Computation &amp; Reasoning lecture notes<br>
<hr>
<a name="21"></a><b>Algorithms in Computing</b><br>
Mathematical description of actions on numbers or symbols.<br>&#xFFFD; can be executed by a machine<br>&#xFFFD; are easily accessible to analysis<br>
We will look at the abstract properties of algorithms, understanding how <br>they work and using a bit of mathematics to determine how they behave.<br>
21<br>
<hr>
<a name="22"></a><b>Describing an Algorithm</b><br>
&#xFFFD;<br>
As unstructured text<br>
&#xFFFD;<br>
As structured text<br>
&#xFFFD;<br>
As a flow chart<br>
&#xFFFD;<br>
As pseudocode<br>
&#xFFFD;<br>
As Java code (or any programming language)<br>
In this module we will mainly use pseudocode and Java.<br>
22<br>
<hr>
<a name="23"></a><b>Pseudocode Syntax*</b><br>
Title with function/method name and <br>arguments<br>
Sequence control in capitals:<br>
<i>Function foo(array):</i><br>
&#xFFFD; WHILE<br>
<i>bar </i>&#xFFFD; <i>0, i </i>&#xFFFD; <i>1</i><br>
&#xFFFD; IF/THEN/ELSE<br>
<i>WHILE i &lt;= length of array</i><br>
<i>bar </i>&#xFFFD; <i>bar+ array[i]</i><br>
Indent to indicate scope<br>
<i>i </i>&#xFFFD; <i>i + 1</i><br>
Arrow for assignment (can <br>
<i>Return bar</i><br>
be typed &quot;&lt;-&quot;)<br>
23<br>
* See Computation &amp; Reasoning lecture notes<br>
<hr>
<a name="24"></a><b>Another Example</b><br>
Title with function/method name and <br>arguments<br>
<i>Function foo2(array):<br>bar </i>&#xFFFD; <i>0, i </i>&#xFFFD; <i>1</i><br>
Sequence control in capitals:<br>
<i>WHILE i &lt;= length of array</i><br>
&#xFFFD; WHILE<br>
<i>IF array[i] = 0 THEN</i><br>
&#xFFFD; IF/THEN/ELSE<br>
<i>bar </i>&#xFFFD; <i>bar + 1</i><br>
<i>ELSE</i><br>
Indentation indicates scope<br>
<i>array[i] </i>&#xFFFD; <i>0</i><br>
<i>i </i>&#xFFFD; <i>i + 1</i><br>
Arrow for assignment (can <br>
<i>Return bar</i><br>
24<br>
be typed as &quot;&lt;-&quot;)<br>
<hr>
<a name="25"></a><b>Data Structures</b><br>
Data structures are ways of organising data.<br>
They should<br>&#xFFFD; represent all relevant information<br>&#xFFFD; use little memory<br>&#xFFFD; support efficient algorithms<br>
25<br>
<hr>
<a name="26"></a><b>A simple data structure: a static array</b><br>
&#xFFFD; Built into most programming languages<br>&#xFFFD; A finite set of elements<br>&#xFFFD; The elements are in a fixed sequence<br>&#xFFFD; Elements can be addressed by <br>indices (Pseudocode, Mathematics, Pascal) or offsets (Java, C, C++)<br>
26 3<br>
7 13 9<br>
5 17 4<br>
index<br>
1<br>
2<br>
3<br>
4<br>
5<br>
6<br>
7<br>
8<br>
offset<br>
0<br>
1<br>
2<br>
3<br>
4<br>
5<br>
6<br>
7<br>
26<br>
<hr>
<a name="27"></a><b>Devising programmes to solve problems</b><br>
... is a combination of identifying the most suitable<br>
&#xFFFD;<br>
data structure to contain the data<br>
&#xFFFD;<br>
algorithm to accomplish the task <br>
&#xFFFD;<br>
Not all combinations of data structures and algorithms work<br>
&#xFFFD;<br>
A given combination of data structure and algorithm may be ideal for <br>one situation, yet not the best for another<br>
27<br>
<hr>
<a name="28"></a><b>An algorithm example</b><br>
What does <i>foo </i>do? *<br>
<i>Function foo(array):<br>bar </i>&#xFFFD; <i>0, i </i>&#xFFFD; <i>1<br>WHILE i &lt;= length of array</i><br>
<i>bar </i>&#xFFFD; <i>bar+ array[i]<br>i </i>&#xFFFD; <i>i + 1</i><br>
<i>Return bar</i><br>
* From slide 23<br>
28<br>
<hr>
<a name="29"></a><b>Another algorithm example</b><br>
What does <i>foo2 </i>do? *<br>
<i>Function foo2(array):<br>bar </i>&#xFFFD; <i>0, i </i>&#xFFFD; <i>1<br>WHILE i &lt;= length of array</i><br>
<i>IF array[i] = 0 THEN</i><br>
<i>bar </i>&#xFFFD; <i>bar + 1</i><br>
<i>ELSE</i><br>
<i>array[i] </i>&#xFFFD; <i>0</i><br>
<i>i </i>&#xFFFD; <i>i + 1</i><br>
<i>Return bar</i><br>
* From slide 23<br>
29<br>
<hr>
<a name="30"></a><b>Known algorithm examples</b><br>
&#xFFFD; Selection sort<br>&#xFFFD; Insertion sort<br>&#xFFFD; Quicksort<br>&#xFFFD; Mergesort<br>&#xFFFD; Binary search<br>
&#xFFFD; Why were these examples explored?<br>
* Seen on Computation &amp; Reasoning<br>
30<br>
<hr>
<a name="31"></a><b>Computational Complexity</b><br>
31<br>
<hr>
<a name="32"></a><b>Computational Complexity</b><br>
Description of the resources needed by an algorithm:<br>&#xFFFD; Complexity in <br>
&#xFFFD; (running) time or<br>&#xFFFD; (memory) space<br>
&#xFFFD; Best, worst and average cases<br>&#xFFFD; Representation by growth<br>
32<br>
<hr>
<a name="33"></a><b>Formalism for big-O</b><br>
DEFINITION: <i>f(n) </i>is in <i>O(g(n)) </i>if and only if <i>c </i>and <i>N&gt;0 </i>exist such that for all <i>n <br>&gt; N</i>, <i>f(n) </i> <i>c</i>&#xFFFD; <i>g(n)<br>c </i>is a constant factor, and <i>N </i>is an index of asymptotic behaviour.<br>Example: <i>f(n)=2n2 + 3n + 1 </i>is in <i>O(n2)</i>:<br><i>N=2 </i>and <i>c=4</i>, or <i>N=4 </i>and <i>c=3</i>, etc.<br>Property: if <i>f1(n) </i>and <i>f2(n) </i>are both in <i>O(g(n))</i>, so is <i>f1(n)+f2(n)<br></i>Proof (sketch): Let <i>c1</i>, <i>c2 </i>be the constant factors for <i>f1 and f2, then with c1+2 = c1<br>+ c2 apply big-O definition.</i><br>
33<br>
<hr>
<a name="34"></a><b>Implications...</b><br>
&#xFFFD; Big-O is an upper bound, actual values may be less<br>
&#xFFFD; If <i>g</i>(<i>n</i>) <i> f(n) </i>then <i>g</i>(<i>n</i>) is in O(<i>f(n))</i><br>
&#xFFFD; Saying that an algorithm <i>a </i>is in O(<i>g</i>(<i>n</i>)) means that it grows no faster than <br>
<i>g</i>(<i>n</i>).<br>
Note: We often omit the word &apos;in&apos; and say <i>a </i>is O(<i>g</i>(<i>n</i>)).<br>
34<br>
<hr>
<a name="35"></a><b>Properties of big-O</b><br>
Rule 1: Scaling by a constant: <i>O(c&#xFFFD;f(n)) = O(f(n))</i><br>
Rule 2: Addition: <br>
if <i>f(n) </i>is <i>O(g(n)) (always applies to one part)</i><br>
then <i>O(f(n)) + O(g(n)) = O(g(n)) </i>(greater term dominates)<br>
<i>Rule 3: Multiplication:</i><br>
<i>O(f(n))&#xFFFD;O(g(n)) = O(f(n)&#xFFFD;g(n))</i><br>
<i>Rule 4: Logarithms: </i><br>
<i>O(loga n) = O(logb n) </i>(we usual y just write <i>O(log n)</i>)<br>
35<br>
<hr>
<a name="36"></a><b>Example calculations</b><br>
&#xFFFD;Orders of sequential algorithm phases are added:<br>
e.g. an <i>O(n2) </i>phase followed by an <i>O(n log (n)) </i>phase is <br>
<i>O(n2) + O(n log(n)) = O(n2)</i><br>
&#xFFFD;(<i>n log(n)) is O(n2)</i>, apply Rule 2)<br>
&#xFFFD;3n log(n) + 100n + 50log(n) + 23  is  <i>...</i><br>
36<br>
<hr>
<a name="37"></a><b>Example calculations (2)</b><br>
&#xFFFD; Orders of nested loops are multiplied:<br>
e.g. an outer loop is executed <i>O(n2) </i>times and contains an inner loop that <br>
is executed <i>O(n) </i>times (its content is O(1)): <br>
O(n2)&#xFFFD;O(n) = O(n3)  <br>
Rule 3<br>
&#xFFFD; 3n log(n) &#xFFFD; 2n + 7log(n)  is  <i>...</i><br>
37<br>
<hr>
<a name="38"></a><b>Common types of complexity *</b><br>
constant: <i>O(1)<br></i>logarithmic: <i>O(log n) </i><br>
<i><b>good</b></i><br>
linear: <i>O(n)<br></i>quadratic: <i>O(n2)</i><br>
<i><b>acceptable </b>(sometimes)</i><br>
cubic: <i>O(n3)<br></i>polynomial: <i>O(nk)<br></i>exponential: <i>O(an)</i><br>
<i><b>intractable</b></i><br>
<i>factorial: O(n!)</i><br>
* See Computation &amp; Reasoning lecture notes<br>
38<br>
<hr>
<a name="39"></a><b>Sequential search is linear</b><br>
O(n)<br>
<i>number <br>of loops</i><br>
<i>array length</i><br>
39<br>
<hr>
<a name="40"></a><b>Binary search is logarithmic: O(log n)</b><br>
<i>log(n)+1<br>worst case</i><br>
<i>average</i><br>
<i>loops</i><br>
40<br>
<i>array length</i><br>
<hr>
<a name="41"></a><b>Binary search is logarithmic: O(log n)</b><br>
<i>log(n)+1</i><br>
<i>loops</i><br>
<i>worst</i><br>
<i>average</i><br>
<i>array length</i><br>
41<br>
<i>Note how flat the graph gets for large numbers.</i><br>
<hr>
<a name="42"></a><b>Finding the order of complexity</b><br>
<i>Function binary_search(array, key)<br>lo </i>1<i>, hi  length of array<br>WHILE lo  hi</i><br>
<i>mid  (lo + hi) / </i>2<br><i>IF key &lt; array[mid] THEN</i><br>
<i>hi = mid - </i>1<br>
<i>ELSE</i><br>
<i>IF key &gt; array[mid] THEN</i><br>
<i>lo = mid + </i>1<br>
<i>ELSE</i><br>
<i>Return mid</i><br>
<i>Return </i>-1<br>
42<br>
<hr>
<a name="43"></a><b>Examples of code complexity analysis</b><br>
<i>Function foo3(array):<br>sum  </i>0<i>, c  </i>1<br><i>WHILE c &lt;= length of array</i><br>
<i>c1  </i>1<br><i>WHILE c1 &lt;= length of array</i><br>
<i>sum  sum + array[c] * </i><br>
<i>array[c1]</i><br>
<i>c1  c1 + </i>1<br>
<i>c  c + </i>1<br>
<i>Return sum</i><br>
43<br>
<hr>
<a name="44"></a><b>Other examples of complexity code analysis *</b><br>
<i>Function foo(array):<br>bar </i>&#xFFFD; <i>0, i </i>&#xFFFD; <i>1<br>WHILE i &lt;= length of array</i><br>
<i>bar </i>&#xFFFD; <i>bar+ array[i]<br>i </i>&#xFFFD; <i>i + 1</i><br>
<i>Return bar</i><br>
44<br>
* From slides 22 and 27<br>
<hr>
<a name="45"></a><b>Other examples of complexity code analysis *</b><br>
<i>Function foo2(array):<br>bar </i>&#xFFFD; <i>0, i </i>&#xFFFD; <i>1<br>WHILE i &lt;= length of array</i><br>
<i>IF array[i] = 0 THEN</i><br>
<i>bar </i>&#xFFFD; <i>bar + 1</i><br>
<i>ELSE</i><br>
<i>array[i] </i>&#xFFFD; <i>0</i><br>
<i>i </i>&#xFFFD; <i>i + 1</i><br>
<i>Return bar</i><br>
45<br>
* From slides 23 and 28<br>
<hr>
<a name="46"></a><b>Some algorithms and their complexity</b><br>
&#xFFFD; Binary search: O(log n) time, O(1) space <br>
<b>fast</b><br>
&#xFFFD; Linear search: O(n) time, O(1) space<br>&#xFFFD; Multiplication of n-bit integers: O(n log n log log n) <b>doable<br></b>&#xFFFD; Matrix multiplication for n*n matrices (std): O(n3)<br>&#xFFFD; Travelling salesman: Best known algorithms take<br>
O(2n) time <br>
<b>intractable</b><br>
&#xFFFD; All permutations of a sequence: O(n!)<br>
46<br>
<hr>
<a name="47"></a><b>Well known complexity classes</b><br>
P: computable in polynomial time<br>&#xFFFD; these problems are considered tractable (although there are limits in practice).<br>
NP: computable in polynomial time on a non-deterministic (infinitely parallel) <br>machine<br>&#xFFFD; if we can take a solution and test it in polynomial time, we can find any solution <br>
by testing all possible solutions in parallel<br>
EXPTIME: exponential time<br>&#xFFFD; these problems are known to be really hard.<br>
47<br>
<hr>
<a name="48"></a><b>NP-Complete Problems</b><br>
Class of combinatorial problems that are equally hard; e.g.:<br>&#xFFFD; Travelling salesman problem:<br>
Shortest tour visiting all cities in a set<br>
&#xFFFD; Knapsack:<br>
Given a set of items with a given value and weight each,<br>find the set with the highest value within a weight limit<br>
&#xFFFD; Satisfiability:<br>
Find the assignment of values to make a logical proposition true<br>
Any NP problem can be reduced to any of these, i.e. if we have a solution to one <br>of them we have one to all NP.<br>
48<br>
<hr>
<a name="49"></a><b>Famous Question: Is P = NP?</b><br>
One of the 6 Millennium Prize Problems<br>US $1 million offered for a solution by<br>Clay Mathematics Institute, Massachusetts.<br>
If there is an polynomial solution to an NP-complete problem, then P = NP.<br>No solution found yet, but also no proof that it is impossible.<br>
Most scientists believe P != NP. Otherwise some very hard problems will become <br>easy (possibly including some cryptographic code-breaking). Some solutions have <br>been presented, but none has stood up to scrutiny yet.<br>
49<br>
<hr>
<a name="50"></a><img src="lecture1Introduction-50_1.jpg"><br>
Grigori Perelman<br>
50<br>
<hr>
<a name="51"></a><b>Reading</b><br>
&#xFFFD; For visualisations check Linear and Binary Search on:<br>
https://www.cs.usfca.edu/~galles/visualization/Search.html<br>
&#xFFFD; Weiss:  Chapter 5 <br>
&#xFFFD; Drozdek:  Chapter 2 <br>
Next week: Recursion &amp; Abstract Data Types<br>
51<br>
<hr>
<a name="52"></a>City, University of London<br>Northampton Square<br>London<br>EC1V 0HB<br>United Kingdom<br>
T: +44 (0)20 7040 8406<br>E: ug-compsci@city.ac.uk<br>www.city.ac.uk/department-computer-science<br>
52<br>
<hr>


null
<a name="1"></a><b>Module IN2002--Data Structures and Algorithms </b><br>
<b>Exercise Sheet 1 </b><br>
 <br> <br>Note that you may not have enough time to finish this during the tutorial slot. Get started, see <br>where you have difficulties, study, ask questions, and try again. You should aim to finish all <br>the questions before the next lecture. <br> <br> <br>1. Consider the following pseudocode : <br>
<i> <br>Function foo(array) <br></i>i  1 <br>WHILE array[i] mod 23 != 0 AND i &lt;= length of array <br>
i  i+1 <br>
Return i <br><i> </i><br>
(a)  Describe in plain English what this algorithm does. <br>(b) What is the time complexity with respect to the array size <i>n </i>of the algorithm described <br>
in the worst case, best case, average case? Justify your answer and state assumptions <br>you make for the average case. <br>
 <br> <br>2. Suppose a program consists of two phases executed one after the other. The program takes <br>a string as input, which may be of any length <i>n</i> . What is the time complexity of the whole <br>program, with the phases being of the following complexities? <br>
(a)  O(<i>n</i>2) and O(<i>n </i>log <i>n</i>) <br>(b) O(log <i>n</i>) and O(<i>n</i>) <br>(c)  O(<i>n</i>) and O(<i>n</i>) <br>
 <br> <br>3. Consider the following pseudocode: <br>
<i> <br>Function foo(k) <br></i>s  1 <br>WHILE k &gt; 0 <br>
s  s * 2 <br>k  k-1 <br>
Return s <br><i> <br></i>(a) What does <i>foo </i>compute? <br>
i. nothing  <br>ii. k2 <br>iii. s * k <br>iv. 2k <br>
 <br>
(b) What is the time complexity of <i>foo </i>with respect to <i>k </i>in the worst case? <br>
i. O(1) <br>ii. O(2k) <br>iii.O(s) <br>iv. O(k) <br>
<hr>
<a name="2"></a> <br>
(c) How is the complexity different for the best or average case? <br>Justify your answers. <br>
 <br> <br>4. Create an algorithm that given an array of integers returns the number of times that the <br>number 100 is present in the array. Then answer the questions below. <br> <br>
(a)  What is the time complexity of your algorithm? Justify your answer. <br>(b) What is its space complexity? Justify your answer. <br>(c)  Would it make a difference if the input array was sorted? Justify your answer. <br>
 <br> <br>5. Consider the following pseudocode: <br><i> </i><br>
<i>Function bar(k) <br></i>WHILE k &gt; 0 <br>
i  k <br>s  0 <br>WHILE i &gt; 0 <br>
s  s + i <br>i  i -1 <br>
array[k]  s <br>k  k &#xFFFD; 1 <br>
Return array <br><i> <br></i>(a) What does <i>bar </i>compute? <br>
i. [] <br>ii. [1,2,3, ... , k] <br>iii. [1,1+2,1+2+3, ... , 1+ ... +k] <br>iv. k * s <br>
 <br>
(b) What is the time complexity of <i>bar </i>with respect to <i>k </i>in the worst case: <br>
i. O(1) <br>ii. O(s) <br>iii. O(k) <br>iv. O(k2) <br>
 <br>
(c) Is the complexity different for the best or average case? <br> <br>
(d) How could the computation in <i>bar </i>be done in a more efficient way? (You need to <br>remember your Maths knowledge to do this. This link will help: http://www.cut-the-<br>knot.org/Curriculum/Algebra/GaussSummation.shtml ). Justify your answers. <br>
 <br> <br>
<hr>


</p></body>